/**
 * Standardized Report Generation Workflow Service
 * Orchestrates the complete data flow: EDF Upload ‚Üí qEEG Pro ‚Üí NeuroSense ‚Üí Care Plan
 */

import DatabaseService from './databaseService';
import QEEGProService from './qeegProService';
import NeuroSenseService from './neuroSenseService';
import StorageService from './storageService';
import { supabase } from '../lib/supabaseClient';
import toast from 'react-hot-toast';

class ReportWorkflowService {
  constructor() {
    this.workflows = new Map(); // Track active workflows
  }

  /**
   * Start complete EDF processing workflow
   * @param {File} edfFile - The EDF file to process
   * @param {Object} patientInfo - Patient information
   * @param {string} clinicId - Clinic identifier
   * @returns {Promise<string>} Workflow ID for tracking
   */
  async startEDFProcessingWorkflow(edfFile, patientInfo, clinicId) {
    const workflowId = `workflow_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;

    try {
      console.log('START: Starting EDF processing workflow:', workflowId);

      // Initialize workflow tracking
      const workflow = {
        id: workflowId,
        patientId: patientInfo.id,
        patientName: patientInfo.name,
        clinicId,
        fileName: edfFile.name,
        fileSize: edfFile.size,
        status: 'started',
        steps: {
          fileUpload: { status: 'pending', startedAt: null, completedAt: null },
          qeegProcessing: { status: 'pending', startedAt: null, completedAt: null },
          neuroSenseAnalysis: { status: 'pending', startedAt: null, completedAt: null },
          carePlanGeneration: { status: 'pending', startedAt: null, completedAt: null },
          reportFinalization: { status: 'pending', startedAt: null, completedAt: null }
        },
        startedAt: new Date().toISOString(),
        estimatedCompletion: new Date(Date.now() + 8 * 60 * 1000).toISOString(), // 8 minutes
        results: {}
      };

      this.workflows.set(workflowId, workflow);
      await this.saveWorkflowToDatabase(workflow);

      // Start the async processing pipeline
      this.executeWorkflowSteps(workflowId, edfFile, patientInfo, clinicId);

      return workflowId;
    } catch (error) {
      console.error('ERROR: Failed to start workflow:', error);
      throw new Error(`Workflow initialization failed: ${error.message}`);
    }
  }

  /**
   * Execute workflow steps sequentially
   */
  async executeWorkflowSteps(workflowId, edfFile, patientInfo, clinicId) {
    try {
      const workflow = this.workflows.get(workflowId);
      if (!workflow) throw new Error('Workflow not found');

      // Step 1: Upload EDF file to S3
      await this.executeFileUpload(workflowId, edfFile, patientInfo, clinicId);

      // Step 2: Process through qEEG Pro
      await this.executeQEEGProcessing(workflowId, edfFile, patientInfo);

      // Step 3: Analyze through NeuroSense
      await this.executeNeuroSenseAnalysis(workflowId, patientInfo);

      // Step 4: Generate care plan
      await this.executeCarePlanGeneration(workflowId, patientInfo);

      // Step 5: Finalize and save report
      await this.executeReportFinalization(workflowId, clinicId, patientInfo);

      console.log('SUCCESS: Workflow completed successfully:', workflowId);

    } catch (error) {
      console.error('ERROR: Workflow failed:', workflowId, error);
      await this.markWorkflowAsFailed(workflowId, error.message);
    }
  }

  /**
   * Step 1: Upload EDF file to S3
   */
  async executeFileUpload(workflowId, edfFile, patientInfo, clinicId) {
    const workflow = this.workflows.get(workflowId);
    workflow.steps.fileUpload.status = 'processing';
    workflow.steps.fileUpload.startedAt = new Date().toISOString();
    await this.updateWorkflowInDatabase(workflow);

    try {
      console.log('üöÄ WORKFLOW: Starting file upload...');
      console.log('File name:', edfFile.name);
      console.log('File size:', edfFile.size, 'bytes');
      console.log('File type:', edfFile.type);
      console.log('Clinic ID:', clinicId);
      console.log('Patient ID:', patientInfo.id);

      // Check authentication status (non-blocking)
      const { data: { session } } = await supabase.auth.getSession();
      if (session) {
        console.log('‚úÖ WORKFLOW: User authenticated:', session.user.email);
      } else {
        console.warn('‚ö†Ô∏è WORKFLOW: No session found, but continuing with upload...');
      }

      // Check if bucket exists
      const { data: buckets, error: bucketsError } = await supabase.storage.listBuckets();
      if (bucketsError) {
        console.error('‚ùå WORKFLOW: Cannot list buckets:', bucketsError);
        throw new Error(`Cannot access storage: ${bucketsError.message}`);
      }
      const edfBucket = buckets.find(b => b.id === 'edf-files');
      if (!edfBucket) {
        console.error('‚ùå WORKFLOW: edf-files bucket does not exist!');
        console.error('Available buckets:', buckets.map(b => b.id).join(', '));
        throw new Error('Storage bucket "edf-files" not found. Please run CREATE_EDF_BUCKET_NOW.sql in Supabase');
      }
      console.log('‚úÖ WORKFLOW: edf-files bucket exists');

      // Upload directly to edf-files bucket in Supabase Storage
      const timestamp = Date.now();
      const sanitizedFileName = edfFile.name.replace(/[^a-zA-Z0-9._-]/g, '_');
      const filePath = `${clinicId}/${patientInfo.id}/${timestamp}_${sanitizedFileName}`;

      console.log('üìÅ WORKFLOW: Uploading to edf-files bucket...');
      console.log('üìÅ Path:', filePath);
      console.log('üìÅ Bucket:', 'edf-files');
      console.log('üìÅ Content-Type:', edfFile.type || 'application/octet-stream');

      // Upload to edf-files bucket
      const { data, error } = await supabase.storage
        .from('edf-files')
        .upload(filePath, edfFile, {
          contentType: edfFile.type || 'application/octet-stream',
          upsert: false,
          metadata: {
            clinicId,
            patientId: patientInfo.id,
            workflowId,
            originalName: edfFile.name,
            uploadedAt: new Date().toISOString()
          }
        });

      if (error) {
        console.error('‚ùå WORKFLOW: Upload to edf-files bucket failed!');
        console.error('‚ùå Error statusCode:', error.statusCode);
        console.error('‚ùå Error code:', error.code);
        console.error('‚ùå Error message:', error.message);
        console.error('‚ùå Error name:', error.name);
        console.error('‚ùå Full error object:', JSON.stringify(error, null, 2));

        // Provide user-friendly error messages
        if (error.statusCode === 403 || error.message?.includes('policy')) {
          throw new Error('Permission denied. The storage bucket policies may not be configured correctly. Please run CREATE_EDF_BUCKET_NOW.sql');
        } else if (error.message?.includes('not found')) {
          throw new Error('Storage bucket not found. Please create the edf-files bucket first.');
        } else {
          throw new Error(`Upload failed: ${error.message || 'Unknown error'}`);
        }
      }

      // Get signed URL for the uploaded file
      const { data: urlData } = supabase.storage
        .from('edf-files')
        .getPublicUrl(data.path);

      const uploadResult = {
        success: true,
        path: data.path,
        url: urlData.publicUrl,
        bucket: 'edf-files',
        fileName: edfFile.name,
        uploadedAt: new Date().toISOString()
      };

      console.log('‚úÖ WORKFLOW: File uploaded successfully to edf-files bucket!');
      console.log('üìÑ File path:', data.path);
      console.log('üîó File URL:', urlData.publicUrl);
      console.log('üì¶ Bucket:', 'edf-files');

      // Save file record
      const fileRecord = {
        id: `file_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
        workflowId,
        fileName: edfFile.name,
        fileSize: edfFile.size,
        fileType: 'EDF',
        storagePath: uploadResult.path,
        storageUrl: uploadResult.url,
        patientId: patientInfo.id,
        clinicId,
        uploadedAt: new Date().toISOString(),
        status: 'uploaded'
      };

      // Try to save file record (optional - continue even if fails)
      try {
        await DatabaseService.add('uploaded_files', fileRecord);
        console.log('SUCCESS: File record saved to database');
      } catch (error) {
        console.warn('WARNING: Could not save file record to database (table may not exist yet):', error.message);
      }

      // HOT: CREATE IMMEDIATE REPORT ENTRY - User can see it right away!
      // Don't set id - let database generate UUID automatically
      const immediateReport = {
        // id will be auto-generated by database (uuid_generate_v4())
        clinic_id: clinicId,
        patient_id: patientInfo.id,
        file_name: edfFile.name,
        file_path: uploadResult.path,
        file_type: edfFile.type || 'application/octet-stream', // Add fileType for dashboard display
        file_size: formatFileSize(edfFile.size), // Human-readable size
        storage_path: uploadResult.path, // For download
        file_url: uploadResult.url, // Public URL
        bucket_name: 'edf-files', // Bucket info for superadmin dashboard
        status: 'processing',
        // Store extra data in JSONB report_data column
        report_data: {
          title: edfFile.name.replace(/\.(edf|eeg|bdf)$/i, ''),
          type: 'EEG/qEEG Analysis',
          report_type: 'eeg_analysis',
          patient_name: patientInfo.name,
          workflow_id: workflowId,
          file_size: edfFile.size, // Raw bytes for calculations
          file_type: edfFile.type || 'application/octet-stream',
          file_url: uploadResult.url,
          storage_path: uploadResult.path,
          bucket_name: 'edf-files',
          processing_status: 'uploaded',
          processing_step: 'File uploaded - Analysis in progress',
          progress: 20,
          uploaded_at: new Date().toISOString()
        },
        created_at: new Date().toISOString(),
        updated_at: new Date().toISOString()
      };

      // Helper function to format file size
      function formatFileSize(bytes) {
        if (bytes === 0) return '0 Bytes';
        const k = 1024;
        const sizes = ['Bytes', 'KB', 'MB', 'GB'];
        const i = Math.floor(Math.log(bytes) / Math.log(k));
        return Math.round(bytes / Math.pow(k, i) * 100) / 100 + ' ' + sizes[i];
      }

      try {
        const createdReport = await DatabaseService.add('reports', immediateReport);
        const reportId = createdReport.id; // Get auto-generated UUID from database
        console.log('SUCCESS: Immediate report entry created:', reportId);
        workflow.results.reportId = reportId; // Store for later update
      } catch (error) {
        console.error('ERROR: Failed to create immediate report entry:', error);
        console.error('Error details:', error.message);
        // Don't throw - continue workflow even if report entry fails
      }

      workflow.steps.fileUpload.status = 'completed';
      workflow.steps.fileUpload.completedAt = new Date().toISOString();
      workflow.results.fileUpload = fileRecord;

      await this.updateWorkflowInDatabase(workflow);
      console.log('SUCCESS: File upload completed for workflow:', workflowId);

    } catch (error) {
      workflow.steps.fileUpload.status = 'failed';
      workflow.steps.fileUpload.error = error.message;
      await this.updateWorkflowInDatabase(workflow);
      throw error;
    }
  }

  /**
   * Step 2: Process through qEEG Pro
   */
  async executeQEEGProcessing(workflowId, edfFile, patientInfo) {
    const workflow = this.workflows.get(workflowId);
    workflow.steps.qeegProcessing.status = 'processing';
    workflow.steps.qeegProcessing.startedAt = new Date().toISOString();
    await this.updateWorkflowInDatabase(workflow);

    try {
      // Update report progress - qEEG processing started
      const reportId = workflow.results.reportId;
      if (reportId) {
        try {
          const currentReport = await DatabaseService.findById('reports', reportId);
          await DatabaseService.update('reports', reportId, {
            status: 'processing',
            report_data: {
              ...currentReport.report_data,
              processing_status: 'qeeg_processing',
              processing_step: 'qEEG Pro analysis in progress',
              progress: 40
            },
            updated_at: new Date().toISOString()
          });
        } catch (error) {
          console.warn('WARNING: Could not update report progress:', error.message);
        }
      }

      // Submit to qEEG Pro
      const qeegResult = await QEEGProService.uploadForProcessing(edfFile, {
        patientId: patientInfo.id,
        patientName: patientInfo.name,
        clinicId: workflow.clinicId
      });

      // Wait for processing to complete (in real implementation, this would be a webhook/polling)
      await this.waitForQEEGCompletion(qeegResult.jobId);

      // Download results
      const qeegReport = await QEEGProService.downloadReport(qeegResult.jobId);

      workflow.steps.qeegProcessing.status = 'completed';
      workflow.steps.qeegProcessing.completedAt = new Date().toISOString();
      workflow.results.qeegProcessing = {
        jobId: qeegResult.jobId,
        report: qeegReport
      };

      // Update report progress - qEEG completed
      if (reportId) {
        try {
          const currentReport = await DatabaseService.findById('reports', reportId);
          await DatabaseService.update('reports', reportId, {
            status: 'processing',
            report_data: {
              ...currentReport.report_data,
              processing_status: 'qeeg_completed',
              processing_step: 'qEEG analysis completed',
              progress: 60,
              qeeg_job_id: qeegResult.jobId
            },
            updated_at: new Date().toISOString()
          });
        } catch (error) {
          console.warn('WARNING: Could not update report progress:', error.message);
        }
      }

      await this.updateWorkflowInDatabase(workflow);
      console.log('SUCCESS: qEEG processing completed for workflow:', workflowId);

    } catch (error) {
      workflow.steps.qeegProcessing.status = 'failed';
      workflow.steps.qeegProcessing.error = error.message;
      await this.updateWorkflowInDatabase(workflow);
      throw error;
    }
  }

  /**
   * Step 3: Analyze through NeuroSense
   */
  async executeNeuroSenseAnalysis(workflowId, patientInfo) {
    const workflow = this.workflows.get(workflowId);
    workflow.steps.neuroSenseAnalysis.status = 'processing';
    workflow.steps.neuroSenseAnalysis.startedAt = new Date().toISOString();
    await this.updateWorkflowInDatabase(workflow);

    try {
      // Update report progress - NeuroSense analysis started
      const reportId = workflow.results.reportId;
      if (reportId) {
        try {
          const currentReport = await DatabaseService.findById('reports', reportId);
          await DatabaseService.update('reports', reportId, {
            status: 'processing',
            report_data: {
              ...currentReport.report_data,
              processing_status: 'neurosense_analyzing',
              processing_step: 'NeuroSense AI analysis in progress',
              progress: 70
            },
            updated_at: new Date().toISOString()
          });
        } catch (error) {
          console.warn('WARNING: Could not update report progress:', error.message);
        }
      }

      const qeegReport = workflow.results.qeegProcessing.report;

      // Process through NeuroSense algorithms
      const neuroSenseResult = await NeuroSenseService.processQEEGReport(qeegReport, patientInfo);

      // Save NeuroSense report
      const savedReport = await NeuroSenseService.saveProcessedReport(
        neuroSenseResult,
        workflow.clinicId,
        patientInfo.id
      );

      workflow.steps.neuroSenseAnalysis.status = 'completed';
      workflow.steps.neuroSenseAnalysis.completedAt = new Date().toISOString();
      workflow.results.neuroSenseAnalysis = {
        reportId: savedReport.id,
        standardizedReport: neuroSenseResult.standardizedReport,
        riskAssessment: neuroSenseResult.riskAssessment,
        recommendations: neuroSenseResult.recommendations
      };

      // Update report progress - NeuroSense completed
      if (reportId) {
        try {
          const currentReport = await DatabaseService.findById('reports', reportId);
          await DatabaseService.update('reports', reportId, {
            status: 'processing',
            report_data: {
              ...currentReport.report_data,
              processing_status: 'neurosense_completed',
              processing_step: 'NeuroSense analysis completed',
              progress: 85,
              neurosense_report_id: savedReport.id
            },
            updated_at: new Date().toISOString()
          });
        } catch (error) {
          console.warn('WARNING: Could not update report progress:', error.message);
        }
      }

      await this.updateWorkflowInDatabase(workflow);
      console.log('SUCCESS: NeuroSense analysis completed for workflow:', workflowId);

    } catch (error) {
      workflow.steps.neuroSenseAnalysis.status = 'failed';
      workflow.steps.neuroSenseAnalysis.error = error.message;
      await this.updateWorkflowInDatabase(workflow);
      throw error;
    }
  }

  /**
   * Step 4: Generate care plan
   */
  async executeCarePlanGeneration(workflowId, patientInfo) {
    const workflow = this.workflows.get(workflowId);
    workflow.steps.carePlanGeneration.status = 'processing';
    workflow.steps.carePlanGeneration.startedAt = new Date().toISOString();
    await this.updateWorkflowInDatabase(workflow);

    try {
      // Update report progress - Care plan generation started
      const reportId = workflow.results.reportId;
      if (reportId) {
        try {
          const currentReport = await DatabaseService.findById('reports', reportId);
          await DatabaseService.update('reports', reportId, {
            status: 'processing',
            report_data: {
              ...currentReport.report_data,
              processing_status: 'careplan_generating',
              processing_step: 'Generating personalized care plan',
              progress: 90
            },
            updated_at: new Date().toISOString()
          });
        } catch (error) {
          console.warn('WARNING: Could not update report progress:', error.message);
        }
      }

      const neuroSenseResults = workflow.results.neuroSenseAnalysis;

      // Generate personalized care plan
      const carePlan = await NeuroSenseService.generateCarePlan(
        neuroSenseResults.riskAssessment,
        patientInfo
      );

      // Save care plan
      const carePlanData = {
        id: `careplan_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
        workflowId,
        patientId: patientInfo.id,
        clinicId: workflow.clinicId,
        neuroSenseReportId: neuroSenseResults.reportId,
        carePlan,
        createdAt: new Date().toISOString(),
        status: 'active'
      };

      await DatabaseService.add('care_plans', carePlanData);

      workflow.steps.carePlanGeneration.status = 'completed';
      workflow.steps.carePlanGeneration.completedAt = new Date().toISOString();
      workflow.results.carePlanGeneration = carePlanData;

      await this.updateWorkflowInDatabase(workflow);
      console.log('SUCCESS: Care plan generation completed for workflow:', workflowId);

    } catch (error) {
      workflow.steps.carePlanGeneration.status = 'failed';
      workflow.steps.carePlanGeneration.error = error.message;
      await this.updateWorkflowInDatabase(workflow);
      throw error;
    }
  }

  /**
   * Step 5: Finalize and save complete report
   */
  async executeReportFinalization(workflowId, clinicId, patientInfo) {
    const workflow = this.workflows.get(workflowId);
    workflow.steps.reportFinalization.status = 'processing';
    workflow.steps.reportFinalization.startedAt = new Date().toISOString();
    await this.updateWorkflowInDatabase(workflow);

    try {
      // Get the report ID created during file upload
      const reportId = workflow.results.reportId;

      // UPDATE existing report instead of creating new one
      if (reportId) {
        try {
          const currentReport = await DatabaseService.findById('reports', reportId);

          // Compile final report data with all components
          const finalReportData = {
            status: 'completed',
            report_data: {
              ...currentReport.report_data,
              // Processing results
              workflow_id: workflowId,
              type: 'complete_eeg_analysis',
              report_type: 'complete_eeg_analysis',
              original_file: workflow.results.fileUpload,
              qeeg_report: workflow.results.qeegProcessing?.report || null,
              neurosense_analysis: workflow.results.neuroSenseAnalysis || null,
              care_plan: workflow.results.carePlanGeneration?.carePlan || null,
              processing_workflow: {
                workflowId,
                totalProcessingTime: this.calculateProcessingTime(workflow),
                completedSteps: Object.keys(workflow.steps).length,
                qualityScore: this.calculateQualityScore(workflow)
              },
              // Final status
              processing_status: 'completed',
              processing_step: 'Analysis completed successfully',
              progress: 100,
              completed_at: new Date().toISOString()
            },
            updated_at: new Date().toISOString()
          };

          await DatabaseService.update('reports', reportId, finalReportData);
          console.log('SUCCESS: Report updated with complete analysis:', reportId);
        } catch (error) {
          console.error('ERROR: Failed to update final report:', error);
          throw error;
        }
      } else {
        // Fallback: Create new report if no reportId found (shouldn't happen)
        console.warn('WARNING: No reportId found in workflow, creating new report');
        const newReport = {
          // id will be auto-generated by database
          clinic_id: clinicId,
          patient_id: patientInfo.id,
          file_name: workflow.fileName || 'unknown',
          file_path: workflow.results.fileUpload?.storagePath || '',
          status: 'completed',
          report_data: {
            workflow_id: workflowId,
            type: 'complete_eeg_analysis',
            completed_at: new Date().toISOString()
          },
          created_at: new Date().toISOString(),
          updated_at: new Date().toISOString()
        };
        await DatabaseService.add('reports', newReport);
      }

      // Update patient status
      await this.updatePatientStatus(patientInfo.id, 'report_completed');

      // Update clinic usage
      await this.updateClinicUsage(clinicId);

      workflow.steps.reportFinalization.status = 'completed';
      workflow.steps.reportFinalization.completedAt = new Date().toISOString();
      workflow.status = 'completed';
      workflow.completedAt = new Date().toISOString();
      workflow.results.finalReport = { id: reportId, ...finalReportData };

      await this.updateWorkflowInDatabase(workflow);
      console.log('SUCCESS: Report finalization completed for workflow:', workflowId);

      // Notify completion
      this.notifyWorkflowCompletion(workflow, { id: reportId, ...finalReportData });

    } catch (error) {
      workflow.steps.reportFinalization.status = 'failed';
      workflow.steps.reportFinalization.error = error.message;
      await this.updateWorkflowInDatabase(workflow);
      throw error;
    }
  }

  /**
   * Get workflow status
   * @param {string} workflowId - Workflow identifier
   * @returns {Promise<Object>} Current workflow status
   */
  async getWorkflowStatus(workflowId) {
    try {
      // Check memory first
      if (this.workflows.has(workflowId)) {
        return this.workflows.get(workflowId);
      }

      // Load from database
      const workflow = await DatabaseService.findById('workflows', workflowId);
      if (workflow) {
        this.workflows.set(workflowId, workflow);
      }

      return workflow;
    } catch (error) {
      console.error('Failed to get workflow status:', error);
      return null;
    }
  }

  /**
   * Cancel workflow
   * @param {string} workflowId - Workflow to cancel
   */
  async cancelWorkflow(workflowId) {
    try {
      const workflow = this.workflows.get(workflowId);
      if (workflow && workflow.status !== 'completed') {
        workflow.status = 'cancelled';
        workflow.cancelledAt = new Date().toISOString();

        await this.updateWorkflowInDatabase(workflow);
        console.log(' Workflow cancelled:', workflowId);
      }
    } catch (error) {
      console.error('Failed to cancel workflow:', error);
    }
  }

  /**
   * Helper methods
   */
  async waitForQEEGCompletion(jobId, maxWaitTime = 300000) { // 5 minutes max
    const startTime = Date.now();

    while (Date.now() - startTime < maxWaitTime) {
      const status = await QEEGProService.checkProcessingStatus(jobId);

      if (status.status === 'completed') {
        return status;
      } else if (status.status === 'failed') {
        throw new Error(`qEEG processing failed: ${status.message}`);
      }

      // Wait 5 seconds before checking again
      await new Promise(resolve => setTimeout(resolve, 5000));
    }

    throw new Error('qEEG processing timeout');
  }

  calculateProcessingTime(workflow) {
    const start = new Date(workflow.startedAt);
    const end = new Date();
    return Math.round((end - start) / 1000); // seconds
  }

  calculateQualityScore(workflow) {
    let score = 100;

    // Deduct points for failed steps
    Object.values(workflow.steps).forEach(step => {
      if (step.status === 'failed') score -= 20;
    });

    // Deduct points for long processing time
    const processingTime = this.calculateProcessingTime(workflow);
    if (processingTime > 600) score -= 10; // More than 10 minutes

    return Math.max(0, score);
  }

  async updatePatientStatus(patientId, status) {
    try {
      await DatabaseService.update('patients', patientId, {
        lastReportStatus: status,
        lastReportDate: new Date().toISOString()
      });
    } catch (error) {
      console.error('Failed to update patient status:', error);
    }
  }

  async updateClinicUsage(clinicId) {
    try {
      const clinic = await DatabaseService.findById('clinics', clinicId);
      if (clinic) {
        await DatabaseService.update('clinics', clinicId, {
          reportsUsed: (clinic.reportsUsed || 0) + 1,
          lastReportDate: new Date().toISOString()
        });
      }
    } catch (error) {
      console.error('Failed to update clinic usage:', error);
    }
  }

  notifyWorkflowCompletion(workflow, finalReport) {
    // In a real implementation, this would send notifications
    console.log('EMAIL: Workflow completion notification:', {
      workflowId: workflow.id,
      patientName: workflow.patientName,
      reportId: finalReport.id,
      processingTime: this.calculateProcessingTime(workflow)
    });

    // Show success toast
    toast.success(`Report completed for ${workflow.patientName}`, {
      duration: 5000
    });
  }

  async markWorkflowAsFailed(workflowId, errorMessage) {
    try {
      const workflow = this.workflows.get(workflowId);
      if (workflow) {
        workflow.status = 'failed';
        workflow.error = errorMessage;
        workflow.failedAt = new Date().toISOString();
        await this.updateWorkflowInDatabase(workflow);

        toast.error(`Workflow failed: ${errorMessage}`);
      }
    } catch (error) {
      console.error('Failed to mark workflow as failed:', error);
    }
  }

  async saveWorkflowToDatabase(workflow) {
    try {
      await DatabaseService.add('workflows', workflow);
      console.log('SUCCESS: Workflow saved to database:', workflow.id);
    } catch (error) {
      // Workflow tracking is optional - continue even if database save fails
      console.warn('WARNING: Could not save workflow to database (table may not exist yet):', error.message);
      console.log('INFO: Workflow will continue processing without database tracking');
    }
  }

  async updateWorkflowInDatabase(workflow) {
    try {
      await DatabaseService.update('workflows', workflow.id, workflow);
      console.log('SUCCESS: Workflow updated in database:', workflow.id);
    } catch (error) {
      // Workflow tracking is optional - continue even if database update fails
      // Don't log as error, just info - this is expected if workflows table doesn't exist
      if (error.message && error.message.includes('0 rows')) {
        console.log('INFO: Workflow not in database (table may not exist), skipping update');
      } else {
        console.warn('WARNING: Could not update workflow in database:', error.message);
      }
    }
  }

  /**
   * Get all workflows for a clinic
   * @param {string} clinicId - Clinic identifier
   * @returns {Promise<Array>} List of workflows
   */
  async getClinicWorkflows(clinicId) {
    try {
      const workflows = await DatabaseService.get('workflows');
      return workflows.filter(w => w.clinicId === clinicId)
                     .sort((a, b) => new Date(b.startedAt) - new Date(a.startedAt));
    } catch (error) {
      console.error('Failed to get clinic workflows:', error);
      return [];
    }
  }
}

export default new ReportWorkflowService();