const fs = require('fs');
const path = require('path');
const crypto = require('crypto');
const { GoogleGenerativeAI } = require('@google/generative-ai');
const pdfParse = require('pdf-parse'); // Kept for legacy/fallback support only
const XLSX = require('xlsx');
const rateLimiter = require('./geminiRateLimiter'); // Shared rate limiter

// Initialize Gemini AI client
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
let geminiModel = null;

// Debug: Log Gemini API configuration
console.log('\n===== GEMINI API CONFIGURATION =====');
console.log(`   Gemini key present: ${!!process.env.GEMINI_API_KEY}`);
console.log(`   Gemini key length: ${process.env.GEMINI_API_KEY?.length || 0}`);
console.log('====================================\n');

// In-memory cache for PDF extraction results (ensures deterministic behavior)
// Key: PDF MD5 hash ‚Üí Value: Extracted QEEG data
const extractionCache = new Map();

// Cache statistics for monitoring
const cacheStats = {
  hits: 0,
  misses: 0,
  totalExtractions: 0
};

class QEEGParser {
  /**
   * Fetch available Gemini models that support generateContent
   * @returns {Promise<Array>} List of available models
   */
  static async fetchAvailableModels() {
    try {
      console.log('üîç Fetching available Gemini models...');

      const response = await fetch(
        `https://generativelanguage.googleapis.com/v1/models?key=${process.env.GEMINI_API_KEY}`
      );

      if (!response.ok) {
        throw new Error(`API returned ${response.status}: ${response.statusText}`);
      }

      const data = await response.json();

      // Filter models that support generateContent
      const supportedModels = (data.models || []).filter(model =>
        model.supportedGenerationMethods?.includes('generateContent')
      );

      console.log(`‚úÖ Found ${supportedModels.length} models that support generateContent:`);
      supportedModels.forEach(model => {
        console.log(`   - ${model.name}`);
      });

      return supportedModels;
    } catch (error) {
      console.error('‚ùå Failed to fetch models:', error.message);
      return [];
    }
  }

  /**
   * Select best available model from list
   * @param {Array} models - List of available models
   * @returns {string|null} Model name to use
   */
  static selectBestModel(models) {
    if (!models || models.length === 0) return null;

    // Priority: flash models (fastest) > pro models > any other
    const preferences = ['flash', 'pro'];

    for (const preference of preferences) {
      const found = models.find(m =>
        m.name.toLowerCase().includes(preference)
      );
      if (found) {
        console.log(`‚úÖ Selected model: ${found.name}`);
        return found.name;
      }
    }

    // Fallback to first available
    console.log(`‚úÖ Using first available model: ${models[0].name}`);
    return models[0].name;
  }

  /**
   * Validate Gemini API key is configured and appears valid
   * @throws {Error} if API key is missing or invalid format
   */
  static validateAPIKey() {
    const apiKey = process.env.GEMINI_API_KEY;

    // Check if key exists
    if (!apiKey || apiKey.trim() === '') {
      const error = new Error('GEMINI_API_KEY environment variable is not set');
      error.code = 'MISSING_API_KEY';
      throw error;
    }

    // Check if key is placeholder
    if (apiKey === 'your-gemini-api-key-here' || apiKey.includes('placeholder')) {
      const error = new Error('GEMINI_API_KEY is set to placeholder value. Please configure a valid Gemini API key.');
      error.code = 'INVALID_API_KEY';
      throw error;
    }

    console.log('‚úÖ Gemini API key validation passed');
    return true;
  }

  /**
   * Test Gemini API connection with a simple request
   * @returns {Promise<boolean>} true if connection successful
   * @throws {Error} if connection fails
   */
  static async testAPIConnection() {
    try {
      this.validateAPIKey();

      console.log('üîå Testing Gemini API connection...');

      if (!geminiModel) {
        console.log('üîë API Key check:', process.env.GEMINI_API_KEY ? 'Present' : 'MISSING');

        // Fetch available models dynamically
        const availableModels = await this.fetchAvailableModels();

        if (availableModels.length === 0) {
          throw new Error('No Gemini models available. Check your API key at https://aistudio.google.com/apikey');
        }

        // Select best model
        const modelName = this.selectBestModel(availableModels);

        if (!modelName) {
          throw new Error('Could not select a valid model');
        }

        // Initialize model with full path
        console.log(`üîß Initializing model: ${modelName}`);
        geminiModel = genAI.getGenerativeModel({ model: modelName });

        // Test it with simple call
        console.log('üìû Testing model with simple call...');
        const testResult = await geminiModel.generateContent('Hello');
        await testResult.response;
        console.log('‚úÖ Model initialized and tested successfully');
      }

      const result = await geminiModel.generateContent('Reply with OK');
      const response = await result.response;
      const text = response.text();

      if (text) {
        console.log('‚úÖ Gemini API connection successful');
        return true;
      } else {
        throw new Error('Gemini API returned unexpected response');
      }

    } catch (error) {
      console.error('‚ùå Gemini API connection test failed:', error.message);
      const enhancedError = new Error(`Gemini API connection test failed: ${error.message}`);
      enhancedError.code = 'API_CONNECTION_FAILED';
      enhancedError.originalError = error;
      throw enhancedError;
    }
  }

  /**
   * Detect report type (raw power values or Z-scores)
   * @param {Object} file - Multer file object
   * @returns {Promise<string>} 'raw' or 'zscore'
   */
  static async detectReportType(file) {
    try {
      console.log(`üîç Detecting report type for: ${file.originalname}`);

      const dataBuffer = fs.readFileSync(file.path);
      const pdfData = await pdfParse(dataBuffer);
      const text = pdfData.text.toLowerCase();

      // Keyword detection
      const zscoreKeywords = ['z-score', 'z score', 'z =', 'z=', 'standard deviation', 'sd from mean'];
      const rawKeywords = ['absolute power (Œºv¬≤)', 'absolute power (uv¬≤)', 'relative power (%)', 'Œºv¬≤', 'uv¬≤'];

      let zscoreCount = 0;
      let rawCount = 0;

      // Count keyword occurrences
      zscoreKeywords.forEach(keyword => {
        const matches = (text.match(new RegExp(keyword, 'g')) || []).length;
        zscoreCount += matches;
      });

      rawKeywords.forEach(keyword => {
        const matches = (text.match(new RegExp(keyword, 'g')) || []).length;
        rawCount += matches;
      });

      console.log(`   Z-score keywords found: ${zscoreCount}`);
      console.log(`   Raw power keywords found: ${rawCount}`);

      // Decision logic
      if (zscoreCount > rawCount && zscoreCount >= 3) {
        console.log(`‚úÖ Detected: Z-SCORE report`);
        return 'zscore';
      } else if (rawCount > zscoreCount && rawCount >= 2) {
        console.log(`‚úÖ Detected: RAW POWER report`);
        return 'raw';
      } else if (zscoreCount > 0 && rawCount > 0) {
        // Mixed report - check for table structure
        if (text.includes('z-score table') || text.includes('z score table')) {
          console.log(`‚ö†Ô∏è Mixed report detected - preferring Z-SCORE`);
          return 'zscore';
        } else {
          console.log(`‚ö†Ô∏è Mixed report detected - preferring RAW POWER`);
          return 'raw';
        }
      } else {
        // Fallback: assume raw if unclear
        console.warn(`‚ö†Ô∏è Could not clearly detect report type - defaulting to RAW POWER`);
        return 'raw';
      }

    } catch (error) {
      console.error(`‚ùå Error detecting report type for ${file.originalname}:`, error.message);
      // Safe default
      console.warn(`   Defaulting to RAW POWER mode`);
      return 'raw';
    }
  }

  /**
   * Main method to parse uploaded files
   * @param {Object} eyesOpenFile - Multer file object for Eyes Open data
   * @param {Object} eyesClosedFile - Multer file object for Eyes Closed data
   * @returns {Object} Parsed QEEG data
   */
  static async parse(eyesOpenFile, eyesClosedFile) {
    try {
      console.log('\nüìÑ === QEEG File Parsing Started ===');
      console.log('  - Eyes Open:', eyesOpenFile?.originalname);
      console.log('  - Eyes Closed:', eyesClosedFile?.originalname);

      // STEP 1: Detect report types
      console.log('\nüîç STEP 1: Detecting report types...');
      const eoReportType = await this.detectReportType(eyesOpenFile);
      const ecReportType = await this.detectReportType(eyesClosedFile);

      console.log(`\nüìä Detection Results:`);
      console.log(`  - Eyes Open: ${eoReportType.toUpperCase()}`);
      console.log(`  - Eyes Closed: ${ecReportType.toUpperCase()}`);

      // STEP 2: Validate matching types
      console.log('\n‚úì STEP 2: Validating report type consistency...');
      if (eoReportType !== ecReportType) {
        const error = new Error(
          `‚ùå Mismatched report types detected!\n\n` +
          `Eyes Open is ${eoReportType.toUpperCase()}, but Eyes Closed is ${ecReportType.toUpperCase()}.\n\n` +
          `Both files must be the same type (either both RAW POWER or both Z-SCORE reports).\n` +
          `Please upload matching report types and try again.`
        );
        error.code = 'REPORT_TYPE_MISMATCH';
        throw error;
      }

      const reportType = eoReportType;
      console.log(`‚úÖ Report type validated: ${reportType.toUpperCase()} mode\n`);

      // STEP 3: Determine file formats (pdf, csv, excel)
      console.log('üìÅ STEP 3: Determining file formats...');
      const eoFileType = this.getFileType(eyesOpenFile.originalname);
      const ecFileType = this.getFileType(eyesClosedFile.originalname);
      console.log(`  - Eyes Open: ${eoFileType}`);
      console.log(`  - Eyes Closed: ${ecFileType}\n`);

      // STEP 4: Parse each file with appropriate method
      console.log('üìñ STEP 4: Extracting data from files...');
      const eyesOpenData = await this.parseFile(eyesOpenFile, eoFileType, 'EO', reportType);
      const eyesClosedData = await this.parseFile(eyesClosedFile, ecFileType, 'EC', reportType);

      // STEP 5: Combine data with metadata
      console.log('\nüîó STEP 5: Combining data...');
      const combinedData = {
        EO: eyesOpenData,
        EC: eyesClosedData,
        dataType: reportType // Add metadata
      };

      console.log(`‚úÖ QEEG files parsed successfully in ${reportType.toUpperCase()} mode`);
      console.log('=== QEEG File Parsing Completed ===\n');
      return combinedData;

    } catch (error) {
      console.error('\n‚ùå === QEEG File Parsing Failed ===');
      console.error('Error:', error.message);
      if (error.code === 'REPORT_TYPE_MISMATCH') {
        // Re-throw mismatch errors with original message
        throw error;
      } else {
        throw new Error(`Failed to parse QEEG files: ${error.message}`);
      }
    }
  }

  /**
   * Determine file type from filename
   */
  static getFileType(filename) {
    const ext = path.extname(filename).toLowerCase();
    if (ext === '.pdf') return 'pdf';
    if (ext === '.csv') return 'csv';
    if (ext === '.xlsx' || ext === '.xls') return 'excel';
    throw new Error(`Unsupported file type: ${ext}`);
  }

  /**
   * Parse a single file based on its type
   */
  static async parseFile(file, fileType, condition, reportType = 'raw') {
    if (fileType === 'pdf') {
      return await this.parsePDF(file, condition, reportType);
    } else if (fileType === 'csv') {
      return this.parseCSV(file);
    } else if (fileType === 'excel') {
      return this.parseExcel(file);
    }
    throw new Error(`Unknown file type: ${fileType}`);
  }

  /**
   * Get extraction prompt for Gemini Multimodal (Direct PDF approach)
   * @param {string} condition - 'EO' or 'EC'
   * @param {string} reportType - 'raw' or 'zscore'
   * @returns {string} Extraction prompt (no PDF text needed)
   */
  static getExtractionPromptForMultimodal(condition, reportType) {
    const conditionName = condition === 'EO' ? 'Eyes Open' : 'Eyes Closed';

    if (reportType === 'zscore') {
      return `### Role
You are an expert Data Extraction & Structuring Assistant specialized in processing medical qEEGPro reports. Your sole task is to analyze the provided PDF document and extract statistical EEG data into a strict, machine-readable JSON format.

### Task Overview
You will analyze a qEEGPro report PDF for ${conditionName} condition. You must locate and extract data tables specifically from **Page 13** and **Page 24** of this document.

---

### Target Data & Extraction Rules

#### 1. Page 13: Alpha Peak Data
* **Target Table:** Look for the table titled **"Z-scored Alpha Peak"** or a table containing the headers "APF" and "Z-APF".
* **Data Points to Extract:**
    * **Channel Name (Ch):** (e.g., FP1, FP2, Fz, etc.)
    * **Alpha Peak Frequency (APF):** The value in Hz.
    * **Z-Score (Z-APF):** The statistical deviation value.
* **Correction Logic:** If a channel is missing a Z-score or APF value due to OCR errors, leave the value as \`null\`.

#### 2. Page 24: Absolute & Relative Power Data with Z-Scores
* **Target Table 1:** Look for **"Z-scored FFT Absolute Power"** (headers often include "Absolute Power (uV¬≤)" or just frequency bands like Delta, Theta, etc.).
* **Target Table 2:** Look for **"Relative Power"** (headers often include "Relative Power (%)").
* **Data Points to Extract:** For every channel, extract the **Raw Value** and **Z-Score** for the following five frequency bands:
    * **Delta** (Œ¥) - 0.5-4 Hz, 1-4 Hz
    * **Theta** (Œ∏) - 4-8 Hz
    * **Alpha** (Œ±) - 8-13 Hz
    * **Beta** (Œ≤) - 13-30 Hz
    * **hiBeta** (High Beta / Œ≤Œ≤) - 20-30 Hz, 25-30 Hz, 30-50 Hz

---

### Critical Parsing Instructions (Must Follow)

#### 1. Handle Merged Rows (High Priority)
PDF text extraction often causes two rows to merge into a single line. You must detect this pattern and separate them into two distinct channel entries.

* **Detection:** If a line contains two channel names (e.g., "F7 F3") or an unusual number of values (e.g., 20 numbers instead of 10), it is a merged row.
* **Resolution Strategy:**
    * Identify the two channel names at the start (e.g., "F7" and "F3").
    * The first half of the numeric values belong to the first channel (F7).
    * The second half of the numeric values belong to the second channel (F3).

#### 2. Data Typing & Formatting
* **Numbers:** Extract the **actual numerical values** found in the text. Convert them to **floating-point numbers**. Do not return strings.
* **Channel Names:** Keep as strings (e.g., "FP1", "T3").
* **Dynamic Extraction:** Do not invent data. Only output values present in the provided PDF.
* **Preserve Exact Values:** Copy numbers exactly as they appear - don't round or modify values.

#### 3. Channels to Extract (19 EEG channels)
FP1, FP2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2

---

### Output Schema (Strict JSON)

You must output **only** a valid JSON object matching this structure exactly. Do NOT include markdown formatting (like \`\`\`json). Just pure JSON.

{
  "file_metadata": {
    "report_type": "qEEGPro",
    "condition": "${conditionName}",
    "page_extracted": [13, 24]
  },
  "alpha_peak_data": [
    {
      "channel": "FP1",
      "apf": 8.3,
      "z_score": -1.2
    }
    // ... Repeat for ALL channels found on Page 13
  ],
  "absolute_power_data": [
    {
      "channel": "FP1",
      "delta": { "value": 691.8, "z_score": 1.2 },
      "theta": { "value": 160.9, "z_score": 1.8 },
      "alpha": { "value": 66.4, "z_score": 1.1 },
      "beta":  { "value": 73.1, "z_score": 1.0 },
      "hibeta": { "value": 151.2, "z_score": 0.5 }
    }
    // ... Repeat for ALL channels found in Absolute Power table on Page 24
  ],
  "relative_power_data": [
    {
      "channel": "FP1",
      "delta": { "value": 40.0, "z_score": 0.6 },
      "theta": { "value": 9.3, "z_score": 1.0 },
      "alpha": { "value": 3.8, "z_score": 0.1 },
      "beta":  { "value": 4.2, "z_score": 0.2 },
      "hibeta": { "value": 8.7, "z_score": -0.2 }
    }
    // ... Repeat for ALL channels found in Relative Power table on Page 24
  ]
}

**CRITICAL OUTPUT RULES:**
- Return ONLY the JSON object (no markdown, no explanations, no code blocks)
- Just pure JSON starting with { and ending with }
- No \`\`\`json markers
- No text before or after the JSON
- All numeric values must be floating-point numbers, not strings
- Extract ALL channels found in the tables - do not skip any
- For Relative Power, values should sum to approximately 100% per channel`;

    } else {
      // RAW POWER mode (reportType === 'raw')
      return `### Role
You are an expert Data Extraction & Structuring Assistant specialized in processing medical qEEGPro reports. Your sole task is to analyze the provided PDF document and extract statistical EEG data into a strict, machine-readable JSON format.

### Task Overview
You will analyze a qEEGPro report PDF for ${conditionName} condition. You must locate and extract data tables specifically from **Page 13** and **Page 24** of this document.

---

### Target Data & Extraction Rules

#### 1. Page 13: Alpha Peak Data
* **Target Table:** Look for the table titled **"Alpha Peak"** or a table containing the header "APF".
* **Data Points to Extract:**
    * **Channel Name (Ch):** (e.g., FP1, FP2, Fz, etc.)
    * **Alpha Peak Frequency (APF):** The value in Hz.

#### 2. Page 24: Absolute & Relative Power Data
* **Target Table 1:** Look for **"FFT Absolute Power"** or **"Absolute Power"** (headers often include "Absolute Power (uV¬≤)").
* **Target Table 2:** Look for **"Relative Power"** (headers often include "Relative Power (%)").
* **Data Points to Extract:** For every channel, extract the **Raw Value** (NO z-scores) for the following five frequency bands:
    * **Delta** (Œ¥) - 0.5-4 Hz, 1-4 Hz
    * **Theta** (Œ∏) - 4-8 Hz
    * **Alpha** (Œ±) - 8-13 Hz
    * **Beta** (Œ≤) - 13-30 Hz
    * **hiBeta** (High Beta / Œ≤Œ≤) - 20-30 Hz, 25-30 Hz, 30-50 Hz

---

### Critical Parsing Instructions (Must Follow)

#### 1. Handle Merged Rows (High Priority)
PDF text extraction often causes two rows to merge into a single line. You must detect this pattern and separate them into two distinct channel entries.

#### 2. Data Typing & Formatting
* **Numbers:** Extract the **actual numerical values** found in the text. Convert them to **floating-point numbers**. Do not return strings.
* **Channel Names:** Keep as strings (e.g., "FP1", "T3").
* **Dynamic Extraction:** Do not invent data. Only output values present in the provided PDF.

#### 3. Channels to Extract (19 EEG channels)
FP1, FP2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2

---

### Output Schema (Strict JSON)

You must output **only** a valid JSON object matching this structure exactly. Do NOT include markdown formatting (like \`\`\`json). Just pure JSON.

{
  "file_metadata": {
    "report_type": "qEEGPro",
    "condition": "${conditionName}",
    "page_extracted": [13, 24]
  },
  "alpha_peak_data": [
    {
      "channel": "FP1",
      "apf": 8.3
    }
    // ... Repeat for ALL channels found on Page 13
  ],
  "absolute_power_data": [
    {
      "channel": "FP1",
      "delta": { "value": 691.8 },
      "theta": { "value": 160.9 },
      "alpha": { "value": 66.4 },
      "beta":  { "value": 73.1 },
      "hibeta": { "value": 151.2 }
    }
    // ... Repeat for ALL channels found in Absolute Power table on Page 24
  ],
  "relative_power_data": [
    {
      "channel": "FP1",
      "delta": { "value": 40.0 },
      "theta": { "value": 9.3 },
      "alpha": { "value": 3.8 },
      "beta":  { "value": 4.2 },
      "hibeta": { "value": 8.7 }
    }
    // ... Repeat for ALL channels found in Relative Power table on Page 24
  ]
}

**CRITICAL OUTPUT RULES:**
- Return ONLY the JSON object (no markdown, no explanations, no code blocks)
- Just pure JSON starting with { and ending with }
- No \`\`\`json markers
- No text before or after the JSON
- All numeric values must be floating-point numbers, not strings
- Extract ALL channels found in the tables - do not skip any
- For Relative Power, values should sum to approximately 100% per channel`;
    }
  }

  /**
   * LEGACY: Get extraction prompt based on report type (with PDF text)
   * Kept for backward compatibility
   * @param {string} condition - 'EO' or 'EC'
   * @param {string} reportType - 'raw' or 'zscore'
   * @param {string} pdfText - PDF text content
   * @returns {string} Extraction prompt
   */
  static getExtractionPrompt(condition, reportType, pdfText) {
    const conditionName = condition === 'EO' ? 'Eyes Open' : 'Eyes Closed';

    if (reportType === 'zscore') {
      // Z-SCORE extraction prompt
      return `You are a QEEG Z-score data extraction expert. Extract Z-score values from this ${conditionName} QEEG report.

**IMPORTANT**: Z-scores represent standard deviations from the mean. They typically range from -3 to +3.
- Negative values = below average (lower than normal)
- Zero (0) = average (normal)
- Positive values = above average (higher than normal)

Look for tables labeled with "Z-score", "Z score", "Z", or "Standard Deviation" in the headers.

Extract Z-score values for these EEG channels: FP1, FP2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2

For each channel, extract Z-scores for these frequency bands:
- Delta (1-4 Hz)
- Theta (4-8 Hz)
- Alpha (8-13 Hz)
- Beta (13-30 Hz)
- HiBeta / High Beta (20-30 Hz)

Also extract:
- Alpha Peak Frequency (Hz) and its Z-score if available

If you cannot find Z-scores for a particular channel or band, use 0.0 as the default value.

**CRITICAL**: Your response must be ONLY the JSON object. Do NOT include:
- No markdown formatting (no \`\`\`json or \`\`\`)
- No explanations before or after
- No comments
- Just pure JSON that starts with { and ends with }

Return ONLY this EXACT JSON format:
{
  "zscores": {
    "absolute": {
      "Fz": { "Delta": 0.0, "Theta": 0.0, "Alpha": 0.0, "Beta": 0.0, "HiBeta": 0.0 },
      "Cz": { "Delta": 0.0, "Theta": 0.0, "Alpha": 0.0, "Beta": 0.0, "HiBeta": 0.0 },
      "Pz": { "Delta": 0.0, "Theta": 0.0, "Alpha": 0.0, "Beta": 0.0, "HiBeta": 0.0 },
      "F3": { "Delta": 0.0, "Theta": 0.0, "Alpha": 0.0, "Beta": 0.0, "HiBeta": 0.0 },
      "F4": { "Delta": 0.0, "Theta": 0.0, "Alpha": 0.0, "Beta": 0.0, "HiBeta": 0.0 },
      "C3": { "Delta": 0.0, "Theta": 0.0, "Alpha": 0.0, "Beta": 0.0, "HiBeta": 0.0 },
      "C4": { "Delta": 0.0, "Theta": 0.0, "Alpha": 0.0, "Beta": 0.0, "HiBeta": 0.0 },
      "P3": { "Delta": 0.0, "Theta": 0.0, "Alpha": 0.0, "Beta": 0.0, "HiBeta": 0.0 },
      "P4": { "Delta": 0.0, "Theta": 0.0, "Alpha": 0.0, "Beta": 0.0, "HiBeta": 0.0 }
    },
    "relative": {
      "Fz": { "Delta": 0.0, "Theta": 0.0, "Alpha": 0.0, "Beta": 0.0, "HiBeta": 0.0 },
      "Cz": { "Delta": 0.0, "Theta": 0.0, "Alpha": 0.0, "Beta": 0.0, "HiBeta": 0.0 },
      "Pz": { "Delta": 0.0, "Theta": 0.0, "Alpha": 0.0, "Beta": 0.0, "HiBeta": 0.0 },
      "F3": { "Delta": 0.0, "Theta": 0.0, "Alpha": 0.0, "Beta": 0.0, "HiBeta": 0.0 },
      "F4": { "Delta": 0.0, "Theta": 0.0, "Alpha": 0.0, "Beta": 0.0, "HiBeta": 0.0 },
      "C3": { "Delta": 0.0, "Theta": 0.0, "Alpha": 0.0, "Beta": 0.0, "HiBeta": 0.0 },
      "C4": { "Delta": 0.0, "Theta": 0.0, "Alpha": 0.0, "Beta": 0.0, "HiBeta": 0.0 },
      "P3": { "Delta": 0.0, "Theta": 0.0, "Alpha": 0.0, "Beta": 0.0, "HiBeta": 0.0 },
      "P4": { "Delta": 0.0, "Theta": 0.0, "Alpha": 0.0, "Beta": 0.0, "HiBeta": 0.0 }
    }
  },
  "special": {
    "alphaPeak": 10.0,
    "alphaPeakZscore": 0.0
  }
}

PDF Content (Pages 13 & 24):
${pdfText}`;

    } else {
      // qEEGPro-specific extraction prompt for Pages 13 & 24
      return `### Role
You are an expert Data Extraction & Structuring Assistant specialized in processing medical qEEGPro reports. Your sole task is to analyze the provided unstructured text from a specific patient's PDF report and extract their unique statistical EEG data into a strict, machine-readable JSON format.

### Task Overview
You will be provided with the text content of a unique qEEGPro report for ${conditionName} condition. You must locate and extract data tables specifically from **Page 13** and **Page 24** of this specific document.

---

### Target Data & Extraction Rules

#### 1. Page 13: Alpha Peak Data
* **Target Table:** Look for the table titled **"Z-scored Alpha Peak"** or a table containing the headers "APF" and "Z-APF".
* **Data Points to Extract:**
    * **Channel Name (Ch):** (e.g., FP1, FP2, Fz, etc.)
    * **Alpha Peak Frequency (APF):** The value in Hz.
    * **Z-Score (Z-APF):** The statistical deviation value.
* **Correction Logic:** If a channel is missing a Z-score or APF value due to OCR errors, leave the value as \`null\`.

#### 2. Page 24: Absolute & Relative Power Data
* **Target Table 1:** Look for **"Z-scored FFT Absolute Power"** (headers often include "Absolute Power (uV¬≤)" or just frequency bands like Delta, Theta, etc.).
* **Target Table 2:** Look for **"Relative Power"** (headers often include "Relative Power (%)").
* **Data Points to Extract:** For every channel, extract the **Raw Value** and **Z-Score** for the following five frequency bands:
    * **Delta** (Œ¥) - 0.5-4 Hz, 1-4 Hz
    * **Theta** (Œ∏) - 4-8 Hz
    * **Alpha** (Œ±) - 8-13 Hz
    * **Beta** (Œ≤) - 13-30 Hz
    * **hiBeta** (High Beta / Œ≤Œ≤) - 20-30 Hz, 25-30 Hz, 30-50 Hz

---

### Critical Parsing Instructions (Must Follow)

#### 1. Handle Merged Rows (High Priority)
PDF text extraction often causes two rows to merge into a single line. You must detect this pattern and separate them into two distinct channel entries.

* **Detection:** If a line contains two channel names (e.g., "F7 F3") or an unusual number of values (e.g., 20 numbers instead of 10), it is a merged row.
* **Resolution Strategy:**
    * Identify the two channel names at the start (e.g., "F7" and "F3").
    * The first half of the numeric values belong to the first channel (F7).
    * The second half of the numeric values belong to the second channel (F3).
    * *Example Input:* "F7 F3 32.4 42.5 1.1 1.6..."
    * *Example Output:* F7 gets 32.4 (Value) and 1.1 (Z-score); F3 gets 42.5 (Value) and 1.6 (Z-score).

#### 2. Data Typing & Formatting
* **Numbers:** Extract the **actual numerical values** found in the text. Convert them to **floating-point numbers**. Do not return strings.
* **Channel Names:** Keep as strings (e.g., "FP1", "T3").
* **Dynamic Extraction:** Do not invent data. Only output values present in the provided text.
* **Preserve Exact Values:** Copy numbers exactly as they appear - don't round or modify values.

#### 3. Channels to Extract (19 EEG channels)
FP1, FP2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2

---

### Output Schema (Strict JSON)

You must output **only** a valid JSON object matching this structure exactly. Do NOT include markdown formatting (like \`\`\`json). Just pure JSON.

{
  "file_metadata": {
    "report_type": "qEEGPro",
    "condition": "${conditionName}",
    "page_extracted": [13, 24]
  },
  "alpha_peak_data": [
    {
      "channel": "FP1",
      "apf": 8.3,
      "z_score": -1.2
    }
    // ... Repeat for ALL channels found on Page 13
  ],
  "absolute_power_data": [
    {
      "channel": "FP1",
      "delta": { "value": 691.8, "z_score": 1.2 },
      "theta": { "value": 160.9, "z_score": 1.8 },
      "alpha": { "value": 66.4, "z_score": 1.1 },
      "beta":  { "value": 73.1, "z_score": 1.0 },
      "hibeta": { "value": 151.2, "z_score": 0.5 }
    }
    // ... Repeat for ALL channels found in Absolute Power table on Page 24
  ],
  "relative_power_data": [
    {
      "channel": "FP1",
      "delta": { "value": 40.0, "z_score": 0.6 },
      "theta": { "value": 9.3, "z_score": 1.0 },
      "alpha": { "value": 3.8, "z_score": 0.1 },
      "beta":  { "value": 4.2, "z_score": 0.2 },
      "hibeta": { "value": 8.7, "z_score": -0.2 }
    }
    // ... Repeat for ALL channels found in Relative Power table on Page 24
  ]
}

**CRITICAL OUTPUT RULES:**
- Return ONLY the JSON object (no markdown, no explanations, no code blocks)
- Just pure JSON starting with { and ending with }
- No \`\`\`json markers
- No text before or after the JSON
- All numeric values must be floating-point numbers, not strings
- Extract ALL channels found in the tables - do not skip any
- For Relative Power, values should sum to approximately 100% per channel

---

### PDF Content (Pages 13 & 24):

${pdfText}`;
    }
  }

  /**
   * Extract ONLY pages 13 and 24 from PDF (qEEGPro specific pages)
   * Uses PDF.js (Mozilla) for MAXIMUM reliability with complex medical PDFs
   * @param {Buffer} dataBuffer - PDF file buffer
   * @returns {Promise<string>} Extracted text from pages 13 and 24
   */
  static async extractSpecificPages(dataBuffer) {
    console.log(`\n  üìÑ ========================================`);
    console.log(`  üìÑ EXTRACTING PDF PAGES 13 & 24`);
    console.log(`  üìÑ Using PDF.js (Mozilla) for Complex PDFs`);
    console.log(`  üìÑ ========================================\n`);

    try {
      // üöÄ LOAD PDF using PDF.js
      console.log(`  üîß Loading PDF with PDF.js...`);
      const loadingTask = pdfjsLib.getDocument({
        data: new Uint8Array(dataBuffer),
        standardFontDataUrl: null,
        useSystemFonts: true
      });

      const pdfDoc = await loadingTask.promise;
      const totalPages = pdfDoc.numPages;

      console.log(`\n  ‚úÖ PDF LOADED SUCCESSFULLY:`);
      console.log(`     üìñ Total Pages: ${totalPages}`);

      // Validate PDF has required pages
      if (totalPages < 24) {
        console.error(`\n  ‚ùå ERROR: PDF has only ${totalPages} pages, but we need page 24!`);
        console.warn(`     Will try to extract available pages...`);
      }

      // üéØ Extract pages 13 and 24
      const targetPages = [13, 24];
      const extractedPages = [];
      let totalChars = 0;

      for (const pageNum of targetPages) {
        if (pageNum > totalPages) {
          console.warn(`\n  ‚ö†Ô∏è  Page ${pageNum} does not exist (PDF has ${totalPages} pages)`);
          continue;
        }

        console.log(`\n  üìñ Extracting page ${pageNum} with PDF.js...`);

        try {
          // Get page
          const page = await pdfDoc.getPage(pageNum);

          // Extract text content
          const textContent = await page.getTextContent();

          // Combine all text items
          let pageText = '';
          textContent.items.forEach((item) => {
            if (item.str) {
              pageText += item.str;
              // Add space or newline based on position
              if (item.hasEOL) {
                pageText += '\n';
              } else {
                pageText += ' ';
              }
            }
          });

          // Clean up extra spaces
          pageText = pageText.replace(/\s+/g, ' ').replace(/\s*\n\s*/g, '\n').trim();

          console.log(`     ‚úÖ Extracted page ${pageNum}:`);
          console.log(`        - Characters: ${pageText.length}`);
          console.log(`        - First 300 chars: ${pageText.substring(0, 300)}...`);

          totalChars += pageText.length;

          if (pageText && pageText.length > 50) {
            extractedPages.push(`\n=== PAGE ${pageNum} ===\n${pageText}\n`);
          } else {
            console.warn(`     ‚ö†Ô∏è  Page ${pageNum} has very little text (${pageText.length} chars)`);
            extractedPages.push(`\n=== PAGE ${pageNum} (LIMITED CONTENT) ===\n${pageText}\n`);
          }

        } catch (pageError) {
          console.error(`     ‚ùå Failed to extract page ${pageNum}:`, pageError.message);
          continue;
        }
      }

      // üö® CRITICAL VALIDATION: Check if we got enough text
      console.log(`\n  üìä VALIDATION:`);
      console.log(`     üìù Total Characters Extracted: ${totalChars}`);

      if (totalChars < 5000) {
        console.error(`\n  ‚ùå ERROR: PDF text is too short (${totalChars} chars)`);
        console.error(`     Expected: 20,000+ characters for text-based PDF`);
        console.error(`     Got: ${totalChars} characters`);
        console.error(`\n  ‚ö†Ô∏è  This PDF might be:`);
        console.error(`     1. Image-based (scanned) - Needs OCR (Tesseract)`);
        console.error(`     2. Pages 13 & 24 don't contain the data tables`);
        console.error(`     3. Data is in different pages`);
        console.warn(`\n  üîÑ FALLBACK: Extracting ALL pages and searching for tables...`);

        // FALLBACK: Extract all pages and search for table keywords
        return await this.extractAllPagesWithPdfJs(pdfDoc, totalPages);

      } else if (totalChars < 20000) {
        console.warn(`\n  ‚ö†Ô∏è  WARNING: PDF text is shorter than expected`);
        console.warn(`     Expected: 20,000+ characters`);
        console.warn(`     Got: ${totalChars} characters`);
        console.warn(`     Extraction may be incomplete`);
      } else {
        console.log(`\n  ‚úÖ VALIDATION PASSED: Got ${totalChars} characters (20,000+)`);
        console.log(`     This looks like valid text-based PDF!`);
      }

      // Combine extracted pages
      if (extractedPages.length === 0) {
        console.error(`\n  ‚ùå FAILED: Could not extract any pages!`);
        console.warn(`  üîÑ FALLBACK: Extracting all pages...`);
        return await this.extractAllPagesWithPdfJs(pdfDoc, totalPages);
      }

      const combinedText = extractedPages.join('\n\n');

      console.log(`\n  ‚úÖ ========================================`);
      console.log(`  ‚úÖ EXTRACTION SUCCESSFUL`);
      console.log(`  ‚úÖ ========================================`);
      console.log(`     üìÑ Pages extracted: ${extractedPages.length}`);
      console.log(`     üìù Total characters: ${combinedText.length}`);
      console.log(`     ‚úÖ Ready to send to Gemini AI`);
      console.log(`\n  üìù Sample of extracted text (first 500 chars):`);
      console.log(`     ${combinedText.substring(0, 500).replace(/\n/g, '\n     ')}...\n`);

      return combinedText;

    } catch (error) {
      console.error(`\n  ‚ùå CRITICAL ERROR during PDF.js extraction:`, error.message);
      console.error(`     Stack trace:`, error.stack);

      // Final fallback: Try old pdf-parse
      try {
        console.log(`\n  üîÑ FALLBACK: Attempting pdf-parse...`);
        const fallbackData = await pdfParse(dataBuffer);
        console.log(`  ‚úÖ Fallback successful: ${fallbackData.text.length} characters`);
        return fallbackData.text;
      } catch (fallbackError) {
        console.error(`  ‚ùå FALLBACK FAILED:`, fallbackError.message);
        throw new Error(`Failed to extract PDF text: ${error.message}`);
      }
    }
  }

  /**
   * FALLBACK: Extract ALL pages with PDF.js and search for table keywords
   * @param {Object} pdfDoc - PDF.js document object
   * @param {number} totalPages - Total pages in PDF
   * @returns {Promise<string>} Extracted text
   */
  static async extractAllPagesWithPdfJs(pdfDoc, totalPages) {
    console.log(`\n  üîÑ FALLBACK: Extracting ALL ${totalPages} pages...`);

    let allText = '';
    const relevantPages = [];

    // Keywords to identify relevant pages
    const keywords = [
      'absolute power',
      'relative power',
      'alpha peak',
      'z-score',
      'delta', 'theta', 'alpha', 'beta',
      'fp1', 'fp2', 'fz', 'cz', 'pz'
    ];

    for (let pageNum = 1; pageNum <= totalPages; pageNum++) {
      try {
        const page = await pdfDoc.getPage(pageNum);
        const textContent = await page.getTextContent();

        let pageText = '';
        textContent.items.forEach((item) => {
          if (item.str) {
            pageText += item.str + (item.hasEOL ? '\n' : ' ');
          }
        });

        pageText = pageText.replace(/\s+/g, ' ').replace(/\s*\n\s*/g, '\n').trim();

        // Check if page contains relevant keywords
        const lowerText = pageText.toLowerCase();
        const hasKeywords = keywords.some(kw => lowerText.includes(kw));

        if (hasKeywords && pageText.length > 200) {
          console.log(`     ‚úÖ Found relevant data on page ${pageNum} (${pageText.length} chars)`);
          relevantPages.push(`\n=== PAGE ${pageNum} ===\n${pageText}\n`);
        }

        allText += pageText + '\n';

      } catch (pageError) {
        console.warn(`     ‚ö†Ô∏è  Failed to extract page ${pageNum}:`, pageError.message);
      }
    }

    console.log(`\n  üìä Extraction complete:`);
    console.log(`     - Total pages scanned: ${totalPages}`);
    console.log(`     - Relevant pages found: ${relevantPages.length}`);
    console.log(`     - Total characters: ${allText.length}`);

    // Return relevant pages if found, otherwise all text
    if (relevantPages.length > 0) {
      const combinedRelevant = relevantPages.join('\n\n');
      console.log(`     ‚úÖ Using ${relevantPages.length} relevant pages (${combinedRelevant.length} chars)`);
      return combinedRelevant;
    }

    console.log(`     ‚ö†Ô∏è  No relevant pages found, using all text (${allText.length} chars)`);
    return allText;
  }

  /**
   * LEGACY: Extract relevant sections using keyword search
   * Kept for backward compatibility
   * @param {string} fullText - Full PDF text
   * @returns {string} Extracted relevant sections
   */
  static extractRelevantPages(fullText) {
    console.log(`  üìÑ Using legacy keyword-based extraction...`);
    console.log(`  üìö Full text length: ${fullText.length} characters`);

    // Just return the full text for now, as we're using extractSpecificPages instead
    return fullText;
  }

  /**
   * Validate extracted QEEG data for completeness
   * @param {Object} data - Extracted QEEG data
   * @param {string} condition - 'EC' or 'EO'
   * @returns {Object} Validation result with isValid and missingFields
   */
  static validateExtractedData(data, condition) {
    console.log(`\n  üîç === VALIDATING EXTRACTED DATA (${condition}) ===`);

    const requiredChannels = ['Fz', 'Cz', 'Pz', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4'];
    const requiredBands = ['Delta', 'Theta', 'Alpha', 'Beta', 'HiBeta'];
    const missingFields = [];

    // Check if data structure exists
    if (!data || typeof data !== 'object') {
      return {
        isValid: false,
        missingFields: ['Complete data structure is missing'],
        error: 'No data extracted from PDF'
      };
    }

    // Check absolute power
    if (!data.absolute || typeof data.absolute !== 'object') {
      missingFields.push('absolute power section');
    } else {
      requiredChannels.forEach(channel => {
        if (!data.absolute[channel]) {
          missingFields.push(`absolute.${channel}`);
        } else {
          requiredBands.forEach(band => {
            const value = data.absolute[channel][band];
            if (value === null || value === undefined) {
              missingFields.push(`absolute.${channel}.${band}`);
            }
          });
        }
      });
    }

    // Check relative power
    if (!data.relative || typeof data.relative !== 'object') {
      missingFields.push('relative power section');
    } else {
      requiredChannels.forEach(channel => {
        if (!data.relative[channel]) {
          missingFields.push(`relative.${channel}`);
        } else {
          requiredBands.forEach(band => {
            const value = data.relative[channel][band];
            if (value === null || value === undefined) {
              missingFields.push(`relative.${channel}.${band}`);
            }
          });

          // Validate relative power sums to ~100%
          const sum = requiredBands.reduce((acc, band) => {
            return acc + (data.relative[channel][band] || 0);
          }, 0);

          if (sum < 90 || sum > 110) {
            missingFields.push(`relative.${channel} (sum=${sum.toFixed(1)}%, expected ~100%)`);
          }
        }
      });
    }

    // Check alpha peak
    if (!data.special || (!data.special.alphaPeak && !data.special.O1)) {
      missingFields.push('special.alphaPeak');
    }

    const isValid = missingFields.length === 0;

    console.log(`  üìä Validation Results:`);
    console.log(`     - Status: ${isValid ? '‚úÖ VALID' : '‚ùå INVALID'}`);
    console.log(`     - Missing fields: ${missingFields.length}`);

    if (!isValid) {
      console.log(`  ‚ùå Missing/Invalid Fields:`);
      missingFields.forEach(field => {
        console.log(`     - ${field}`);
      });
    }

    console.log(`  === END VALIDATION ===\n`);

    return {
      isValid,
      missingFields,
      error: isValid ? null : `Incomplete data extraction: ${missingFields.length} fields missing`
    };
  }

  /**
   * Calculate MD5 hash of PDF file for caching
   * @param {Buffer} dataBuffer - PDF file buffer
   * @returns {string} MD5 hash
   */
  static calculatePDFHash(dataBuffer) {
    return crypto.createHash('md5').update(dataBuffer).digest('hex');
  }

  /**
   * Normalize extracted value to consistent decimal places
   * Prevents precision-related variations
   * @param {number} value - The value to normalize
   * @param {number} decimalPlaces - Number of decimal places (default: 2)
   * @returns {number|null} Normalized value
   */
  static normalizeValue(value, decimalPlaces = 2) {
    if (value === null || value === undefined || isNaN(value)) {
      return null;
    }

    // Round to consistent decimal places
    const multiplier = Math.pow(10, decimalPlaces);
    return Math.round(value * multiplier) / multiplier;
  }

  /**
   * Normalize all values in extracted QEEG data
   * Ensures consistent precision across all measurements
   * @param {Object} extractedData - The raw extracted data
   * @returns {Object} Normalized data
   */
  static normalizeExtractedData(extractedData) {
    const normalized = JSON.parse(JSON.stringify(extractedData)); // Deep clone

    // Normalize absolute power values
    if (normalized.absolute) {
      Object.keys(normalized.absolute).forEach(channel => {
        Object.keys(normalized.absolute[channel]).forEach(band => {
          normalized.absolute[channel][band] =
            this.normalizeValue(normalized.absolute[channel][band], 2);
        });
      });
    }

    // Normalize relative power values
    if (normalized.relative) {
      Object.keys(normalized.relative).forEach(channel => {
        Object.keys(normalized.relative[channel]).forEach(band => {
          normalized.relative[channel][band] =
            this.normalizeValue(normalized.relative[channel][band], 2);
        });
      });
    }

    // Normalize special values (alpha peak, etc.)
    if (normalized.special) {
      Object.keys(normalized.special).forEach(key => {
        normalized.special[key] = this.normalizeValue(normalized.special[key], 2);
      });
    }

    // Normalize zscores if present (for z-score reports)
    if (normalized.zscores) {
      if (normalized.zscores.absolute) {
        Object.keys(normalized.zscores.absolute).forEach(channel => {
          Object.keys(normalized.zscores.absolute[channel]).forEach(band => {
            normalized.zscores.absolute[channel][band] =
              this.normalizeValue(normalized.zscores.absolute[channel][band], 2);
          });
        });
      }
      if (normalized.zscores.relative) {
        Object.keys(normalized.zscores.relative).forEach(channel => {
          Object.keys(normalized.zscores.relative[channel]).forEach(band => {
            normalized.zscores.relative[channel][band] =
              this.normalizeValue(normalized.zscores.relative[channel][band], 2);
          });
        });
      }
    }

    return normalized;
  }

  /**
   * Transform qEEGPro format to legacy format for backward compatibility
   * Converts array-based format to channel-object format
   * @param {Object} qeegProData - Data in qEEGPro format
   * @returns {Object} Data in legacy format
   */
  static transformQEEGProToLegacyFormat(qeegProData) {
    console.log('  üîÑ Transforming qEEGPro format to legacy format...');

    // Check if data is already in legacy format (has 'absolute' key)
    if (qeegProData.absolute || qeegProData.zscores) {
      console.log('  ‚ÑπÔ∏è  Data is already in legacy format, skipping transformation');
      return qeegProData;
    }

    const legacyFormat = {
      absolute: {},
      relative: {},
      special: {}
    };

    // Transform absolute_power_data array to absolute object
    if (qeegProData.absolute_power_data && Array.isArray(qeegProData.absolute_power_data)) {
      qeegProData.absolute_power_data.forEach(channelData => {
        const channel = channelData.channel;
        legacyFormat.absolute[channel] = {
          Delta: channelData.delta?.value || 0,
          Theta: channelData.theta?.value || 0,
          Alpha: channelData.alpha?.value || 0,
          Beta: channelData.beta?.value || 0,
          HiBeta: channelData.hibeta?.value || 0
        };
      });
      console.log(`  ‚úÖ Transformed ${qeegProData.absolute_power_data.length} absolute power channels`);
    }

    // Transform relative_power_data array to relative object
    if (qeegProData.relative_power_data && Array.isArray(qeegProData.relative_power_data)) {
      qeegProData.relative_power_data.forEach(channelData => {
        const channel = channelData.channel;
        legacyFormat.relative[channel] = {
          Delta: channelData.delta?.value || 0,
          Theta: channelData.theta?.value || 0,
          Alpha: channelData.alpha?.value || 0,
          Beta: channelData.beta?.value || 0,
          HiBeta: channelData.hibeta?.value || 0
        };
      });
      console.log(`  ‚úÖ Transformed ${qeegProData.relative_power_data.length} relative power channels`);
    }

    // Transform alpha_peak_data array to special object
    if (qeegProData.alpha_peak_data && Array.isArray(qeegProData.alpha_peak_data)) {
      // Extract alpha peak values for Pz and below (posterior electrodes)
      // As per specification: "Alpha peak - Eyes Closed Special PZ or below - the highest score will be taken"
      const posteriorChannels = ['Pz', 'P3', 'P4', 'O1', 'O2', 'Oz'];

      posteriorChannels.forEach(channel => {
        const peak = qeegProData.alpha_peak_data.find(entry => entry.channel === channel && entry.apf > 0);
        if (peak) {
          legacyFormat.special[channel] = peak.apf;
          console.log(`  ‚úÖ Extracted alpha peak for ${channel}: ${peak.apf} Hz`);
        }
      });

      // Find the average or first available alpha peak (for backwards compatibility)
      const alphaPeakEntry = qeegProData.alpha_peak_data.find(entry => entry.apf && entry.apf > 0);
      if (alphaPeakEntry) {
        legacyFormat.special.alphaPeak = alphaPeakEntry.apf;
        legacyFormat.special.alphaPeakZscore = alphaPeakEntry.z_score || 0;
      } else {
        legacyFormat.special.alphaPeak = 10.0; // Default
        legacyFormat.special.alphaPeakZscore = 0.0;
      }

      console.log(`  ‚úÖ Transformed alpha peak data (backwards compat): ${legacyFormat.special.alphaPeak} Hz`);
    }

    console.log('  ‚úÖ Transformation complete');
    return legacyFormat;
  }

  /**
   * Helper: Convert PDF file to Generative AI-compatible part (Base64 encoded)
   * @param {string} filePath - Path to PDF file
   * @param {string} mimeType - MIME type of the file
   * @returns {Object} File part for Gemini API
   */
  static fileToGenerativePart(filePath, mimeType) {
    console.log(`  üìÑ Converting file to Base64: ${path.basename(filePath)}`);

    const fileData = fs.readFileSync(filePath);
    const base64Data = fileData.toString('base64');

    console.log(`  ‚úÖ File converted to Base64 (${base64Data.length} chars)`);

    return {
      inlineData: {
        data: base64Data,
        mimeType: mimeType
      }
    };
  }

  /**
   * Parse PDF file using Gemini Multimodal (Direct PDF approach - NO local text extraction)
   * @param {Object} file - Multer file object
   * @param {string} condition - 'EO' or 'EC'
   * @param {string} reportType - 'raw' or 'zscore'
   */
  static async parsePDF(file, condition, reportType = 'raw') {
    console.log(`\n  üöÄ ========================================`);
    console.log(`  üöÄ GEMINI MULTIMODAL PDF EXTRACTION`);
    console.log(`  üöÄ Sending RAW PDF directly to Gemini`);
    console.log(`  üöÄ ========================================\n`);
    console.log(`  üìÑ File: ${file.originalname}`);
    console.log(`  üìä Condition: ${condition} (${condition === 'EO' ? 'Eyes Open' : 'Eyes Closed'})`);
    console.log(`  üìã Report Type: ${reportType.toUpperCase()}`);

    try {
      // Validate API key before attempting to use it
      this.validateAPIKey();

      // Read PDF file for hashing
      const dataBuffer = fs.readFileSync(file.path);

      // Calculate PDF hash for caching (ensures same PDF = same result)
      const pdfHash = this.calculatePDFHash(dataBuffer);
      const cacheKey = `${pdfHash}_${condition}_${reportType}`;

      console.log(`\n  üîë PDF Hash: ${pdfHash.substring(0, 12)}... (for deterministic caching)`);

      // Check cache first
      if (extractionCache.has(cacheKey)) {
        cacheStats.hits++;
        cacheStats.totalExtractions++;
        console.log(`  ‚úÖ CACHE HIT! Using cached extraction result (100% deterministic)`);
        console.log(`  üìä Cache Stats: ${cacheStats.hits} hits, ${cacheStats.misses} misses, ${((cacheStats.hits / cacheStats.totalExtractions) * 100).toFixed(1)}% hit rate`);
        return extractionCache.get(cacheKey);
      }

      cacheStats.misses++;
      cacheStats.totalExtractions++;
      console.log(`  ‚ö†Ô∏è  Cache miss - extracting data with Gemini AI...`);
      console.log(`  üìä Cache Stats: ${cacheStats.hits} hits, ${cacheStats.misses} misses`);

      // üéØ CONVERT PDF TO BASE64 FOR GEMINI MULTIMODAL
      console.log(`\n  üìÑ Converting PDF to Base64 for Gemini Multimodal...`);
      const pdfFilePart = this.fileToGenerativePart(file.path, 'application/pdf');
      console.log(`  ‚úÖ PDF converted successfully`);

      // ü§ñ GET EXTRACTION PROMPT (without text, just instructions)
      const prompt = this.getExtractionPromptForMultimodal(condition, reportType);

      // üîß INITIALIZE GEMINI 2.0 FLASH (Multimodal)
      console.log(`\n  üîß Initializing Gemini 2.0 Flash (Multimodal)...`);
      console.log(`  üîë API Key status:`, process.env.GEMINI_API_KEY ? 'Present' : 'MISSING');

      // Use gemini-2.0-flash for multimodal support
      const model = genAI.getGenerativeModel({
        model: 'gemini-2.0-flash',
        generationConfig: {
          temperature: 0,        // Deterministic output
          topK: 1,
          topP: 1,
          maxOutputTokens: 8192
        }
      });

      console.log(`  ‚úÖ Model initialized: gemini-2.0-flash`);

      // üõ°Ô∏è RATE LIMITING
      await rateLimiter.waitForRateLimit();

      // üöÄ SEND PDF + PROMPT TO GEMINI
      console.log(`\n  üöÄ Sending PDF directly to Gemini...`);
      console.log(`  üìä Extracting from PDF pages 13 & 24`);

      let result;
      let retryCount = 0;
      const maxRetries = 3;

      while (retryCount <= maxRetries) {
        try {
          // Send both prompt and PDF file
          result = await model.generateContent([prompt, pdfFilePart]);

          // ‚úÖ Record successful API call
          rateLimiter.recordRequest();

          break; // Success
        } catch (apiError) {
          // Handle quota/rate limit errors
          if (apiError.message && (apiError.message.includes('quota') || apiError.message.includes('429'))) {
            const retryDelay = Math.pow(2, retryCount) * 5000;

            console.warn(`  ‚ö†Ô∏è  Gemini API quota/rate limit hit (attempt ${retryCount + 1}/${maxRetries + 1})`);

            if (retryCount < maxRetries) {
              console.log(`  ‚è≥ Waiting ${retryDelay / 1000} seconds before retry...`);
              await new Promise(resolve => setTimeout(resolve, retryDelay));
              retryCount++;
              continue;
            } else {
              const enhancedError = new Error(
                'Gemini API quota exceeded. Your free tier allows 20 requests per day. ' +
                'Please wait a few hours for quota to reset, or upgrade to a paid plan at https://ai.google.dev/pricing'
              );
              enhancedError.code = 'GEMINI_QUOTA_EXCEEDED';
              enhancedError.originalError = apiError;
              throw enhancedError;
            }
          } else {
            // Not a quota error, throw immediately
            throw apiError;
          }
        }
      }

      const response = await result.response;
      const text = response.text();

      console.log(`  üìù Gemini response received (${condition}), length: ${text.length} characters`);

      // Parse JSON from response (remove markdown code blocks if present)
      let extractedData;
      try {
        const jsonText = text.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
        const rawData = JSON.parse(jsonText);

        // üîÑ TRANSFORM new qEEGPro format to legacy format for compatibility
        const transformedData = this.transformQEEGProToLegacyFormat(rawData);

        // üîß NORMALIZE all values to consistent decimal places
        // This ensures minor extraction variations don't affect calculations
        extractedData = this.normalizeExtractedData(transformedData);

        console.log(`  ‚úÖ PDF data extracted, transformed, and normalized successfully (${condition})`);

        // === ENHANCED DEBUG: Show COMPLETE extracted data ===
        console.log(`\n  üêõ === DEBUG: COMPLETE EXTRACTED DATA (${condition}) ===`);
        console.log(`  üìä ABSOLUTE POWER (ŒºV¬≤):`);
        if (extractedData.absolute) {
          Object.keys(extractedData.absolute).forEach(channel => {
            const bands = extractedData.absolute[channel];
            console.log(`     ${channel}: Delta=${bands.Delta}, Theta=${bands.Theta}, Alpha=${bands.Alpha}, Beta=${bands.Beta}, HiBeta=${bands.HiBeta}`);
          });
        }

        console.log(`\n  üìä RELATIVE POWER (%):`);
        if (extractedData.relative) {
          Object.keys(extractedData.relative).forEach(channel => {
            const bands = extractedData.relative[channel];
            const sum = (bands.Delta || 0) + (bands.Theta || 0) + (bands.Alpha || 0) + (bands.Beta || 0) + (bands.HiBeta || 0);
            console.log(`     ${channel}: Delta=${bands.Delta}%, Theta=${bands.Theta}%, Alpha=${bands.Alpha}%, Beta=${bands.Beta}%, HiBeta=${bands.HiBeta}% [Sum=${sum.toFixed(1)}%]`);
          });
        }

        console.log(`\n  üìä SPECIAL VALUES:`);
        if (extractedData.special) {
          console.log(`     Alpha Peak: ${extractedData.special.alphaPeak} Hz`);
          if (extractedData.special.O1) console.log(`     O1: ${extractedData.special.O1} Hz`);
        }

        // If Z-score data exists
        if (extractedData.zscores) {
          console.log(`\n  üìä Z-SCORE DATA (ABSOLUTE):`);
          if (extractedData.zscores.absolute) {
            Object.keys(extractedData.zscores.absolute).forEach(channel => {
              const bands = extractedData.zscores.absolute[channel];
              console.log(`     ${channel}: Delta=${bands.Delta}, Theta=${bands.Theta}, Alpha=${bands.Alpha}, Beta=${bands.Beta}, HiBeta=${bands.HiBeta}`);
            });
          }

          console.log(`\n  üìä Z-SCORE DATA (RELATIVE):`);
          if (extractedData.zscores.relative) {
            Object.keys(extractedData.zscores.relative).forEach(channel => {
              const bands = extractedData.zscores.relative[channel];
              console.log(`     ${channel}: Delta=${bands.Delta}, Theta=${bands.Theta}, Alpha=${bands.Alpha}, Beta=${bands.Beta}, HiBeta=${bands.HiBeta}`);
            });
          }
        }
        console.log(`  === END DEBUG: EXTRACTED DATA ===\n`);

      } catch (parseError) {
        console.error(`  ‚ùå Failed to parse JSON from Gemini response (${condition}):`, parseError.message);
        console.error(`  üìÑ Raw response:`, text.substring(0, 500));
        throw new Error(`Failed to parse JSON from Gemini response: ${parseError.message}`);
      }

      // Add detailed logging
      console.log(`  üìä Data extraction summary (${condition}):`);
      console.log(`     - Absolute power channels: ${Object.keys(extractedData.absolute || {}).length}`);
      console.log(`     - Relative power channels: ${Object.keys(extractedData.relative || {}).length}`);
      console.log(`     - Special values: ${JSON.stringify(extractedData.special || {})}`);

      // Log sample extracted values for verification (prove it's real patient data, not static)
      console.log(`\n  üìã Sample Extracted Values (${condition}) - Proof of Dynamic Extraction:`);
      if (extractedData.absolute?.Fz) {
        console.log(`     - Fz Absolute: Theta=${extractedData.absolute.Fz.Theta}, Beta=${extractedData.absolute.Fz.Beta}`);
      }
      if (extractedData.absolute?.Pz) {
        console.log(`     - Pz Absolute: Alpha=${extractedData.absolute.Pz.Alpha}, HiBeta=${extractedData.absolute.Pz.HiBeta}`);
      }
      if (extractedData.relative?.Pz) {
        console.log(`     - Pz Relative: Alpha=${extractedData.relative.Pz.Alpha}, Beta=${extractedData.relative.Pz.Beta}`);
      }
      if (extractedData.absolute?.F3 && extractedData.absolute?.F4) {
        console.log(`     - F3/F4 Absolute Alpha: F3=${extractedData.absolute.F3.Alpha}, F4=${extractedData.absolute.F4.Alpha}`);
      }
      if (extractedData.special?.alphaPeak) {
        console.log(`     - Alpha Peak Frequency: ${extractedData.special.alphaPeak} Hz`);
      }

      // Validate extracted data has minimum required fields
      const requiredChannels = ['Fz', 'Cz', 'Pz', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4'];
      const absoluteChannels = Object.keys(extractedData.absolute || {});
      const relativeChannels = Object.keys(extractedData.relative || {});

      const missingAbsolute = requiredChannels.filter(ch => !absoluteChannels.includes(ch));
      const missingRelative = requiredChannels.filter(ch => !relativeChannels.includes(ch));

      if (missingAbsolute.length > 0) {
        console.warn(`  ‚ö†Ô∏è  Missing absolute power channels: ${missingAbsolute.join(', ')}`);
      }
      if (missingRelative.length > 0) {
        console.warn(`  ‚ö†Ô∏è  Missing relative power channels: ${missingRelative.join(', ')}`);
      }

      // üîç VALIDATE: Check if relative power sums to ~100% for each channel
      console.log(`\n  üîç Validating relative power values (${condition})...`);
      let incompleteChannels = [];

      for (const channel of requiredChannels) {
        if (extractedData.relative?.[channel]) {
          const bands = extractedData.relative[channel];
          const sum = (bands.Delta || 0) + (bands.Theta || 0) + (bands.Alpha || 0) +
                     (bands.Beta || 0) + (bands.HiBeta || 0);

          // Check if sum is close to 100% (allow ¬±5% tolerance)
          if (sum < 95 || sum > 105) {
            incompleteChannels.push({
              channel,
              sum: sum.toFixed(1),
              bands: {
                Delta: bands.Delta || 0,
                Theta: bands.Theta || 0,
                Alpha: bands.Alpha || 0,
                Beta: bands.Beta || 0,
                HiBeta: bands.HiBeta || 0
              }
            });
          }
        }
      }

      if (incompleteChannels.length > 0) {
        console.error(`\n  ‚ùå ==================== DATA EXTRACTION INCOMPLETE ====================`);
        console.error(`  ‚ùå CRITICAL: ${incompleteChannels.length} channels have incorrect relative power sums!`);
        console.error(`  ‚ùå Relative power MUST sum to ~100% for each channel.`);
        console.error(`  ‚ùå Incomplete extraction will cause INCORRECT ALGORITHM RESULTS!\n`);

        incompleteChannels.forEach(({ channel, sum, bands }) => {
          console.error(`     Channel ${channel}: Sum = ${sum}% (Expected: ~100%)`);
          console.error(`       Delta: ${bands.Delta}% | Theta: ${bands.Theta}% | Alpha: ${bands.Alpha}%`);
          console.error(`       Beta: ${bands.Beta}% | HiBeta: ${bands.HiBeta}%`);

          // Identify which bands are likely missing (have 0 or very low values)
          const missingBands = [];
          Object.entries(bands).forEach(([band, value]) => {
            if (value === 0 || value < 0.1) {
              missingBands.push(band);
            }
          });

          if (missingBands.length > 0) {
            console.error(`       ‚ö†Ô∏è  Likely missing bands: ${missingBands.join(', ')}`);
          }
          console.error('');
        });

        console.error(`  ‚ùå RECOMMENDATION: Check if the PDF contains all frequency band values.`);
        console.error(`  ‚ùå Gemini may need to look in different table sections or pages.`);
        console.error(`  ‚ùå ====================================================================\n`);
      } else {
        console.log(`  ‚úÖ Relative power validation passed: All channels sum to ~100%`);
      }

      // ‚ö†Ô∏è COMPREHENSIVE DATA VALIDATION - Check but allow warnings
      const validation = this.validateExtractedData(extractedData, condition);

      if (!validation.isValid) {
        // Check if data is completely empty (all relative power = 0)
        const requiredChannels = ['Fz', 'Cz', 'Pz', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4'];
        const requiredBands = ['Delta', 'Theta', 'Alpha', 'Beta', 'HiBeta'];

        const hasAnyRelativeData = requiredChannels.some(channel => {
          if (!extractedData.relative?.[channel]) return false;
          const sum = requiredBands.reduce((acc, band) => {
            return acc + (extractedData.relative[channel][band] || 0);
          }, 0);
          return sum > 0;
        });

        const hasAnyAbsoluteData = requiredChannels.some(channel => {
          if (!extractedData.absolute?.[channel]) return false;
          const sum = requiredBands.reduce((acc, band) => {
            return acc + (extractedData.absolute[channel][band] || 0);
          }, 0);
          return sum > 0;
        });

        if (!hasAnyRelativeData && !hasAnyAbsoluteData) {
          // Completely failed extraction - throw error
          console.error(`\n  ‚ùå ==================== DATA EXTRACTION COMPLETELY FAILED ====================`);
          console.error(`  ‚ùå CRITICAL: No data was extracted from PDF!`);
          console.error(`  ‚ùå Missing/Invalid fields: ${validation.missingFields.length}`);
          console.error(`  ‚ùå ${validation.error}`);
          console.error(`  ‚ùå ALGORITHM CALCULATION CANNOT PROCEED!`);
          console.error(`  ‚ùå ========================================================================\n`);

          const extractionError = new Error(
            `COMPLETE DATA EXTRACTION FAILURE: ${validation.error}\n` +
            `Missing fields: ${validation.missingFields.join(', ')}\n` +
            `PDF data from pages 13 & 24 was not extracted.\n` +
            `Please ensure the PDF contains valid QEEG tables and try again.`
          );
          extractionError.code = 'COMPLETE_DATA_EXTRACTION_FAILURE';
          extractionError.validation = validation;
          extractionError.condition = condition;
          throw extractionError;
        } else {
          // Partial data extracted - show warnings but continue
          console.warn(`\n  ‚ö†Ô∏è  ==================== PARTIAL DATA EXTRACTION ====================`);
          console.warn(`  ‚ö†Ô∏è  WARNING: Data extraction is incomplete but has some data!`);
          console.warn(`  ‚ö†Ô∏è  Missing/Invalid fields: ${validation.missingFields.length}`);
          console.warn(`  ‚ö†Ô∏è  ${validation.error}`);
          console.warn(`  ‚ö†Ô∏è  Algorithm will proceed with available data.`);
          console.warn(`  ‚ö†Ô∏è  Results may be less accurate.`);
          console.warn(`  ‚ö†Ô∏è  ================================================================\n`);
        }
      } else {
        console.log(`  üéâ Data validation PASSED! All required fields present.`);
      }

      // ‚úÖ CACHE the extraction result for deterministic behavior
      // Same PDF will now ALWAYS return the same values
      extractionCache.set(cacheKey, extractedData);
      console.log(`  üíæ Extraction result cached (key: ${pdfHash.substring(0, 12)}...)`);
      console.log(`  üìä Cache size: ${extractionCache.size} entries`);

      return extractedData;

    } catch (error) {
      console.error(`  ‚ùå Gemini API error (${condition}):`, error.message);

      // Log more details for debugging
      if (error.response) {
        console.error(`  ‚ùå Gemini API Status:`, error.response?.status);
        console.error(`  ‚ùå Gemini API Error:`, error.response?.data);
      }

      console.error(`  üìÑ Error stack:`, error.stack);

      // Re-throw with more context
      const enhancedError = new Error(`Failed to extract QEEG data from PDF using Gemini (${condition}): ${error.message}`);
      enhancedError.code = 'PDF_EXTRACTION_FAILED';
      enhancedError.originalError = error;
      enhancedError.condition = condition;
      throw enhancedError;
    }
  }

  /**
   * Parse CSV file
   */
  static parseCSV(file) {
    console.log('  üìä Parsing CSV file...');

    // Read CSV file
    const workbook = XLSX.readFile(file.path);
    const sheetName = workbook.SheetNames[0];
    const worksheet = workbook.Sheets[sheetName];
    const jsonData = XLSX.utils.sheet_to_json(worksheet);

    // Convert CSV data to our format
    const data = this.convertCSVToFormat(jsonData);

    console.log('  ‚úÖ CSV parsed successfully');
    return data;
  }

  /**
   * Parse Excel file
   */
  static parseExcel(file) {
    console.log('  üìä Parsing Excel file...');

    // Read Excel file
    const workbook = XLSX.readFile(file.path);
    const sheetName = workbook.SheetNames[0];
    const worksheet = workbook.Sheets[sheetName];
    const jsonData = XLSX.utils.sheet_to_json(worksheet);

    // Convert Excel data to our format
    const data = this.convertExcelToFormat(jsonData);

    console.log('  ‚úÖ Excel parsed successfully');
    return data;
  }

  /**
   * Convert CSV data to expected format
   */
  static convertCSVToFormat(csvData) {
    // Assuming CSV has structure: Channel, PowerType, Delta, Theta, Alpha, Beta, HiBeta
    const result = {
      absolute: {},
      relative: {},
      special: { alphaPeak: 10.0, O1: 10.0 }
    };

    const channels = ['Fz', 'Cz', 'Pz', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4'];
    const bands = ['Delta', 'Theta', 'Alpha', 'Beta', 'HiBeta'];

    for (const row of csvData) {
      const channel = row.Channel;
      const powerType = row.PowerType?.toLowerCase();

      if (channels.includes(channel) && (powerType === 'absolute' || powerType === 'relative')) {
        result[powerType][channel] = {
          Delta: parseFloat(row.Delta) || 0,
          Theta: parseFloat(row.Theta) || 0,
          Alpha: parseFloat(row.Alpha) || 0,
          Beta: parseFloat(row.Beta) || 0,
          HiBeta: parseFloat(row.HiBeta || row.HighBeta) || 0
        };
      }
    }

    return result;
  }

  /**
   * Convert Excel data to expected format (same as CSV for now)
   */
  static convertExcelToFormat(excelData) {
    return this.convertCSVToFormat(excelData);
  }

  /**
   * Get cache statistics
   * @returns {Object} Cache statistics
   */
  static getCacheStats() {
    return {
      ...cacheStats,
      cacheSize: extractionCache.size,
      hitRate: cacheStats.totalExtractions > 0
        ? ((cacheStats.hits / cacheStats.totalExtractions) * 100).toFixed(1) + '%'
        : '0%'
    };
  }

  /**
   * Clear extraction cache (useful for testing or memory management)
   * @param {string} pdfHash - Optional: Clear specific PDF hash, or all if not provided
   */
  static clearCache(pdfHash = null) {
    if (pdfHash) {
      // Clear specific PDF
      let cleared = 0;
      for (const key of extractionCache.keys()) {
        if (key.startsWith(pdfHash)) {
          extractionCache.delete(key);
          cleared++;
        }
      }
      console.log(`üóëÔ∏è  Cleared ${cleared} cache entries for PDF hash: ${pdfHash.substring(0, 12)}...`);
    } else {
      // Clear all
      const size = extractionCache.size;
      extractionCache.clear();
      cacheStats.hits = 0;
      cacheStats.misses = 0;
      cacheStats.totalExtractions = 0;
      console.log(`üóëÔ∏è  Cleared entire extraction cache (${size} entries)`);
    }
  }

  /**
   * Get Gemini API quota status
   * @returns {Object} Current quota usage and limits
   */
  static getQuotaStatus() {
    return rateLimiter.getQuotaStatus();
  }
}

module.exports = QEEGParser;
