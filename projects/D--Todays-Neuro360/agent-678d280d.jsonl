{"parentUuid":null,"isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","type":"user","message":{"role":"user","content":"User wants to implement a DUAL-MODE system that can handle TWO types of QEEG reports:\n\n## REQUIREMENT:\n\n**Mode 1: Raw Power Values Report**\n- Report contains Absolute Power (ŒºV¬≤) and Relative Power (%)\n- Extract raw values\n- Use current formulas (calculate ratios from raw values)\n- Display scores and metrics\n\n**Mode 2: Z-Score Only Report**\n- Report contains ONLY Z-score tables\n- Extract Z-scores\n- Convert Z-scores or apply Z-score specific formulas\n- Display scores and metrics\n\n## INVESTIGATION NEEDED:\n\n### 1. Detection Logic\nHow to automatically detect which type of report was uploaded?\n- Check table headers for \"Z-score\" vs \"Absolute Power (ŒºV¬≤)\"\n- Look for value ranges (Z-scores: -3 to +3, Raw: 0-500+)\n- Parse specific keywords in the PDF\n\n### 2. Extraction Strategy\n**For qeegParser.js:**\n- Should we modify the OpenAI prompt to detect and extract BOTH types?\n- Create two separate prompts (one for raw, one for Z-scores)?\n- Add a pre-processing step to identify report type?\n\n### 3. Calculation Strategy\n**For algorithmCalculator.js:**\n\n**Option A: Convert Z-scores to Raw Values**\n- If Z-score report, convert Z-scores back to estimated raw values\n- Use existing formulas unchanged\n- Need normative database mean/SD values for conversion\n\n**Option B: Dual Formula Sets**\n- Keep current formulas for raw values\n- Create new formulas for Z-score based calculations\n- Example Z-score thresholds:\n  - Normal: -1 to +1 (within 1 SD)\n  - Mild abnormality: ¬±1 to ¬±2\n  - Significant: beyond ¬±2\n\n**Option C: Direct Z-score Analysis**\n- Don't calculate ratios from Z-scores\n- Directly assess if individual Z-scores are abnormal\n- Different scoring logic entirely\n\n### 4. Implementation Architecture\n\nProposed structure:\n```javascript\n// qeegParser.js\nasync parse(file) {\n  const reportType = await detectReportType(file);\n  \n  if (reportType === 'raw') {\n    return await extractRawValues(file);\n  } else if (reportType === 'zscore') {\n    return await extractZScores(file);\n  }\n}\n\n// algorithmCalculator.js\nconstructor(qeegData, dataType) {\n  this.data = qeegData;\n  this.dataType = dataType; // 'raw' or 'zscore'\n}\n\ncalculate() {\n  if (this.dataType === 'raw') {\n    return this.calculateFromRawValues();\n  } else {\n    return this.calculateFromZScores();\n  }\n}\n```\n\n### 5. Z-Score to Raw Conversion\nIf we need to convert Z-scores to raw values:\n\nFormula: `Raw Value = (Z-score √ó SD) + Mean`\n\nNeed normative data:\n- Mean absolute power for each channel/band\n- Standard deviation for each channel/band\n- Source: Published QEEG normative databases (age-matched)\n\nExample:\n```javascript\n// Normative data (example values)\nconst norms = {\n  Fz: {\n    Theta: { mean: 3.8, sd: 1.2 },\n    Beta: { mean: 3.2, sd: 0.8 }\n  }\n};\n\n// Convert Z-score to raw\nfunction zScoreToRaw(zScore, channel, band) {\n  const norm = norms[channel][band];\n  return (zScore * norm.sd) + norm.mean;\n}\n```\n\n### 6. Data Structure\n\nCurrent structure works for raw values:\n```javascript\n{\n  EO: {\n    absolute: { Fz: { Theta: 3.8, Beta: 3.2 } },\n    relative: { Fz: { Theta: 18.5 } }\n  }\n}\n```\n\nZ-score structure could be:\n```javascript\n{\n  EO: {\n    zScores: { \n      absolute: { Fz: { Theta: 1.5, Beta: 0.8 } },\n      relative: { Fz: { Theta: 2.1 } }\n    }\n  },\n  dataType: 'zscore'\n}\n```\n\n### 7. Questions to Answer:\n\n1. Should we convert Z-scores to raw values, or create separate Z-score formulas?\n2. Do we have access to normative database for Z-score conversion?\n3. Are the clinical thresholds (1.5, 10, etc.) appropriate for Z-score calculations?\n4. How to handle edge cases (report with mixed data types)?\n5. Should detection be automatic or user-selected?\n\n### 8. Files to Modify:\n\n- `server/services/qeegParser.js` - Add detection + dual extraction\n- `server/services/algorithmCalculator.js` - Add dual calculation mode\n- `server/routes/qeegRoutes.js` - Pass data type flag\n- `src/components/admin/AlgorithmDataProcessor.jsx` - UI for mode selection (optional)\n\nPlease provide:\n- Recommended architecture for dual-mode system\n- Detection strategy (automatic vs manual)\n- Calculation strategy (convert vs separate formulas)\n- Implementation plan with priorities\n- Normative database requirements (if conversion needed)\n\nThis is a MAJOR feature addition requiring careful design!"},"uuid":"e6b0431d-61da-41b7-bfe5-01d36ed8bb7b","timestamp":"2025-12-02T09:00:05.918Z"}
{"parentUuid":"e6b0431d-61da-41b7-bfe5-01d36ed8bb7b","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01AWuivPpRmDJkgJTWxvVAEd","type":"message","role":"assistant","content":[{"type":"text","text":"I'll investigate the current codebase to understand the existing architecture and provide recommendations for implementing this dual-mode QEEG system."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":10011,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":10011,"ephemeral_1h_input_tokens":0},"output_tokens":216,"service_tier":"standard"}},"requestId":"req_011CVhayoMmbcgnjJUvo68LF","type":"assistant","uuid":"69e4b38e-8fc5-4836-b113-65c98492548c","timestamp":"2025-12-02T09:00:12.789Z"}
{"parentUuid":"69e4b38e-8fc5-4836-b113-65c98492548c","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01AWuivPpRmDJkgJTWxvVAEd","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01HYbe439o1a8N6esJCiqFW9","name":"Glob","input":{"pattern":"**/qeegParser.js"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":10011,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":10011,"ephemeral_1h_input_tokens":0},"output_tokens":216,"service_tier":"standard"}},"requestId":"req_011CVhayoMmbcgnjJUvo68LF","type":"assistant","uuid":"70ae4487-3e18-4cbe-8c6b-9909edd81010","timestamp":"2025-12-02T09:00:13.193Z"}
{"parentUuid":"70ae4487-3e18-4cbe-8c6b-9909edd81010","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01AWuivPpRmDJkgJTWxvVAEd","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Wep7JrcjErDFJ7ypXNS4QW","name":"Glob","input":{"pattern":"**/algorithmCalculator.js"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":10011,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":10011,"ephemeral_1h_input_tokens":0},"output_tokens":216,"service_tier":"standard"}},"requestId":"req_011CVhayoMmbcgnjJUvo68LF","type":"assistant","uuid":"5c30280d-9b87-447f-bd62-5d987544acf4","timestamp":"2025-12-02T09:00:13.678Z"}
{"parentUuid":"5c30280d-9b87-447f-bd62-5d987544acf4","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01AWuivPpRmDJkgJTWxvVAEd","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01QLBFao8N6Wc5JCEqFC4oY1","name":"Glob","input":{"pattern":"**/qeegRoutes.js"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":10011,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":10011,"ephemeral_1h_input_tokens":0},"output_tokens":216,"service_tier":"standard"}},"requestId":"req_011CVhayoMmbcgnjJUvo68LF","type":"assistant","uuid":"f32de5bb-c3eb-455a-a7da-fb026a7c787a","timestamp":"2025-12-02T09:00:13.870Z"}
{"parentUuid":"f32de5bb-c3eb-455a-a7da-fb026a7c787a","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01AWuivPpRmDJkgJTWxvVAEd","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01116eGaA2aj4D9QLZsh51js","name":"Glob","input":{"pattern":"**/AlgorithmDataProcessor.jsx"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":10011,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":10011,"ephemeral_1h_input_tokens":0},"output_tokens":216,"service_tier":"standard"}},"requestId":"req_011CVhayoMmbcgnjJUvo68LF","type":"assistant","uuid":"136eed15-a2d2-43dd-8cb9-0a5561e52b24","timestamp":"2025-12-02T09:00:14.126Z"}
{"parentUuid":"136eed15-a2d2-43dd-8cb9-0a5561e52b24","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01HYbe439o1a8N6esJCiqFW9","type":"tool_result","content":"D:\\Todays\\Neuro360\\server\\services\\qeegParser.js"}]},"uuid":"53c5d598-6f72-4d13-8bc1-38f08256e3d0","timestamp":"2025-12-02T09:00:22.913Z","toolUseResult":{"filenames":["D:\\Todays\\Neuro360\\server\\services\\qeegParser.js"],"durationMs":913,"numFiles":1,"truncated":false}}
{"parentUuid":"53c5d598-6f72-4d13-8bc1-38f08256e3d0","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Wep7JrcjErDFJ7ypXNS4QW","type":"tool_result","content":"D:\\Todays\\Neuro360\\server\\services\\algorithmCalculator.js"}]},"uuid":"abde225d-558c-4b99-ae29-f93e2bf68285","timestamp":"2025-12-02T09:00:23.008Z","toolUseResult":{"filenames":["D:\\Todays\\Neuro360\\server\\services\\algorithmCalculator.js"],"durationMs":959,"numFiles":1,"truncated":false}}
{"parentUuid":"abde225d-558c-4b99-ae29-f93e2bf68285","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01QLBFao8N6Wc5JCEqFC4oY1","type":"tool_result","content":"D:\\Todays\\Neuro360\\server\\routes\\qeegRoutes.js"}]},"uuid":"4832819c-fcf7-4cc1-88f2-4e7862716333","timestamp":"2025-12-02T09:00:23.158Z","toolUseResult":{"filenames":["D:\\Todays\\Neuro360\\server\\routes\\qeegRoutes.js"],"durationMs":1108,"numFiles":1,"truncated":false}}
{"parentUuid":"4832819c-fcf7-4cc1-88f2-4e7862716333","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01116eGaA2aj4D9QLZsh51js","type":"tool_result","content":"D:\\Todays\\Neuro360\\src\\components\\admin\\AlgorithmDataProcessor.jsx"}]},"uuid":"691ecb17-54db-48ab-8ef9-4269a8a98b1e","timestamp":"2025-12-02T09:00:23.263Z","toolUseResult":{"filenames":["D:\\Todays\\Neuro360\\src\\components\\admin\\AlgorithmDataProcessor.jsx"],"durationMs":1172,"numFiles":1,"truncated":false}}
{"parentUuid":"691ecb17-54db-48ab-8ef9-4269a8a98b1e","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01NiPaQNMMdCD9CJVRk6kuT3","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01QYEu2mMcqpPRDb97BDfYqa","name":"Read","input":{"file_path":"D:\\Todays\\Neuro360\\server\\services\\qeegParser.js"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":616,"cache_read_input_tokens":10011,"cache_creation":{"ephemeral_5m_input_tokens":616,"ephemeral_1h_input_tokens":0},"output_tokens":245,"service_tier":"standard"}},"requestId":"req_011CVhazyN4DaSYe6uiAhjBK","type":"assistant","uuid":"a25034dc-7a44-4234-99c3-97df30ffc05b","timestamp":"2025-12-02T09:00:28.203Z"}
{"parentUuid":"a25034dc-7a44-4234-99c3-97df30ffc05b","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01NiPaQNMMdCD9CJVRk6kuT3","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01HUPBDZxS5UxLxT7ZY5X56z","name":"Read","input":{"file_path":"D:\\Todays\\Neuro360\\server\\services\\algorithmCalculator.js"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":616,"cache_read_input_tokens":10011,"cache_creation":{"ephemeral_5m_input_tokens":616,"ephemeral_1h_input_tokens":0},"output_tokens":245,"service_tier":"standard"}},"requestId":"req_011CVhazyN4DaSYe6uiAhjBK","type":"assistant","uuid":"64541150-eda3-4e86-aed5-69a92d28ec32","timestamp":"2025-12-02T09:00:28.681Z"}
{"parentUuid":"64541150-eda3-4e86-aed5-69a92d28ec32","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01NiPaQNMMdCD9CJVRk6kuT3","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WuXt1FWpQfJn7jqmguxapo","name":"Read","input":{"file_path":"D:\\Todays\\Neuro360\\server\\routes\\qeegRoutes.js"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":616,"cache_read_input_tokens":10011,"cache_creation":{"ephemeral_5m_input_tokens":616,"ephemeral_1h_input_tokens":0},"output_tokens":245,"service_tier":"standard"}},"requestId":"req_011CVhazyN4DaSYe6uiAhjBK","type":"assistant","uuid":"92e2851c-72c1-4235-8749-1c56add2ddc7","timestamp":"2025-12-02T09:00:29.010Z"}
{"parentUuid":"92e2851c-72c1-4235-8749-1c56add2ddc7","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01NiPaQNMMdCD9CJVRk6kuT3","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01PcQP6MNGkP8ATpVa95h1ML","name":"Read","input":{"file_path":"D:\\Todays\\Neuro360\\src\\components\\admin\\AlgorithmDataProcessor.jsx"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":616,"cache_read_input_tokens":10011,"cache_creation":{"ephemeral_5m_input_tokens":616,"ephemeral_1h_input_tokens":0},"output_tokens":245,"service_tier":"standard"}},"requestId":"req_011CVhazyN4DaSYe6uiAhjBK","type":"assistant","uuid":"0828dc20-0ae0-41de-b80b-28b81b2134d4","timestamp":"2025-12-02T09:00:29.631Z"}
{"parentUuid":"0828dc20-0ae0-41de-b80b-28b81b2134d4","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01QYEu2mMcqpPRDb97BDfYqa","type":"tool_result","content":"     1‚Üíconst fs = require('fs');\n     2‚Üíconst path = require('path');\n     3‚Üíconst OpenAI = require('openai');\n     4‚Üíconst pdfParse = require('pdf-parse');\n     5‚Üíconst XLSX = require('xlsx');\n     6‚Üí\n     7‚Üí// Initialize OpenAI client\n     8‚Üíconst openai = new OpenAI({\n     9‚Üí  apiKey: process.env.OPENAI_API_KEY\n    10‚Üí});\n    11‚Üí\n    12‚Üíclass QEEGParser {\n    13‚Üí  /**\n    14‚Üí   * Validate OpenAI API key is configured and appears valid\n    15‚Üí   * @throws {Error} if API key is missing or invalid format\n    16‚Üí   */\n    17‚Üí  static validateAPIKey() {\n    18‚Üí    const apiKey = process.env.OPENAI_API_KEY;\n    19‚Üí\n    20‚Üí    // Check if key exists\n    21‚Üí    if (!apiKey || apiKey.trim() === '') {\n    22‚Üí      const error = new Error('OPENAI_API_KEY environment variable is not set');\n    23‚Üí      error.code = 'MISSING_API_KEY';\n    24‚Üí      throw error;\n    25‚Üí    }\n    26‚Üí\n    27‚Üí    // Check if key is placeholder\n    28‚Üí    if (apiKey === 'your-openai-api-key-here' || apiKey.includes('placeholder')) {\n    29‚Üí      const error = new Error('OPENAI_API_KEY is set to placeholder value. Please configure a valid OpenAI API key.');\n    30‚Üí      error.code = 'INVALID_API_KEY';\n    31‚Üí      throw error;\n    32‚Üí    }\n    33‚Üí\n    34‚Üí    // Check key format (OpenAI keys start with sk-)\n    35‚Üí    if (!apiKey.startsWith('sk-')) {\n    36‚Üí      const error = new Error('OPENAI_API_KEY has invalid format. OpenAI keys should start with \"sk-\"');\n    37‚Üí      error.code = 'INVALID_API_KEY_FORMAT';\n    38‚Üí      throw error;\n    39‚Üí    }\n    40‚Üí\n    41‚Üí    console.log('‚úÖ OpenAI API key validation passed');\n    42‚Üí    return true;\n    43‚Üí  }\n    44‚Üí\n    45‚Üí  /**\n    46‚Üí   * Test OpenAI API connection with a simple request\n    47‚Üí   * @returns {Promise<boolean>} true if connection successful\n    48‚Üí   * @throws {Error} if connection fails\n    49‚Üí   */\n    50‚Üí  static async testAPIConnection() {\n    51‚Üí    try {\n    52‚Üí      this.validateAPIKey();\n    53‚Üí\n    54‚Üí      console.log('üîå Testing OpenAI API connection...');\n    55‚Üí\n    56‚Üí      const response = await openai.chat.completions.create({\n    57‚Üí        model: 'gpt-4-turbo-preview',\n    58‚Üí        messages: [\n    59‚Üí          { role: 'user', content: 'Reply with OK' }\n    60‚Üí        ],\n    61‚Üí        max_tokens: 5\n    62‚Üí      });\n    63‚Üí\n    64‚Üí      if (response.choices && response.choices.length > 0) {\n    65‚Üí        console.log('‚úÖ OpenAI API connection successful');\n    66‚Üí        return true;\n    67‚Üí      } else {\n    68‚Üí        throw new Error('OpenAI API returned unexpected response');\n    69‚Üí      }\n    70‚Üí\n    71‚Üí    } catch (error) {\n    72‚Üí      console.error('‚ùå OpenAI API connection test failed:', error.message);\n    73‚Üí      const enhancedError = new Error(`OpenAI API connection test failed: ${error.message}`);\n    74‚Üí      enhancedError.code = 'API_CONNECTION_FAILED';\n    75‚Üí      enhancedError.originalError = error;\n    76‚Üí      throw enhancedError;\n    77‚Üí    }\n    78‚Üí  }\n    79‚Üí\n    80‚Üí  /**\n    81‚Üí   * Main method to parse uploaded files\n    82‚Üí   * @param {Object} eyesOpenFile - Multer file object for Eyes Open data\n    83‚Üí   * @param {Object} eyesClosedFile - Multer file object for Eyes Closed data\n    84‚Üí   * @returns {Object} Parsed QEEG data\n    85‚Üí   */\n    86‚Üí  static async parse(eyesOpenFile, eyesClosedFile) {\n    87‚Üí    try {\n    88‚Üí      console.log('üìÑ Parsing QEEG files...');\n    89‚Üí      console.log('  - Eyes Open:', eyesOpenFile?.originalname);\n    90‚Üí      console.log('  - Eyes Closed:', eyesClosedFile?.originalname);\n    91‚Üí\n    92‚Üí      // Determine file types\n    93‚Üí      const eoFileType = this.getFileType(eyesOpenFile.originalname);\n    94‚Üí      const ecFileType = this.getFileType(eyesClosedFile.originalname);\n    95‚Üí\n    96‚Üí      // Parse each file\n    97‚Üí      const eyesOpenData = await this.parseFile(eyesOpenFile, eoFileType, 'EO');\n    98‚Üí      const eyesClosedData = await this.parseFile(eyesClosedFile, ecFileType, 'EC');\n    99‚Üí\n   100‚Üí      // Combine data\n   101‚Üí      const combinedData = {\n   102‚Üí        EO: eyesOpenData,\n   103‚Üí        EC: eyesClosedData\n   104‚Üí      };\n   105‚Üí\n   106‚Üí      console.log('‚úÖ QEEG files parsed successfully');\n   107‚Üí      return combinedData;\n   108‚Üí\n   109‚Üí    } catch (error) {\n   110‚Üí      console.error('‚ùå Error parsing QEEG files:', error);\n   111‚Üí      throw new Error(`Failed to parse QEEG files: ${error.message}`);\n   112‚Üí    }\n   113‚Üí  }\n   114‚Üí\n   115‚Üí  /**\n   116‚Üí   * Determine file type from filename\n   117‚Üí   */\n   118‚Üí  static getFileType(filename) {\n   119‚Üí    const ext = path.extname(filename).toLowerCase();\n   120‚Üí    if (ext === '.pdf') return 'pdf';\n   121‚Üí    if (ext === '.csv') return 'csv';\n   122‚Üí    if (ext === '.xlsx' || ext === '.xls') return 'excel';\n   123‚Üí    throw new Error(`Unsupported file type: ${ext}`);\n   124‚Üí  }\n   125‚Üí\n   126‚Üí  /**\n   127‚Üí   * Parse a single file based on its type\n   128‚Üí   */\n   129‚Üí  static async parseFile(file, fileType, condition) {\n   130‚Üí    if (fileType === 'pdf') {\n   131‚Üí      return await this.parsePDF(file, condition);\n   132‚Üí    } else if (fileType === 'csv') {\n   133‚Üí      return this.parseCSV(file);\n   134‚Üí    } else if (fileType === 'excel') {\n   135‚Üí      return this.parseExcel(file);\n   136‚Üí    }\n   137‚Üí    throw new Error(`Unknown file type: ${fileType}`);\n   138‚Üí  }\n   139‚Üí\n   140‚Üí  /**\n   141‚Üí   * Parse PDF file using OpenAI Vision API\n   142‚Üí   */\n   143‚Üí  static async parsePDF(file, condition) {\n   144‚Üí    console.log(`  üîç Parsing PDF with OpenAI Vision API (${condition})...`);\n   145‚Üí\n   146‚Üí    try {\n   147‚Üí      // Validate API key before attempting to use it\n   148‚Üí      this.validateAPIKey();\n   149‚Üí\n   150‚Üí\n   151‚Üí      // Read PDF file\n   152‚Üí      const dataBuffer = fs.readFileSync(file.path);\n   153‚Üí      const pdfData = await pdfParse(dataBuffer);\n   154‚Üí\n   155‚Üí      // Extract text from PDF\n   156‚Üí      const pdfText = pdfData.text;\n   157‚Üí\n   158‚Üí    // Use OpenAI to extract QEEG tables\n   159‚Üí    const prompt = `You are a QEEG data extraction expert. Extract the following data from this ${condition === 'EO' ? 'Eyes Open' : 'Eyes Closed'} QEEG report:\n   160‚Üí\n   161‚ÜíExtract two tables:\n   162‚Üí1. **Absolute Power (ŒºV¬≤)** table\n   163‚Üí2. **Relative Power (%)** table\n   164‚Üí\n   165‚ÜíFor each table, extract values for these EEG channels: FP1, FP2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2\n   166‚Üí\n   167‚ÜíFor each channel, extract values for these frequency bands:\n   168‚Üí- Delta\n   169‚Üí- Theta\n   170‚Üí- Alpha\n   171‚Üí- Beta\n   172‚Üí- HiBeta (High Beta)\n   173‚Üí\n   174‚ÜíAlso extract Alpha Peak Frequency (APF) if available.\n   175‚Üí\n   176‚ÜíReturn the data in this EXACT JSON format:\n   177‚Üí{\n   178‚Üí  \"absolute\": {\n   179‚Üí    \"Fz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   180‚Üí    \"Cz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   181‚Üí    \"Pz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   182‚Üí    \"F3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   183‚Üí    \"F4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   184‚Üí    \"C3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   185‚Üí    \"C4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   186‚Üí    \"P3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   187‚Üí    \"P4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 }\n   188‚Üí  },\n   189‚Üí  \"relative\": {\n   190‚Üí    \"Fz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   191‚Üí    \"Cz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   192‚Üí    \"Pz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   193‚Üí    \"F3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   194‚Üí    \"F4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   195‚Üí    \"C3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   196‚Üí    \"C4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   197‚Üí    \"P3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   198‚Üí    \"P4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 }\n   199‚Üí  },\n   200‚Üí  \"special\": {\n   201‚Üí    \"alphaPeak\": 10.0,\n   202‚Üí    \"O1\": 10.0\n   203‚Üí  }\n   204‚Üí}\n   205‚Üí\n   206‚ÜíPDF Content:\n   207‚Üí${pdfText.substring(0, 15000)}`;\n   208‚Üí\n   209‚Üí      const response = await openai.chat.completions.create({\n   210‚Üí        model: 'gpt-4-turbo-preview',\n   211‚Üí        messages: [\n   212‚Üí          {\n   213‚Üí            role: 'system',\n   214‚Üí            content: 'You are an expert at extracting structured QEEG data from medical reports. Always return valid JSON.'\n   215‚Üí          },\n   216‚Üí          {\n   217‚Üí            role: 'user',\n   218‚Üí            content: prompt\n   219‚Üí          }\n   220‚Üí        ],\n   221‚Üí        temperature: 0.1,\n   222‚Üí        response_format: { type: 'json_object' }\n   223‚Üí      });\n   224‚Üí\n   225‚Üí      const extractedData = JSON.parse(response.choices[0].message.content);\n   226‚Üí      console.log(`  ‚úÖ PDF data extracted successfully (${condition})`);\n   227‚Üí\n   228‚Üí      // Add detailed logging\n   229‚Üí      console.log(`  üìä Data extraction summary (${condition}):`);\n   230‚Üí      console.log(`     - Absolute power channels: ${Object.keys(extractedData.absolute || {}).length}`);\n   231‚Üí      console.log(`     - Relative power channels: ${Object.keys(extractedData.relative || {}).length}`);\n   232‚Üí      console.log(`     - Special values: ${JSON.stringify(extractedData.special || {})}`);\n   233‚Üí\n   234‚Üí      // Validate extracted data has minimum required fields\n   235‚Üí      const requiredChannels = ['Fz', 'Cz', 'Pz', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4'];\n   236‚Üí      const absoluteChannels = Object.keys(extractedData.absolute || {});\n   237‚Üí      const relativeChannels = Object.keys(extractedData.relative || {});\n   238‚Üí\n   239‚Üí      const missingAbsolute = requiredChannels.filter(ch => !absoluteChannels.includes(ch));\n   240‚Üí      const missingRelative = requiredChannels.filter(ch => !relativeChannels.includes(ch));\n   241‚Üí\n   242‚Üí      if (missingAbsolute.length > 0) {\n   243‚Üí        console.warn(`  ‚ö†Ô∏è  Missing absolute power channels: ${missingAbsolute.join(', ')}`);\n   244‚Üí      }\n   245‚Üí      if (missingRelative.length > 0) {\n   246‚Üí        console.warn(`  ‚ö†Ô∏è  Missing relative power channels: ${missingRelative.join(', ')}`);\n   247‚Üí      }\n   248‚Üí\n   249‚Üí      return extractedData;\n   250‚Üí\n   251‚Üí    } catch (error) {\n   252‚Üí      console.error(`  ‚ùå OpenAI API error (${condition}):`, error.message);\n   253‚Üí\n   254‚Üí      // Log more details for debugging\n   255‚Üí      if (error.response) {\n   256‚Üí        console.error(`  ‚ùå OpenAI API Status:`, error.response.status);\n   257‚Üí        console.error(`  ‚ùå OpenAI API Error:`, error.response.data);\n   258‚Üí      }\n   259‚Üí\n   260‚Üí      // Re-throw with more context instead of using fallback\n   261‚Üí      const enhancedError = new Error(`Failed to extract QEEG data from PDF (${condition}): ${error.message}`);\n   262‚Üí      enhancedError.code = 'PDF_EXTRACTION_FAILED';\n   263‚Üí      enhancedError.originalError = error;\n   264‚Üí      enhancedError.condition = condition;\n   265‚Üí      throw enhancedError;\n   266‚Üí    }\n   267‚Üí  }\n   268‚Üí\n   269‚Üí  /**\n   270‚Üí   * Parse CSV file\n   271‚Üí   */\n   272‚Üí  static parseCSV(file) {\n   273‚Üí    console.log('  üìä Parsing CSV file...');\n   274‚Üí\n   275‚Üí    // Read CSV file\n   276‚Üí    const workbook = XLSX.readFile(file.path);\n   277‚Üí    const sheetName = workbook.SheetNames[0];\n   278‚Üí    const worksheet = workbook.Sheets[sheetName];\n   279‚Üí    const jsonData = XLSX.utils.sheet_to_json(worksheet);\n   280‚Üí\n   281‚Üí    // Convert CSV data to our format\n   282‚Üí    const data = this.convertCSVToFormat(jsonData);\n   283‚Üí\n   284‚Üí    console.log('  ‚úÖ CSV parsed successfully');\n   285‚Üí    return data;\n   286‚Üí  }\n   287‚Üí\n   288‚Üí  /**\n   289‚Üí   * Parse Excel file\n   290‚Üí   */\n   291‚Üí  static parseExcel(file) {\n   292‚Üí    console.log('  üìä Parsing Excel file...');\n   293‚Üí\n   294‚Üí    // Read Excel file\n   295‚Üí    const workbook = XLSX.readFile(file.path);\n   296‚Üí    const sheetName = workbook.SheetNames[0];\n   297‚Üí    const worksheet = workbook.Sheets[sheetName];\n   298‚Üí    const jsonData = XLSX.utils.sheet_to_json(worksheet);\n   299‚Üí\n   300‚Üí    // Convert Excel data to our format\n   301‚Üí    const data = this.convertExcelToFormat(jsonData);\n   302‚Üí\n   303‚Üí    console.log('  ‚úÖ Excel parsed successfully');\n   304‚Üí    return data;\n   305‚Üí  }\n   306‚Üí\n   307‚Üí  /**\n   308‚Üí   * Convert CSV data to expected format\n   309‚Üí   */\n   310‚Üí  static convertCSVToFormat(csvData) {\n   311‚Üí    // Assuming CSV has structure: Channel, PowerType, Delta, Theta, Alpha, Beta, HiBeta\n   312‚Üí    const result = {\n   313‚Üí      absolute: {},\n   314‚Üí      relative: {},\n   315‚Üí      special: { alphaPeak: 10.0, O1: 10.0 }\n   316‚Üí    };\n   317‚Üí\n   318‚Üí    const channels = ['Fz', 'Cz', 'Pz', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4'];\n   319‚Üí    const bands = ['Delta', 'Theta', 'Alpha', 'Beta', 'HiBeta'];\n   320‚Üí\n   321‚Üí    for (const row of csvData) {\n   322‚Üí      const channel = row.Channel;\n   323‚Üí      const powerType = row.PowerType?.toLowerCase();\n   324‚Üí\n   325‚Üí      if (channels.includes(channel) && (powerType === 'absolute' || powerType === 'relative')) {\n   326‚Üí        result[powerType][channel] = {\n   327‚Üí          Delta: parseFloat(row.Delta) || 0,\n   328‚Üí          Theta: parseFloat(row.Theta) || 0,\n   329‚Üí          Alpha: parseFloat(row.Alpha) || 0,\n   330‚Üí          Beta: parseFloat(row.Beta) || 0,\n   331‚Üí          HiBeta: parseFloat(row.HiBeta || row.HighBeta) || 0\n   332‚Üí        };\n   333‚Üí      }\n   334‚Üí    }\n   335‚Üí\n   336‚Üí    return result;\n   337‚Üí  }\n   338‚Üí\n   339‚Üí  /**\n   340‚Üí   * Convert Excel data to expected format (same as CSV for now)\n   341‚Üí   */\n   342‚Üí  static convertExcelToFormat(excelData) {\n   343‚Üí    return this.convertCSVToFormat(excelData);\n   344‚Üí  }\n   345‚Üí}\n   346‚Üí\n   347‚Üímodule.exports = QEEGParser;\n   348‚Üí\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"2e50a8d4-76f6-4fec-a451-3d089891f1c7","timestamp":"2025-12-02T09:00:37.644Z","toolUseResult":{"type":"text","file":{"filePath":"D:\\Todays\\Neuro360\\server\\services\\qeegParser.js","content":"const fs = require('fs');\nconst path = require('path');\nconst OpenAI = require('openai');\nconst pdfParse = require('pdf-parse');\nconst XLSX = require('xlsx');\n\n// Initialize OpenAI client\nconst openai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY\n});\n\nclass QEEGParser {\n  /**\n   * Validate OpenAI API key is configured and appears valid\n   * @throws {Error} if API key is missing or invalid format\n   */\n  static validateAPIKey() {\n    const apiKey = process.env.OPENAI_API_KEY;\n\n    // Check if key exists\n    if (!apiKey || apiKey.trim() === '') {\n      const error = new Error('OPENAI_API_KEY environment variable is not set');\n      error.code = 'MISSING_API_KEY';\n      throw error;\n    }\n\n    // Check if key is placeholder\n    if (apiKey === 'your-openai-api-key-here' || apiKey.includes('placeholder')) {\n      const error = new Error('OPENAI_API_KEY is set to placeholder value. Please configure a valid OpenAI API key.');\n      error.code = 'INVALID_API_KEY';\n      throw error;\n    }\n\n    // Check key format (OpenAI keys start with sk-)\n    if (!apiKey.startsWith('sk-')) {\n      const error = new Error('OPENAI_API_KEY has invalid format. OpenAI keys should start with \"sk-\"');\n      error.code = 'INVALID_API_KEY_FORMAT';\n      throw error;\n    }\n\n    console.log('‚úÖ OpenAI API key validation passed');\n    return true;\n  }\n\n  /**\n   * Test OpenAI API connection with a simple request\n   * @returns {Promise<boolean>} true if connection successful\n   * @throws {Error} if connection fails\n   */\n  static async testAPIConnection() {\n    try {\n      this.validateAPIKey();\n\n      console.log('üîå Testing OpenAI API connection...');\n\n      const response = await openai.chat.completions.create({\n        model: 'gpt-4-turbo-preview',\n        messages: [\n          { role: 'user', content: 'Reply with OK' }\n        ],\n        max_tokens: 5\n      });\n\n      if (response.choices && response.choices.length > 0) {\n        console.log('‚úÖ OpenAI API connection successful');\n        return true;\n      } else {\n        throw new Error('OpenAI API returned unexpected response');\n      }\n\n    } catch (error) {\n      console.error('‚ùå OpenAI API connection test failed:', error.message);\n      const enhancedError = new Error(`OpenAI API connection test failed: ${error.message}`);\n      enhancedError.code = 'API_CONNECTION_FAILED';\n      enhancedError.originalError = error;\n      throw enhancedError;\n    }\n  }\n\n  /**\n   * Main method to parse uploaded files\n   * @param {Object} eyesOpenFile - Multer file object for Eyes Open data\n   * @param {Object} eyesClosedFile - Multer file object for Eyes Closed data\n   * @returns {Object} Parsed QEEG data\n   */\n  static async parse(eyesOpenFile, eyesClosedFile) {\n    try {\n      console.log('üìÑ Parsing QEEG files...');\n      console.log('  - Eyes Open:', eyesOpenFile?.originalname);\n      console.log('  - Eyes Closed:', eyesClosedFile?.originalname);\n\n      // Determine file types\n      const eoFileType = this.getFileType(eyesOpenFile.originalname);\n      const ecFileType = this.getFileType(eyesClosedFile.originalname);\n\n      // Parse each file\n      const eyesOpenData = await this.parseFile(eyesOpenFile, eoFileType, 'EO');\n      const eyesClosedData = await this.parseFile(eyesClosedFile, ecFileType, 'EC');\n\n      // Combine data\n      const combinedData = {\n        EO: eyesOpenData,\n        EC: eyesClosedData\n      };\n\n      console.log('‚úÖ QEEG files parsed successfully');\n      return combinedData;\n\n    } catch (error) {\n      console.error('‚ùå Error parsing QEEG files:', error);\n      throw new Error(`Failed to parse QEEG files: ${error.message}`);\n    }\n  }\n\n  /**\n   * Determine file type from filename\n   */\n  static getFileType(filename) {\n    const ext = path.extname(filename).toLowerCase();\n    if (ext === '.pdf') return 'pdf';\n    if (ext === '.csv') return 'csv';\n    if (ext === '.xlsx' || ext === '.xls') return 'excel';\n    throw new Error(`Unsupported file type: ${ext}`);\n  }\n\n  /**\n   * Parse a single file based on its type\n   */\n  static async parseFile(file, fileType, condition) {\n    if (fileType === 'pdf') {\n      return await this.parsePDF(file, condition);\n    } else if (fileType === 'csv') {\n      return this.parseCSV(file);\n    } else if (fileType === 'excel') {\n      return this.parseExcel(file);\n    }\n    throw new Error(`Unknown file type: ${fileType}`);\n  }\n\n  /**\n   * Parse PDF file using OpenAI Vision API\n   */\n  static async parsePDF(file, condition) {\n    console.log(`  üîç Parsing PDF with OpenAI Vision API (${condition})...`);\n\n    try {\n      // Validate API key before attempting to use it\n      this.validateAPIKey();\n\n\n      // Read PDF file\n      const dataBuffer = fs.readFileSync(file.path);\n      const pdfData = await pdfParse(dataBuffer);\n\n      // Extract text from PDF\n      const pdfText = pdfData.text;\n\n    // Use OpenAI to extract QEEG tables\n    const prompt = `You are a QEEG data extraction expert. Extract the following data from this ${condition === 'EO' ? 'Eyes Open' : 'Eyes Closed'} QEEG report:\n\nExtract two tables:\n1. **Absolute Power (ŒºV¬≤)** table\n2. **Relative Power (%)** table\n\nFor each table, extract values for these EEG channels: FP1, FP2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2\n\nFor each channel, extract values for these frequency bands:\n- Delta\n- Theta\n- Alpha\n- Beta\n- HiBeta (High Beta)\n\nAlso extract Alpha Peak Frequency (APF) if available.\n\nReturn the data in this EXACT JSON format:\n{\n  \"absolute\": {\n    \"Fz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"Cz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"Pz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"F3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"F4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"C3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"C4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"P3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"P4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 }\n  },\n  \"relative\": {\n    \"Fz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"Cz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"Pz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"F3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"F4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"C3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"C4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"P3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"P4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 }\n  },\n  \"special\": {\n    \"alphaPeak\": 10.0,\n    \"O1\": 10.0\n  }\n}\n\nPDF Content:\n${pdfText.substring(0, 15000)}`;\n\n      const response = await openai.chat.completions.create({\n        model: 'gpt-4-turbo-preview',\n        messages: [\n          {\n            role: 'system',\n            content: 'You are an expert at extracting structured QEEG data from medical reports. Always return valid JSON.'\n          },\n          {\n            role: 'user',\n            content: prompt\n          }\n        ],\n        temperature: 0.1,\n        response_format: { type: 'json_object' }\n      });\n\n      const extractedData = JSON.parse(response.choices[0].message.content);\n      console.log(`  ‚úÖ PDF data extracted successfully (${condition})`);\n\n      // Add detailed logging\n      console.log(`  üìä Data extraction summary (${condition}):`);\n      console.log(`     - Absolute power channels: ${Object.keys(extractedData.absolute || {}).length}`);\n      console.log(`     - Relative power channels: ${Object.keys(extractedData.relative || {}).length}`);\n      console.log(`     - Special values: ${JSON.stringify(extractedData.special || {})}`);\n\n      // Validate extracted data has minimum required fields\n      const requiredChannels = ['Fz', 'Cz', 'Pz', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4'];\n      const absoluteChannels = Object.keys(extractedData.absolute || {});\n      const relativeChannels = Object.keys(extractedData.relative || {});\n\n      const missingAbsolute = requiredChannels.filter(ch => !absoluteChannels.includes(ch));\n      const missingRelative = requiredChannels.filter(ch => !relativeChannels.includes(ch));\n\n      if (missingAbsolute.length > 0) {\n        console.warn(`  ‚ö†Ô∏è  Missing absolute power channels: ${missingAbsolute.join(', ')}`);\n      }\n      if (missingRelative.length > 0) {\n        console.warn(`  ‚ö†Ô∏è  Missing relative power channels: ${missingRelative.join(', ')}`);\n      }\n\n      return extractedData;\n\n    } catch (error) {\n      console.error(`  ‚ùå OpenAI API error (${condition}):`, error.message);\n\n      // Log more details for debugging\n      if (error.response) {\n        console.error(`  ‚ùå OpenAI API Status:`, error.response.status);\n        console.error(`  ‚ùå OpenAI API Error:`, error.response.data);\n      }\n\n      // Re-throw with more context instead of using fallback\n      const enhancedError = new Error(`Failed to extract QEEG data from PDF (${condition}): ${error.message}`);\n      enhancedError.code = 'PDF_EXTRACTION_FAILED';\n      enhancedError.originalError = error;\n      enhancedError.condition = condition;\n      throw enhancedError;\n    }\n  }\n\n  /**\n   * Parse CSV file\n   */\n  static parseCSV(file) {\n    console.log('  üìä Parsing CSV file...');\n\n    // Read CSV file\n    const workbook = XLSX.readFile(file.path);\n    const sheetName = workbook.SheetNames[0];\n    const worksheet = workbook.Sheets[sheetName];\n    const jsonData = XLSX.utils.sheet_to_json(worksheet);\n\n    // Convert CSV data to our format\n    const data = this.convertCSVToFormat(jsonData);\n\n    console.log('  ‚úÖ CSV parsed successfully');\n    return data;\n  }\n\n  /**\n   * Parse Excel file\n   */\n  static parseExcel(file) {\n    console.log('  üìä Parsing Excel file...');\n\n    // Read Excel file\n    const workbook = XLSX.readFile(file.path);\n    const sheetName = workbook.SheetNames[0];\n    const worksheet = workbook.Sheets[sheetName];\n    const jsonData = XLSX.utils.sheet_to_json(worksheet);\n\n    // Convert Excel data to our format\n    const data = this.convertExcelToFormat(jsonData);\n\n    console.log('  ‚úÖ Excel parsed successfully');\n    return data;\n  }\n\n  /**\n   * Convert CSV data to expected format\n   */\n  static convertCSVToFormat(csvData) {\n    // Assuming CSV has structure: Channel, PowerType, Delta, Theta, Alpha, Beta, HiBeta\n    const result = {\n      absolute: {},\n      relative: {},\n      special: { alphaPeak: 10.0, O1: 10.0 }\n    };\n\n    const channels = ['Fz', 'Cz', 'Pz', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4'];\n    const bands = ['Delta', 'Theta', 'Alpha', 'Beta', 'HiBeta'];\n\n    for (const row of csvData) {\n      const channel = row.Channel;\n      const powerType = row.PowerType?.toLowerCase();\n\n      if (channels.includes(channel) && (powerType === 'absolute' || powerType === 'relative')) {\n        result[powerType][channel] = {\n          Delta: parseFloat(row.Delta) || 0,\n          Theta: parseFloat(row.Theta) || 0,\n          Alpha: parseFloat(row.Alpha) || 0,\n          Beta: parseFloat(row.Beta) || 0,\n          HiBeta: parseFloat(row.HiBeta || row.HighBeta) || 0\n        };\n      }\n    }\n\n    return result;\n  }\n\n  /**\n   * Convert Excel data to expected format (same as CSV for now)\n   */\n  static convertExcelToFormat(excelData) {\n    return this.convertCSVToFormat(excelData);\n  }\n}\n\nmodule.exports = QEEGParser;\n","numLines":348,"startLine":1,"totalLines":348}}}
{"parentUuid":"2e50a8d4-76f6-4fec-a451-3d089891f1c7","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01HUPBDZxS5UxLxT7ZY5X56z","type":"tool_result","content":"     1‚Üí/**\n     2‚Üí * QEEG Algorithm Calculator\n     3‚Üí * Based on Rhea's Report - Calculates 7 brain health parameters\n     4‚Üí * Each parameter has 3 sub-metrics, scored 0-3, classified as Low/Medium/High\n     5‚Üí */\n     6‚Üí\n     7‚Üíclass AlgorithmCalculator {\n     8‚Üí  constructor(qeegData) {\n     9‚Üí    this.data = qeegData;\n    10‚Üí    this.results = {\n    11‚Üí      parameters: [],\n    12‚Üí      rawCalculations: {},\n    13‚Üí      overallScore: 0\n    14‚Üí    };\n    15‚Üí  }\n    16‚Üí\n    17‚Üí  /**\n    18‚Üí   * Main calculation method - calculates all 7 parameters\n    19‚Üí   */\n    20‚Üí  calculate() {\n    21‚Üí    const parameters = [\n    22‚Üí      this.calculateCognition(),\n    23‚Üí      this.calculateStress(),\n    24‚Üí      this.calculateFocusAttention(),\n    25‚Üí      this.calculateBurnoutFatigue(),\n    26‚Üí      this.calculateEmotionalRegulation(),\n    27‚Üí      this.calculateLearning(),\n    28‚Üí      this.calculateCreativity()\n    29‚Üí    ];\n    30‚Üí\n    31‚Üí    this.results.parameters = parameters;\n    32‚Üí    this.results.overallScore = parameters.reduce((sum, p) => sum + p.score, 0);\n    33‚Üí\n    34‚Üí    return this.results;\n    35‚Üí  }\n    36‚Üí\n    37‚Üí  // ==================== HELPER METHODS ====================\n    38‚Üí\n    39‚Üí  /**\n    40‚Üí   * Get value from QEEG data table\n    41‚Üí   * @param {string} condition - 'EC' (Eyes Closed) or 'EO' (Eyes Open)\n    42‚Üí   * @param {string} powerType - 'absolute' or 'relative'\n    43‚Üí   * @param {string} channel - e.g., 'Fz', 'Cz', 'Pz'\n    44‚Üí   * @param {string} band - e.g., 'Theta', 'Alpha', 'Beta', 'HiBeta', 'Delta'\n    45‚Üí   */\n    46‚Üí  getValue(condition, powerType, channel, band) {\n    47‚Üí    try {\n    48‚Üí      return this.data[condition][powerType][channel][band];\n    49‚Üí    } catch (error) {\n    50‚Üí      console.error(`Error getting value: ${condition}.${powerType}.${channel}.${band}`);\n    51‚Üí      return null;\n    52‚Üí    }\n    53‚Üí  }\n    54‚Üí\n    55‚Üí  /**\n    56‚Üí   * Score a metric based on threshold\n    57‚Üí   */\n    58‚Üí  scoreMetric(value, threshold, comparison = 'less') {\n    59‚Üí    if (value === null || value === undefined) return 0;\n    60‚Üí\n    61‚Üí    if (comparison === 'less') {\n    62‚Üí      return value < threshold ? 1 : 0;\n    63‚Üí    } else if (comparison === 'more') {\n    64‚Üí      return value > threshold ? 1 : 0;\n    65‚Üí    } else if (comparison === 'equal') {\n    66‚Üí      return value === threshold ? 1 : 0;\n    67‚Üí    }\n    68‚Üí    return 0;\n    69‚Üí  }\n    70‚Üí\n    71‚Üí  /**\n    72‚Üí   * Classify score to bucket (Low/Medium/High)\n    73‚Üí   */\n    74‚Üí  classifyScore(score) {\n    75‚Üí    if (score <= 1) return 'Low';\n    76‚Üí    if (score === 2) return 'Medium';\n    77‚Üí    return 'High';\n    78‚Üí  }\n    79‚Üí\n    80‚Üí  // ==================== INDIVIDUAL METRICS ====================\n    81‚Üí\n    82‚Üí  /**\n    83‚Üí   * Focus Score (Theta:Beta Ratio) - Used in multiple parameters\n    84‚Üí   * Eyes Open, Absolute Power, Fz & Cz average\n    85‚Üí   * < 1.5 is normal\n    86‚Üí   */\n    87‚Üí  calculateFocusScore() {\n    88‚Üí    const fzTheta = this.getValue('EO', 'absolute', 'Fz', 'Theta');\n    89‚Üí    const fzBeta = this.getValue('EO', 'absolute', 'Fz', 'Beta');\n    90‚Üí    const czTheta = this.getValue('EO', 'absolute', 'Cz', 'Theta');\n    91‚Üí    const czBeta = this.getValue('EO', 'absolute', 'Cz', 'Beta');\n    92‚Üí\n    93‚Üí    if (!fzTheta || !fzBeta || !czTheta || !czBeta) return { value: null, score: 0 };\n    94‚Üí\n    95‚Üí    const fzRatio = fzTheta / fzBeta;\n    96‚Üí    const czRatio = czTheta / czBeta;\n    97‚Üí    const avgRatio = (fzRatio + czRatio) / 2;\n    98‚Üí\n    99‚Üí    return {\n   100‚Üí      value: avgRatio,\n   101‚Üí      score: this.scoreMetric(avgRatio, 1.5, 'less'),\n   102‚Üí      description: `Theta:Beta Ratio = ${avgRatio.toFixed(2)} (< 1.5 is normal)`,\n   103‚Üí      details: { fzRatio: fzRatio.toFixed(2), czRatio: czRatio.toFixed(2) }\n   104‚Üí    };\n   105‚Üí  }\n   106‚Üí\n   107‚Üí  /**\n   108‚Üí   * Alpha Peak - Used in multiple parameters\n   109‚Üí   * Eyes Closed, Special (highest frequency at Pz or below)\n   110‚Üí   * > 9 Hz is normal\n   111‚Üí   */\n   112‚Üí  calculateAlphaPeak() {\n   113‚Üí    // Assuming alphaPeak is provided in the data\n   114‚Üí    const alphaPeak = this.data.EC?.special?.alphaPeak || this.data.EC?.special?.O1 || 10.0;\n   115‚Üí\n   116‚Üí    return {\n   117‚Üí      value: alphaPeak,\n   118‚Üí      score: this.scoreMetric(alphaPeak, 9, 'more'),\n   119‚Üí      description: `Alpha Peak = ${alphaPeak.toFixed(1)} Hz (> 9 is normal)`\n   120‚Üí    };\n   121‚Üí  }\n   122‚Üí\n   123‚Üí  /**\n   124‚Üí   * Alpha:Theta Balance - Used in multiple parameters\n   125‚Üí   * Eyes Closed, Absolute Power, Fz, Cz, Pz\n   126‚Üí   * Order Pz > Cz > Fz is normal (1 point), otherwise 0\n   127‚Üí   */\n   128‚Üí  calculateAlphaThetaBalance() {\n   129‚Üí    const fzAlpha = this.getValue('EC', 'absolute', 'Fz', 'Alpha');\n   130‚Üí    const fzTheta = this.getValue('EC', 'absolute', 'Fz', 'Theta');\n   131‚Üí    const czAlpha = this.getValue('EC', 'absolute', 'Cz', 'Alpha');\n   132‚Üí    const czTheta = this.getValue('EC', 'absolute', 'Cz', 'Theta');\n   133‚Üí    const pzAlpha = this.getValue('EC', 'absolute', 'Pz', 'Alpha');\n   134‚Üí    const pzTheta = this.getValue('EC', 'absolute', 'Pz', 'Theta');\n   135‚Üí\n   136‚Üí    if (!fzAlpha || !fzTheta || !czAlpha || !czTheta || !pzAlpha || !pzTheta) {\n   137‚Üí      return { value: null, score: 0 };\n   138‚Üí    }\n   139‚Üí\n   140‚Üí    const fzRatio = fzAlpha / fzTheta;\n   141‚Üí    const czRatio = czAlpha / czTheta;\n   142‚Üí    const pzRatio = pzAlpha / pzTheta;\n   143‚Üí\n   144‚Üí    const isNormalOrder = pzRatio > czRatio && czRatio > fzRatio;\n   145‚Üí\n   146‚Üí    return {\n   147‚Üí      value: { fz: fzRatio.toFixed(2), cz: czRatio.toFixed(2), pz: pzRatio.toFixed(2) },\n   148‚Üí      score: isNormalOrder ? 1 : 0,\n   149‚Üí      description: `Alpha:Theta Order = ${isNormalOrder ? 'Pz > Cz > Fz (Normal)' : 'Abnormal order'}`,\n   150‚Üí      details: { fzRatio, czRatio, pzRatio, order: isNormalOrder }\n   151‚Üí    };\n   152‚Üí  }\n   153‚Üí\n   154‚Üí  /**\n   155‚Üí   * Arousal Score (HiBeta:Beta Ratio) - Used in multiple parameters\n   156‚Üí   * Eyes Open, Absolute Power, Fz & Cz average\n   157‚Üí   * < 1 is normal\n   158‚Üí   */\n   159‚Üí  calculateArousalScore() {\n   160‚Üí    const fzBeta = this.getValue('EO', 'absolute', 'Fz', 'Beta');\n   161‚Üí    const fzHiBeta = this.getValue('EO', 'absolute', 'Fz', 'HiBeta');\n   162‚Üí    const czBeta = this.getValue('EO', 'absolute', 'Cz', 'Beta');\n   163‚Üí    const czHiBeta = this.getValue('EO', 'absolute', 'Cz', 'HiBeta');\n   164‚Üí\n   165‚Üí    if (!fzBeta || !fzHiBeta || !czBeta || !czHiBeta) return { value: null, score: 0 };\n   166‚Üí\n   167‚Üí    const fzRatio = fzHiBeta / fzBeta;\n   168‚Üí    const czRatio = czHiBeta / czBeta;\n   169‚Üí    const avgRatio = (fzRatio + czRatio) / 2;\n   170‚Üí\n   171‚Üí    return {\n   172‚Üí      value: avgRatio,\n   173‚Üí      score: this.scoreMetric(avgRatio, 1, 'less'),\n   174‚Üí      description: `Arousal Score = ${avgRatio.toFixed(2)} (< 1 is normal)`,\n   175‚Üí      details: { fzRatio: fzRatio.toFixed(2), czRatio: czRatio.toFixed(2) }\n   176‚Üí    };\n   177‚Üí  }\n   178‚Üí\n   179‚Üí  /**\n   180‚Üí   * Relaxation Score - Used in multiple parameters\n   181‚Üí   * Eyes Closed, Absolute Power, Pz, Alpha/Beta\n   182‚Üí   * > 10 is healthy\n   183‚Üí   */\n   184‚Üí  calculateRelaxationScore() {\n   185‚Üí    const pzAlpha = this.getValue('EC', 'absolute', 'Pz', 'Alpha');\n   186‚Üí    const pzBeta = this.getValue('EC', 'absolute', 'Pz', 'Beta');\n   187‚Üí\n   188‚Üí    if (!pzAlpha || !pzBeta) return { value: null, score: 0 };\n   189‚Üí\n   190‚Üí    const ratio = pzAlpha / pzBeta;\n   191‚Üí\n   192‚Üí    return {\n   193‚Üí      value: ratio,\n   194‚Üí      score: this.scoreMetric(ratio, 10, 'more'),\n   195‚Üí      description: `Relaxation Score = ${ratio.toFixed(2)} (> 10 is healthy)`\n   196‚Üí    };\n   197‚Üí  }\n   198‚Üí\n   199‚Üí  /**\n   200‚Üí   * Regeneration (Alpha Modulation) - Used in multiple parameters\n   201‚Üí   * EO & EC, Relative Power, Pz, (EC-EO)/EC * 100\n   202‚Üí   * > 30% is healthy\n   203‚Üí   */\n   204‚Üí  calculateRegeneration() {\n   205‚Üí    const ecAlpha = this.getValue('EC', 'relative', 'Pz', 'Alpha');\n   206‚Üí    const eoAlpha = this.getValue('EO', 'relative', 'Pz', 'Alpha');\n   207‚Üí\n   208‚Üí    if (!ecAlpha || !eoAlpha) return { value: null, score: 0 };\n   209‚Üí\n   210‚Üí    const modulation = ((ecAlpha - eoAlpha) / ecAlpha) * 100;\n   211‚Üí\n   212‚Üí    return {\n   213‚Üí      value: modulation,\n   214‚Üí      score: this.scoreMetric(modulation, 30, 'more'),\n   215‚Üí      description: `Alpha Modulation = ${modulation.toFixed(1)}% (> 30% is healthy)`\n   216‚Üí    };\n   217‚Üí  }\n   218‚Üí\n   219‚Üí  /**\n   220‚Üí   * Focus Theta (Relative Power) - Used in Focus & Attention\n   221‚Üí   * Eyes Open, Relative Power, Fz & Cz average\n   222‚Üí   * < 20% is normal\n   223‚Üí   */\n   224‚Üí  calculateFocusTheta() {\n   225‚Üí    const fzTheta = this.getValue('EO', 'relative', 'Fz', 'Theta');\n   226‚Üí    const czTheta = this.getValue('EO', 'relative', 'Cz', 'Theta');\n   227‚Üí\n   228‚Üí    if (!fzTheta || !czTheta) return { value: null, score: 0 };\n   229‚Üí\n   230‚Üí    const avgTheta = (fzTheta + czTheta) / 2;\n   231‚Üí\n   232‚Üí    return {\n   233‚Üí      value: avgTheta,\n   234‚Üí      score: this.scoreMetric(avgTheta, 20, 'less'),\n   235‚Üí      description: `Focus Theta = ${avgTheta.toFixed(1)}% (< 20% is normal)`\n   236‚Üí    };\n   237‚Üí  }\n   238‚Üí\n   239‚Üí  /**\n   240‚Üí   * Excessive Delta - Used in Burnout & Fatigue\n   241‚Üí   * Eyes Open, Relative Power, avg of Fz, C3, Cz, C4, P3, Pz, P4\n   242‚Üí   * < 70% is normal\n   243‚Üí   */\n   244‚Üí  calculateExcessiveDelta() {\n   245‚Üí    const channels = ['Fz', 'C3', 'Cz', 'C4', 'P3', 'Pz', 'P4'];\n   246‚Üí    let sum = 0;\n   247‚Üí    let count = 0;\n   248‚Üí\n   249‚Üí    for (const channel of channels) {\n   250‚Üí      const delta = this.getValue('EO', 'relative', channel, 'Delta');\n   251‚Üí      if (delta !== null) {\n   252‚Üí        sum += delta;\n   253‚Üí        count++;\n   254‚Üí      }\n   255‚Üí    }\n   256‚Üí\n   257‚Üí    if (count === 0) return { value: null, score: 0 };\n   258‚Üí\n   259‚Üí    const avgDelta = sum / count;\n   260‚Üí\n   261‚Üí    return {\n   262‚Üí      value: avgDelta,\n   263‚Üí      score: this.scoreMetric(avgDelta, 70, 'less'),\n   264‚Üí      description: `Excessive Delta = ${avgDelta.toFixed(1)}% (< 70% is normal)`\n   265‚Üí    };\n   266‚Üí  }\n   267‚Üí\n   268‚Üí  /**\n   269‚Üí   * Alpha Asymmetry (Frontal) - Used in Emotional Regulation\n   270‚Üí   * Eyes Closed, Absolute Power, F3 & F4\n   271‚Üí   * F4/F3 < 1 is normal\n   272‚Üí   */\n   273‚Üí  calculateAlphaAsymmetry() {\n   274‚Üí    const f3Alpha = this.getValue('EC', 'absolute', 'F3', 'Alpha');\n   275‚Üí    const f4Alpha = this.getValue('EC', 'absolute', 'F4', 'Alpha');\n   276‚Üí\n   277‚Üí    if (!f3Alpha || !f4Alpha) return { value: null, score: 0 };\n   278‚Üí\n   279‚Üí    const ratio = f4Alpha / f3Alpha;\n   280‚Üí\n   281‚Üí    return {\n   282‚Üí      value: ratio,\n   283‚Üí      score: this.scoreMetric(ratio, 1, 'less'),\n   284‚Üí      description: `Alpha Asymmetry = ${ratio.toFixed(2)} (< 1 is normal)`\n   285‚Üí    };\n   286‚Üí  }\n   287‚Üí\n   288‚Üí  // ==================== 7 PARAMETER CALCULATIONS ====================\n   289‚Üí\n   290‚Üí  /**\n   291‚Üí   * 1. Cognition\n   292‚Üí   * - Focus Score (Theta:Beta Ratio)\n   293‚Üí   * - Alpha Peak\n   294‚Üí   * - Alpha:Theta Balance\n   295‚Üí   */\n   296‚Üí  calculateCognition() {\n   297‚Üí    const metric1 = this.calculateFocusScore();\n   298‚Üí    const metric2 = this.calculateAlphaPeak();\n   299‚Üí    const metric3 = this.calculateAlphaThetaBalance();\n   300‚Üí\n   301‚Üí    const totalScore = metric1.score + metric2.score + metric3.score;\n   302‚Üí\n   303‚Üí    return {\n   304‚Üí      name: 'Cognition',\n   305‚Üí      score: totalScore,\n   306‚Üí      maxScore: 3,\n   307‚Üí      classification: this.classifyScore(totalScore),\n   308‚Üí      metrics: [\n   309‚Üí        { name: 'Focus Score (Theta:Beta)', ...metric1 },\n   310‚Üí        { name: 'Alpha Peak', ...metric2 },\n   311‚Üí        { name: 'Alpha:Theta Balance', ...metric3 }\n   312‚Üí      ]\n   313‚Üí    };\n   314‚Üí  }\n   315‚Üí\n   316‚Üí  /**\n   317‚Üí   * 2. Stress (Note: 0/3 is healthy, 3/3 is high stress)\n   318‚Üí   * - Arousal Score\n   319‚Üí   * - Relaxation Score\n   320‚Üí   * - Regeneration\n   321‚Üí   */\n   322‚Üí  calculateStress() {\n   323‚Üí    const metric1 = this.calculateArousalScore();\n   324‚Üí    const metric2 = this.calculateRelaxationScore();\n   325‚Üí    const metric3 = this.calculateRegeneration();\n   326‚Üí\n   327‚Üí    const totalScore = metric1.score + metric2.score + metric3.score;\n   328‚Üí\n   329‚Üí    return {\n   330‚Üí      name: 'Stress',\n   331‚Üí      score: totalScore,\n   332‚Üí      maxScore: 3,\n   333‚Üí      classification: this.classifyScore(totalScore),\n   334‚Üí      metrics: [\n   335‚Üí        { name: 'Arousal Score', ...metric1 },\n   336‚Üí        { name: 'Relaxation Score', ...metric2 },\n   337‚Üí        { name: 'Regeneration (Alpha Modulation)', ...metric3 }\n   338‚Üí      ]\n   339‚Üí    };\n   340‚Üí  }\n   341‚Üí\n   342‚Üí  /**\n   343‚Üí   * 3. Focus & Attention\n   344‚Üí   * - Focus Theta\n   345‚Üí   * - Alpha:Theta Balance\n   346‚Üí   * - Focus Score (Theta:Beta)\n   347‚Üí   */\n   348‚Üí  calculateFocusAttention() {\n   349‚Üí    const metric1 = this.calculateFocusTheta();\n   350‚Üí    const metric2 = this.calculateAlphaThetaBalance();\n   351‚Üí    const metric3 = this.calculateFocusScore();\n   352‚Üí\n   353‚Üí    const totalScore = metric1.score + metric2.score + metric3.score;\n   354‚Üí\n   355‚Üí    return {\n   356‚Üí      name: 'Focus & Attention',\n   357‚Üí      score: totalScore,\n   358‚Üí      maxScore: 3,\n   359‚Üí      classification: this.classifyScore(totalScore),\n   360‚Üí      metrics: [\n   361‚Üí        { name: 'Focus Theta', ...metric1 },\n   362‚Üí        { name: 'Alpha:Theta Balance', ...metric2 },\n   363‚Üí        { name: 'Focus Score (Theta:Beta)', ...metric3 }\n   364‚Üí      ]\n   365‚Üí    };\n   366‚Üí  }\n   367‚Üí\n   368‚Üí  /**\n   369‚Üí   * 4. Burnout & Fatigue (Note: 0/3 is healthy)\n   370‚Üí   * - Arousal Score\n   371‚Üí   * - Relaxation Score\n   372‚Üí   * - Excessive Delta\n   373‚Üí   */\n   374‚Üí  calculateBurnoutFatigue() {\n   375‚Üí    const metric1 = this.calculateArousalScore();\n   376‚Üí    const metric2 = this.calculateRelaxationScore();\n   377‚Üí    const metric3 = this.calculateExcessiveDelta();\n   378‚Üí\n   379‚Üí    const totalScore = metric1.score + metric2.score + metric3.score;\n   380‚Üí\n   381‚Üí    return {\n   382‚Üí      name: 'Burnout & Fatigue',\n   383‚Üí      score: totalScore,\n   384‚Üí      maxScore: 3,\n   385‚Üí      classification: this.classifyScore(totalScore),\n   386‚Üí      metrics: [\n   387‚Üí        { name: 'Arousal Score', ...metric1 },\n   388‚Üí        { name: 'Relaxation Score', ...metric2 },\n   389‚Üí        { name: 'Excessive Delta', ...metric3 }\n   390‚Üí      ]\n   391‚Üí    };\n   392‚Üí  }\n   393‚Üí\n   394‚Üí  /**\n   395‚Üí   * 5. Emotional Regulation\n   396‚Üí   * - Alpha Asymmetry\n   397‚Üí   * - Arousal Score\n   398‚Üí   * - Regeneration\n   399‚Üí   */\n   400‚Üí  calculateEmotionalRegulation() {\n   401‚Üí    const metric1 = this.calculateAlphaAsymmetry();\n   402‚Üí    const metric2 = this.calculateArousalScore();\n   403‚Üí    const metric3 = this.calculateRegeneration();\n   404‚Üí\n   405‚Üí    const totalScore = metric1.score + metric2.score + metric3.score;\n   406‚Üí\n   407‚Üí    return {\n   408‚Üí      name: 'Emotional Regulation',\n   409‚Üí      score: totalScore,\n   410‚Üí      maxScore: 3,\n   411‚Üí      classification: this.classifyScore(totalScore),\n   412‚Üí      metrics: [\n   413‚Üí        { name: 'Alpha Asymmetry (Frontal)', ...metric1 },\n   414‚Üí        { name: 'Arousal Score', ...metric2 },\n   415‚Üí        { name: 'Regeneration (Alpha Modulation)', ...metric3 }\n   416‚Üí      ]\n   417‚Üí    };\n   418‚Üí  }\n   419‚Üí\n   420‚Üí  /**\n   421‚Üí   * 6. Learning\n   422‚Üí   * - Alpha Peak\n   423‚Üí   * - Focus Score (Theta:Beta)\n   424‚Üí   * - Arousal Score\n   425‚Üí   */\n   426‚Üí  calculateLearning() {\n   427‚Üí    const metric1 = this.calculateAlphaPeak();\n   428‚Üí    const metric2 = this.calculateFocusScore();\n   429‚Üí    const metric3 = this.calculateArousalScore();\n   430‚Üí\n   431‚Üí    const totalScore = metric1.score + metric2.score + metric3.score;\n   432‚Üí\n   433‚Üí    return {\n   434‚Üí      name: 'Learning',\n   435‚Üí      score: totalScore,\n   436‚Üí      maxScore: 3,\n   437‚Üí      classification: this.classifyScore(totalScore),\n   438‚Üí      metrics: [\n   439‚Üí        { name: 'Alpha Peak', ...metric1 },\n   440‚Üí        { name: 'Focus Score (Theta:Beta)', ...metric2 },\n   441‚Üí        { name: 'Arousal Score', ...metric3 }\n   442‚Üí      ]\n   443‚Üí    };\n   444‚Üí  }\n   445‚Üí\n   446‚Üí  /**\n   447‚Üí   * 7. Creativity\n   448‚Üí   * - Relaxation Score\n   449‚Üí   * - Focus Score (Theta:Beta)\n   450‚Üí   * - Alpha Peak\n   451‚Üí   */\n   452‚Üí  calculateCreativity() {\n   453‚Üí    const metric1 = this.calculateRelaxationScore();\n   454‚Üí    const metric2 = this.calculateFocusScore();\n   455‚Üí    const metric3 = this.calculateAlphaPeak();\n   456‚Üí\n   457‚Üí    const totalScore = metric1.score + metric2.score + metric3.score;\n   458‚Üí\n   459‚Üí    return {\n   460‚Üí      name: 'Creativity',\n   461‚Üí      score: totalScore,\n   462‚Üí      maxScore: 3,\n   463‚Üí      classification: this.classifyScore(totalScore),\n   464‚Üí      metrics: [\n   465‚Üí        { name: 'Relaxation Score', ...metric1 },\n   466‚Üí        { name: 'Focus Score (Theta:Beta)', ...metric2 },\n   467‚Üí        { name: 'Alpha Peak', ...metric3 }\n   468‚Üí      ]\n   469‚Üí    };\n   470‚Üí  }\n   471‚Üí}\n   472‚Üí\n   473‚Üímodule.exports = AlgorithmCalculator;\n   474‚Üí\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"50c2c37e-0f17-470d-8419-0aa80743d148","timestamp":"2025-12-02T09:00:37.647Z","toolUseResult":{"type":"text","file":{"filePath":"D:\\Todays\\Neuro360\\server\\services\\algorithmCalculator.js","content":"/**\n * QEEG Algorithm Calculator\n * Based on Rhea's Report - Calculates 7 brain health parameters\n * Each parameter has 3 sub-metrics, scored 0-3, classified as Low/Medium/High\n */\n\nclass AlgorithmCalculator {\n  constructor(qeegData) {\n    this.data = qeegData;\n    this.results = {\n      parameters: [],\n      rawCalculations: {},\n      overallScore: 0\n    };\n  }\n\n  /**\n   * Main calculation method - calculates all 7 parameters\n   */\n  calculate() {\n    const parameters = [\n      this.calculateCognition(),\n      this.calculateStress(),\n      this.calculateFocusAttention(),\n      this.calculateBurnoutFatigue(),\n      this.calculateEmotionalRegulation(),\n      this.calculateLearning(),\n      this.calculateCreativity()\n    ];\n\n    this.results.parameters = parameters;\n    this.results.overallScore = parameters.reduce((sum, p) => sum + p.score, 0);\n\n    return this.results;\n  }\n\n  // ==================== HELPER METHODS ====================\n\n  /**\n   * Get value from QEEG data table\n   * @param {string} condition - 'EC' (Eyes Closed) or 'EO' (Eyes Open)\n   * @param {string} powerType - 'absolute' or 'relative'\n   * @param {string} channel - e.g., 'Fz', 'Cz', 'Pz'\n   * @param {string} band - e.g., 'Theta', 'Alpha', 'Beta', 'HiBeta', 'Delta'\n   */\n  getValue(condition, powerType, channel, band) {\n    try {\n      return this.data[condition][powerType][channel][band];\n    } catch (error) {\n      console.error(`Error getting value: ${condition}.${powerType}.${channel}.${band}`);\n      return null;\n    }\n  }\n\n  /**\n   * Score a metric based on threshold\n   */\n  scoreMetric(value, threshold, comparison = 'less') {\n    if (value === null || value === undefined) return 0;\n\n    if (comparison === 'less') {\n      return value < threshold ? 1 : 0;\n    } else if (comparison === 'more') {\n      return value > threshold ? 1 : 0;\n    } else if (comparison === 'equal') {\n      return value === threshold ? 1 : 0;\n    }\n    return 0;\n  }\n\n  /**\n   * Classify score to bucket (Low/Medium/High)\n   */\n  classifyScore(score) {\n    if (score <= 1) return 'Low';\n    if (score === 2) return 'Medium';\n    return 'High';\n  }\n\n  // ==================== INDIVIDUAL METRICS ====================\n\n  /**\n   * Focus Score (Theta:Beta Ratio) - Used in multiple parameters\n   * Eyes Open, Absolute Power, Fz & Cz average\n   * < 1.5 is normal\n   */\n  calculateFocusScore() {\n    const fzTheta = this.getValue('EO', 'absolute', 'Fz', 'Theta');\n    const fzBeta = this.getValue('EO', 'absolute', 'Fz', 'Beta');\n    const czTheta = this.getValue('EO', 'absolute', 'Cz', 'Theta');\n    const czBeta = this.getValue('EO', 'absolute', 'Cz', 'Beta');\n\n    if (!fzTheta || !fzBeta || !czTheta || !czBeta) return { value: null, score: 0 };\n\n    const fzRatio = fzTheta / fzBeta;\n    const czRatio = czTheta / czBeta;\n    const avgRatio = (fzRatio + czRatio) / 2;\n\n    return {\n      value: avgRatio,\n      score: this.scoreMetric(avgRatio, 1.5, 'less'),\n      description: `Theta:Beta Ratio = ${avgRatio.toFixed(2)} (< 1.5 is normal)`,\n      details: { fzRatio: fzRatio.toFixed(2), czRatio: czRatio.toFixed(2) }\n    };\n  }\n\n  /**\n   * Alpha Peak - Used in multiple parameters\n   * Eyes Closed, Special (highest frequency at Pz or below)\n   * > 9 Hz is normal\n   */\n  calculateAlphaPeak() {\n    // Assuming alphaPeak is provided in the data\n    const alphaPeak = this.data.EC?.special?.alphaPeak || this.data.EC?.special?.O1 || 10.0;\n\n    return {\n      value: alphaPeak,\n      score: this.scoreMetric(alphaPeak, 9, 'more'),\n      description: `Alpha Peak = ${alphaPeak.toFixed(1)} Hz (> 9 is normal)`\n    };\n  }\n\n  /**\n   * Alpha:Theta Balance - Used in multiple parameters\n   * Eyes Closed, Absolute Power, Fz, Cz, Pz\n   * Order Pz > Cz > Fz is normal (1 point), otherwise 0\n   */\n  calculateAlphaThetaBalance() {\n    const fzAlpha = this.getValue('EC', 'absolute', 'Fz', 'Alpha');\n    const fzTheta = this.getValue('EC', 'absolute', 'Fz', 'Theta');\n    const czAlpha = this.getValue('EC', 'absolute', 'Cz', 'Alpha');\n    const czTheta = this.getValue('EC', 'absolute', 'Cz', 'Theta');\n    const pzAlpha = this.getValue('EC', 'absolute', 'Pz', 'Alpha');\n    const pzTheta = this.getValue('EC', 'absolute', 'Pz', 'Theta');\n\n    if (!fzAlpha || !fzTheta || !czAlpha || !czTheta || !pzAlpha || !pzTheta) {\n      return { value: null, score: 0 };\n    }\n\n    const fzRatio = fzAlpha / fzTheta;\n    const czRatio = czAlpha / czTheta;\n    const pzRatio = pzAlpha / pzTheta;\n\n    const isNormalOrder = pzRatio > czRatio && czRatio > fzRatio;\n\n    return {\n      value: { fz: fzRatio.toFixed(2), cz: czRatio.toFixed(2), pz: pzRatio.toFixed(2) },\n      score: isNormalOrder ? 1 : 0,\n      description: `Alpha:Theta Order = ${isNormalOrder ? 'Pz > Cz > Fz (Normal)' : 'Abnormal order'}`,\n      details: { fzRatio, czRatio, pzRatio, order: isNormalOrder }\n    };\n  }\n\n  /**\n   * Arousal Score (HiBeta:Beta Ratio) - Used in multiple parameters\n   * Eyes Open, Absolute Power, Fz & Cz average\n   * < 1 is normal\n   */\n  calculateArousalScore() {\n    const fzBeta = this.getValue('EO', 'absolute', 'Fz', 'Beta');\n    const fzHiBeta = this.getValue('EO', 'absolute', 'Fz', 'HiBeta');\n    const czBeta = this.getValue('EO', 'absolute', 'Cz', 'Beta');\n    const czHiBeta = this.getValue('EO', 'absolute', 'Cz', 'HiBeta');\n\n    if (!fzBeta || !fzHiBeta || !czBeta || !czHiBeta) return { value: null, score: 0 };\n\n    const fzRatio = fzHiBeta / fzBeta;\n    const czRatio = czHiBeta / czBeta;\n    const avgRatio = (fzRatio + czRatio) / 2;\n\n    return {\n      value: avgRatio,\n      score: this.scoreMetric(avgRatio, 1, 'less'),\n      description: `Arousal Score = ${avgRatio.toFixed(2)} (< 1 is normal)`,\n      details: { fzRatio: fzRatio.toFixed(2), czRatio: czRatio.toFixed(2) }\n    };\n  }\n\n  /**\n   * Relaxation Score - Used in multiple parameters\n   * Eyes Closed, Absolute Power, Pz, Alpha/Beta\n   * > 10 is healthy\n   */\n  calculateRelaxationScore() {\n    const pzAlpha = this.getValue('EC', 'absolute', 'Pz', 'Alpha');\n    const pzBeta = this.getValue('EC', 'absolute', 'Pz', 'Beta');\n\n    if (!pzAlpha || !pzBeta) return { value: null, score: 0 };\n\n    const ratio = pzAlpha / pzBeta;\n\n    return {\n      value: ratio,\n      score: this.scoreMetric(ratio, 10, 'more'),\n      description: `Relaxation Score = ${ratio.toFixed(2)} (> 10 is healthy)`\n    };\n  }\n\n  /**\n   * Regeneration (Alpha Modulation) - Used in multiple parameters\n   * EO & EC, Relative Power, Pz, (EC-EO)/EC * 100\n   * > 30% is healthy\n   */\n  calculateRegeneration() {\n    const ecAlpha = this.getValue('EC', 'relative', 'Pz', 'Alpha');\n    const eoAlpha = this.getValue('EO', 'relative', 'Pz', 'Alpha');\n\n    if (!ecAlpha || !eoAlpha) return { value: null, score: 0 };\n\n    const modulation = ((ecAlpha - eoAlpha) / ecAlpha) * 100;\n\n    return {\n      value: modulation,\n      score: this.scoreMetric(modulation, 30, 'more'),\n      description: `Alpha Modulation = ${modulation.toFixed(1)}% (> 30% is healthy)`\n    };\n  }\n\n  /**\n   * Focus Theta (Relative Power) - Used in Focus & Attention\n   * Eyes Open, Relative Power, Fz & Cz average\n   * < 20% is normal\n   */\n  calculateFocusTheta() {\n    const fzTheta = this.getValue('EO', 'relative', 'Fz', 'Theta');\n    const czTheta = this.getValue('EO', 'relative', 'Cz', 'Theta');\n\n    if (!fzTheta || !czTheta) return { value: null, score: 0 };\n\n    const avgTheta = (fzTheta + czTheta) / 2;\n\n    return {\n      value: avgTheta,\n      score: this.scoreMetric(avgTheta, 20, 'less'),\n      description: `Focus Theta = ${avgTheta.toFixed(1)}% (< 20% is normal)`\n    };\n  }\n\n  /**\n   * Excessive Delta - Used in Burnout & Fatigue\n   * Eyes Open, Relative Power, avg of Fz, C3, Cz, C4, P3, Pz, P4\n   * < 70% is normal\n   */\n  calculateExcessiveDelta() {\n    const channels = ['Fz', 'C3', 'Cz', 'C4', 'P3', 'Pz', 'P4'];\n    let sum = 0;\n    let count = 0;\n\n    for (const channel of channels) {\n      const delta = this.getValue('EO', 'relative', channel, 'Delta');\n      if (delta !== null) {\n        sum += delta;\n        count++;\n      }\n    }\n\n    if (count === 0) return { value: null, score: 0 };\n\n    const avgDelta = sum / count;\n\n    return {\n      value: avgDelta,\n      score: this.scoreMetric(avgDelta, 70, 'less'),\n      description: `Excessive Delta = ${avgDelta.toFixed(1)}% (< 70% is normal)`\n    };\n  }\n\n  /**\n   * Alpha Asymmetry (Frontal) - Used in Emotional Regulation\n   * Eyes Closed, Absolute Power, F3 & F4\n   * F4/F3 < 1 is normal\n   */\n  calculateAlphaAsymmetry() {\n    const f3Alpha = this.getValue('EC', 'absolute', 'F3', 'Alpha');\n    const f4Alpha = this.getValue('EC', 'absolute', 'F4', 'Alpha');\n\n    if (!f3Alpha || !f4Alpha) return { value: null, score: 0 };\n\n    const ratio = f4Alpha / f3Alpha;\n\n    return {\n      value: ratio,\n      score: this.scoreMetric(ratio, 1, 'less'),\n      description: `Alpha Asymmetry = ${ratio.toFixed(2)} (< 1 is normal)`\n    };\n  }\n\n  // ==================== 7 PARAMETER CALCULATIONS ====================\n\n  /**\n   * 1. Cognition\n   * - Focus Score (Theta:Beta Ratio)\n   * - Alpha Peak\n   * - Alpha:Theta Balance\n   */\n  calculateCognition() {\n    const metric1 = this.calculateFocusScore();\n    const metric2 = this.calculateAlphaPeak();\n    const metric3 = this.calculateAlphaThetaBalance();\n\n    const totalScore = metric1.score + metric2.score + metric3.score;\n\n    return {\n      name: 'Cognition',\n      score: totalScore,\n      maxScore: 3,\n      classification: this.classifyScore(totalScore),\n      metrics: [\n        { name: 'Focus Score (Theta:Beta)', ...metric1 },\n        { name: 'Alpha Peak', ...metric2 },\n        { name: 'Alpha:Theta Balance', ...metric3 }\n      ]\n    };\n  }\n\n  /**\n   * 2. Stress (Note: 0/3 is healthy, 3/3 is high stress)\n   * - Arousal Score\n   * - Relaxation Score\n   * - Regeneration\n   */\n  calculateStress() {\n    const metric1 = this.calculateArousalScore();\n    const metric2 = this.calculateRelaxationScore();\n    const metric3 = this.calculateRegeneration();\n\n    const totalScore = metric1.score + metric2.score + metric3.score;\n\n    return {\n      name: 'Stress',\n      score: totalScore,\n      maxScore: 3,\n      classification: this.classifyScore(totalScore),\n      metrics: [\n        { name: 'Arousal Score', ...metric1 },\n        { name: 'Relaxation Score', ...metric2 },\n        { name: 'Regeneration (Alpha Modulation)', ...metric3 }\n      ]\n    };\n  }\n\n  /**\n   * 3. Focus & Attention\n   * - Focus Theta\n   * - Alpha:Theta Balance\n   * - Focus Score (Theta:Beta)\n   */\n  calculateFocusAttention() {\n    const metric1 = this.calculateFocusTheta();\n    const metric2 = this.calculateAlphaThetaBalance();\n    const metric3 = this.calculateFocusScore();\n\n    const totalScore = metric1.score + metric2.score + metric3.score;\n\n    return {\n      name: 'Focus & Attention',\n      score: totalScore,\n      maxScore: 3,\n      classification: this.classifyScore(totalScore),\n      metrics: [\n        { name: 'Focus Theta', ...metric1 },\n        { name: 'Alpha:Theta Balance', ...metric2 },\n        { name: 'Focus Score (Theta:Beta)', ...metric3 }\n      ]\n    };\n  }\n\n  /**\n   * 4. Burnout & Fatigue (Note: 0/3 is healthy)\n   * - Arousal Score\n   * - Relaxation Score\n   * - Excessive Delta\n   */\n  calculateBurnoutFatigue() {\n    const metric1 = this.calculateArousalScore();\n    const metric2 = this.calculateRelaxationScore();\n    const metric3 = this.calculateExcessiveDelta();\n\n    const totalScore = metric1.score + metric2.score + metric3.score;\n\n    return {\n      name: 'Burnout & Fatigue',\n      score: totalScore,\n      maxScore: 3,\n      classification: this.classifyScore(totalScore),\n      metrics: [\n        { name: 'Arousal Score', ...metric1 },\n        { name: 'Relaxation Score', ...metric2 },\n        { name: 'Excessive Delta', ...metric3 }\n      ]\n    };\n  }\n\n  /**\n   * 5. Emotional Regulation\n   * - Alpha Asymmetry\n   * - Arousal Score\n   * - Regeneration\n   */\n  calculateEmotionalRegulation() {\n    const metric1 = this.calculateAlphaAsymmetry();\n    const metric2 = this.calculateArousalScore();\n    const metric3 = this.calculateRegeneration();\n\n    const totalScore = metric1.score + metric2.score + metric3.score;\n\n    return {\n      name: 'Emotional Regulation',\n      score: totalScore,\n      maxScore: 3,\n      classification: this.classifyScore(totalScore),\n      metrics: [\n        { name: 'Alpha Asymmetry (Frontal)', ...metric1 },\n        { name: 'Arousal Score', ...metric2 },\n        { name: 'Regeneration (Alpha Modulation)', ...metric3 }\n      ]\n    };\n  }\n\n  /**\n   * 6. Learning\n   * - Alpha Peak\n   * - Focus Score (Theta:Beta)\n   * - Arousal Score\n   */\n  calculateLearning() {\n    const metric1 = this.calculateAlphaPeak();\n    const metric2 = this.calculateFocusScore();\n    const metric3 = this.calculateArousalScore();\n\n    const totalScore = metric1.score + metric2.score + metric3.score;\n\n    return {\n      name: 'Learning',\n      score: totalScore,\n      maxScore: 3,\n      classification: this.classifyScore(totalScore),\n      metrics: [\n        { name: 'Alpha Peak', ...metric1 },\n        { name: 'Focus Score (Theta:Beta)', ...metric2 },\n        { name: 'Arousal Score', ...metric3 }\n      ]\n    };\n  }\n\n  /**\n   * 7. Creativity\n   * - Relaxation Score\n   * - Focus Score (Theta:Beta)\n   * - Alpha Peak\n   */\n  calculateCreativity() {\n    const metric1 = this.calculateRelaxationScore();\n    const metric2 = this.calculateFocusScore();\n    const metric3 = this.calculateAlphaPeak();\n\n    const totalScore = metric1.score + metric2.score + metric3.score;\n\n    return {\n      name: 'Creativity',\n      score: totalScore,\n      maxScore: 3,\n      classification: this.classifyScore(totalScore),\n      metrics: [\n        { name: 'Relaxation Score', ...metric1 },\n        { name: 'Focus Score (Theta:Beta)', ...metric2 },\n        { name: 'Alpha Peak', ...metric3 }\n      ]\n    };\n  }\n}\n\nmodule.exports = AlgorithmCalculator;\n","numLines":474,"startLine":1,"totalLines":474}}}
{"parentUuid":"50c2c37e-0f17-470d-8419-0aa80743d148","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WuXt1FWpQfJn7jqmguxapo","type":"tool_result","content":"     1‚Üíconst express = require('express');\n     2‚Üíconst multer = require('multer');\n     3‚Üíconst path = require('path');\n     4‚Üíconst fs = require('fs');\n     5‚Üíconst QEEGParser = require('../services/qeegParser');\n     6‚Üíconst AlgorithmCalculator = require('../services/algorithmCalculator');\n     7‚Üí// OLD generators (keeping for fallback)\n     8‚Üíconst PDFReportGenerator = require('../services/pdfGenerator');\n     9‚Üíconst TemplateBasedPDFGenerator = require('../services/pdfGeneratorTemplate');\n    10‚Üíconst templateManager = require('../services/pdf/templateManager');\n    11‚Üíconst AIPdfGenerator = require('../services/aiPdfGenerator');\n    12‚Üíconst SupabaseStorage = require('../services/supabaseStorage');\n    13‚Üí\n    14‚Üí// NEW: Gemini AI Service for report generation\n    15‚Üílet GeminiService = null;\n    16‚Üítry {\n    17‚Üí  GeminiService = require('../services/geminiService');\n    18‚Üí  console.log('‚úÖ Gemini AI Service loaded successfully');\n    19‚Üí} catch (error) {\n    20‚Üí  console.error('‚ùå CRITICAL: Gemini AI Service failed to load!');\n    21‚Üí  console.error('   Error:', error.message);\n    22‚Üí  console.error('   Stack:', error.stack);\n    23‚Üí}\n    24‚Üí\n    25‚Üí// NEW: Gemini PDF Generator - Uses Gemini AI for content generation\n    26‚Üílet GeminiPdfGenerator = null;\n    27‚Üítry {\n    28‚Üí  GeminiPdfGenerator = require('../services/geminiPdfGenerator');\n    29‚Üí  console.log('‚úÖ Gemini PDF Generator loaded successfully');\n    30‚Üí  console.log('   Generator available:', !!GeminiPdfGenerator);\n    31‚Üí} catch (error) {\n    32‚Üí  console.error('‚ùå CRITICAL: Gemini PDF Generator failed to load!');\n    33‚Üí  console.error('   Error:', error.message);\n    34‚Üí  console.error('   Stack:', error.stack);\n    35‚Üí}\n    36‚Üí\n    37‚Üí// OLD: Enhanced AI PDF Generator with OpenAI (keeping as fallback)\n    38‚Üílet EnhancedAIPdfGenerator = null;\n    39‚Üítry {\n    40‚Üí  EnhancedAIPdfGenerator = require('../services/aiPdfGeneratorEnhanced');\n    41‚Üí  console.log('‚úÖ Enhanced AI PDF Generator loaded successfully');\n    42‚Üí} catch (error) {\n    43‚Üí  console.warn('‚ö†Ô∏è  Enhanced AI PDF Generator failed to load:', error.message);\n    44‚Üí  console.warn('   Will use fallback PDF generator');\n    45‚Üí}\n    46‚Üí\n    47‚Üíconst router = express.Router();\n    48‚Üí\n    49‚Üí// Configure multer for file uploads\n    50‚Üíconst storage = multer.diskStorage({\n    51‚Üí  destination: function (req, file, cb) {\n    52‚Üí    const uploadDir = path.join(__dirname, '../uploads');\n    53‚Üí    // Ensure upload directory exists\n    54‚Üí    if (!fs.existsSync(uploadDir)) {\n    55‚Üí      fs.mkdirSync(uploadDir, { recursive: true });\n    56‚Üí    }\n    57‚Üí    cb(null, uploadDir);\n    58‚Üí  },\n    59‚Üí  filename: function (req, file, cb) {\n    60‚Üí    const uniqueSuffix = Date.now() + '-' + Math.round(Math.random() * 1E9);\n    61‚Üí    cb(null, file.fieldname + '-' + uniqueSuffix + path.extname(file.originalname));\n    62‚Üí  }\n    63‚Üí});\n    64‚Üí\n    65‚Üíconst upload = multer({\n    66‚Üí  storage: storage,\n    67‚Üí  limits: {\n    68‚Üí    fileSize: 10 * 1024 * 1024 // 10MB limit\n    69‚Üí  },\n    70‚Üí  fileFilter: function (req, file, cb) {\n    71‚Üí    const allowedExtensions = ['.pdf', '.csv', '.xlsx', '.xls'];\n    72‚Üí    const ext = path.extname(file.originalname).toLowerCase();\n    73‚Üí    if (allowedExtensions.includes(ext)) {\n    74‚Üí      cb(null, true);\n    75‚Üí    } else {\n    76‚Üí      cb(new Error(`Only ${allowedExtensions.join(', ')} files are allowed`));\n    77‚Üí    }\n    78‚Üí  }\n    79‚Üí});\n    80‚Üí\n    81‚Üí/**\n    82‚Üí * POST /api/qeeg/process\n    83‚Üí * Process QEEG files and calculate 7 brain health parameters\n    84‚Üí */\n    85‚Üírouter.post('/process', upload.fields([\n    86‚Üí  { name: 'eyesOpen', maxCount: 1 },\n    87‚Üí  { name: 'eyesClosed', maxCount: 1 }\n    88‚Üí]), async (req, res) => {\n    89‚Üí  let eyesOpenFile = null;\n    90‚Üí  let eyesClosedFile = null;\n    91‚Üí\n    92‚Üí  try {\n    93‚Üí    console.log('\\nüî¨ === QEEG Processing Started ===\\n');\n    94‚Üí\n    95‚Üí    // Get uploaded files\n    96‚Üí    const files = req.files;\n    97‚Üí    if (!files || !files.eyesOpen || !files.eyesClosed) {\n    98‚Üí      return res.status(400).json({\n    99‚Üí        error: true,\n   100‚Üí        message: 'Both Eyes Open and Eyes Closed files are required'\n   101‚Üí      });\n   102‚Üí    }\n   103‚Üí\n   104‚Üí    eyesOpenFile = files.eyesOpen[0];\n   105‚Üí    eyesClosedFile = files.eyesClosed[0];\n   106‚Üí\n   107‚Üí    console.log('üìÅ Files received:');\n   108‚Üí    console.log('  - Eyes Open:', eyesOpenFile.originalname, `(${(eyesOpenFile.size / 1024).toFixed(2)} KB)`);\n   109‚Üí    console.log('  - Eyes Closed:', eyesClosedFile.originalname, `(${(eyesClosedFile.size / 1024).toFixed(2)} KB)`);\n   110‚Üí\n   111‚Üí    // Get patient info from request body\n   112‚Üí    const {\n   113‚Üí      patientId,\n   114‚Üí      patientName,\n   115‚Üí      clinicName,\n   116‚Üí      dateOfBirth,\n   117‚Üí      age,\n   118‚Üí      gender,\n   119‚Üí      handedness\n   120‚Üí    } = req.body;\n   121‚Üí\n   122‚Üí    console.log('\\nüë§ Patient Information:');\n   123‚Üí    console.log('  - Patient ID:', patientId);\n   124‚Üí    console.log('  - Patient Name:', patientName);\n   125‚Üí    console.log('  - Clinic:', clinicName);\n   126‚Üí    console.log('  - Date of Birth:', dateOfBirth);\n   127‚Üí    console.log('  - Age:', age);\n   128‚Üí    console.log('  - Gender:', gender);\n   129‚Üí    console.log('  - Handedness:', handedness);\n   130‚Üí\n   131‚Üí    // Validate OpenAI API configuration before processing (OPTIONAL - don't fail if missing)\n   132‚Üí    console.log('\\nüîê Checking OpenAI API configuration...');\n   133‚Üí    try {\n   134‚Üí      await QEEGParser.testAPIConnection();\n   135‚Üí      console.log('‚úÖ OpenAI API configured properly');\n   136‚Üí    } catch (apiError) {\n   137‚Üí      console.warn('‚ö†Ô∏è  OpenAI API not configured or failed test:', apiError.message);\n   138‚Üí      console.warn('   Continuing with processing anyway...');\n   139‚Üí      // Don't throw error - allow processing to continue without OpenAI\n   140‚Üí    }\n   141‚Üí\n   142‚Üí    // Step 1: Parse QEEG files\n   143‚Üí    console.log('\\nüìä Step 1: Parsing QEEG files...');\n   144‚Üí    const qeegData = await QEEGParser.parse(eyesOpenFile, eyesClosedFile);\n   145‚Üí\n   146‚Üí    // Validate that we got real patient data\n   147‚Üí    console.log('\\nüìä QEEG Data Validation:');\n   148‚Üí    console.log('  - Eyes Open (EO) channels:', Object.keys(qeegData.EO?.absolute || {}).length);\n   149‚Üí    console.log('  - Eyes Closed (EC) channels:', Object.keys(qeegData.EC?.absolute || {}).length);\n   150‚Üí    console.log('  - Using REAL PATIENT DATA (not sample data)');\n   151‚Üí    console.log('  - Patient:', patientName, `(ID: ${patientId})`);\n   152‚Üí\n   153‚Üí    // Step 2: Calculate parameters\n   154‚Üí    console.log('\\nüßÆ Step 2: Calculating 7 brain health parameters...');\n   155‚Üí    const calculator = new AlgorithmCalculator(qeegData);\n   156‚Üí    const results = calculator.calculate();\n   157‚Üí\n   158‚Üí    console.log('\\n‚úÖ Calculation completed successfully!');\n   159‚Üí    console.log('üìà Results Summary:');\n   160‚Üí    results.parameters.forEach(param => {\n   161‚Üí      console.log(`  - ${param.name}: ${param.score}/${param.maxScore} (${param.classification})`);\n   162‚Üí    });\n   163‚Üí    console.log(`  - Overall Score: ${results.overallScore}/21`);\n   164‚Üí\n   165‚Üí    // Step 3: Auto-generate PDF report\n   166‚Üí    console.log('\\nüìÑ Step 3: Auto-generating PDF report...');\n   167‚Üí    let pdfUrl = null;\n   168‚Üí    let pdfFilename = null;\n   169‚Üí\n   170‚Üí    try {\n   171‚Üí      // Prepare patient data for PDF\n   172‚Üí      const pdfPatientData = {\n   173‚Üí        name: patientName,\n   174‚Üí        dateOfBirth: dateOfBirth || 'N/A',\n   175‚Üí        age: age || 'N/A',\n   176‚Üí        gender: gender || 'Not specified',\n   177‚Üí        handedness: handedness || 'Not specified',\n   178‚Üí        patientId: patientId,\n   179‚Üí        clinicName: clinicName\n   180‚Üí      };\n   181‚Üí\n   182‚Üí      // Prepare algorithm results for PDF\n   183‚Üí      const pdfAlgorithmResults = {\n   184‚Üí        parameters: results.parameters,\n   185‚Üí        overallScore: results.overallScore\n   186‚Üí      };\n   187‚Üí\n   188‚Üí      // Debug: Log parameters being sent to PDF\n   189‚Üí      console.log('\\nüìä Parameters for PDF:');\n   190‚Üí      console.log('  - Total Parameters:', pdfAlgorithmResults.parameters.length);\n   191‚Üí      console.log('  - Overall Score:', pdfAlgorithmResults.overallScore);\n   192‚Üí      pdfAlgorithmResults.parameters.forEach((param, i) => {\n   193‚Üí        console.log(`  ${i + 1}. ${param.name}: ${param.score}/${param.maxScore} (${param.classification})`);\n   194‚Üí      });\n   195‚Üí\n   196‚Üí      // Create output filename\n   197‚Üí      const timestamp = Date.now();\n   198‚Üí      const sanitizedName = (patientName || 'patient').replace(/[^a-z0-9]/gi, '_').toLowerCase();\n   199‚Üí      pdfFilename = `neurosense-report-${sanitizedName}-${timestamp}.pdf`;\n   200‚Üí      const uploadsDir = path.join(__dirname, '../uploads');\n   201‚Üí      const pdfOutputPath = path.join(uploadsDir, pdfFilename);\n   202‚Üí\n   203‚Üí      // Ensure uploads directory exists\n   204‚Üí      if (!fs.existsSync(uploadsDir)) {\n   205‚Üí        console.log('üìÅ Creating uploads directory...');\n   206‚Üí        fs.mkdirSync(uploadsDir, { recursive: true });\n   207‚Üí      }\n   208‚Üí\n   209‚Üí      console.log('üìù Generating PDF to:', pdfFilename);\n   210‚Üí      console.log('   Full path:', pdfOutputPath);\n   211‚Üí\n   212‚Üí      // === USE GEMINI PDF GENERATOR (with fallback) ===\n   213‚Üí      console.log('\\nüîç Checking available PDF generators...');\n   214‚Üí      console.log('   GeminiPdfGenerator available:', !!GeminiPdfGenerator);\n   215‚Üí      console.log('   EnhancedAIPdfGenerator available:', !!EnhancedAIPdfGenerator);\n   216‚Üí      console.log('   PDFReportGenerator available:', !!PDFReportGenerator);\n   217‚Üí\n   218‚Üí      let pdfGenerator;\n   219‚Üí      if (GeminiPdfGenerator) {\n   220‚Üí        console.log('\\nü§ñ === USING GEMINI AI PDF GENERATOR ===');\n   221‚Üí        console.log('   Engine: Google Gemini + PDFKit');\n   222‚Üí        console.log('   Patient:', pdfPatientData.name);\n   223‚Üí        console.log('   Parameters:', pdfAlgorithmResults.parameters.length);\n   224‚Üí        try {\n   225‚Üí          pdfGenerator = new GeminiPdfGenerator(pdfPatientData, pdfAlgorithmResults, qeegData);\n   226‚Üí          console.log('‚úÖ Gemini PDF Generator instantiated successfully');\n   227‚Üí        } catch (instantiateError) {\n   228‚Üí          console.error('‚ùå Failed to instantiate Gemini PDF Generator:', instantiateError.message);\n   229‚Üí          throw instantiateError;\n   230‚Üí        }\n   231‚Üí      } else if (EnhancedAIPdfGenerator) {\n   232‚Üí        console.log('ü§ñ Using Enhanced AI PDF Generator (OpenAI + PDFKit - Fallback)');\n   233‚Üí        pdfGenerator = new EnhancedAIPdfGenerator(pdfPatientData, pdfAlgorithmResults, qeegData);\n   234‚Üí      } else {\n   235‚Üí        console.log('üìÑ Using Standard PDF Generator (Basic fallback)');\n   236‚Üí        pdfGenerator = new PDFReportGenerator(pdfPatientData, pdfAlgorithmResults, qeegData);\n   237‚Üí      }\n   238‚Üí\n   239‚Üí      // Generate the PDF\n   240‚Üí      console.log('\\nüìù Calling pdfGenerator.generateReport()...');\n   241‚Üí      console.log('   Output path:', pdfOutputPath);\n   242‚Üí\n   243‚Üí      try {\n   244‚Üí        await pdfGenerator.generateReport(pdfOutputPath);\n   245‚Üí        console.log('‚úÖ PDF generation completed!');\n   246‚Üí      } catch (genError) {\n   247‚Üí        console.error('‚ùå PDF generation threw error:', genError.message);\n   248‚Üí        console.error('   Stack:', genError.stack);\n   249‚Üí        throw genError;\n   250‚Üí      }\n   251‚Üí\n   252‚Üí      // Verify file was created\n   253‚Üí      if (!fs.existsSync(pdfOutputPath)) {\n   254‚Üí        throw new Error('PDF file was not created at expected path: ' + pdfOutputPath);\n   255‚Üí      }\n   256‚Üí\n   257‚Üí      console.log('‚úÖ PDF file verified at:', pdfOutputPath);\n   258‚Üí      console.log('üìÑ File:', pdfFilename);\n   259‚Üí      console.log('üìä Size:', (fs.statSync(pdfOutputPath).size / 1024).toFixed(2), 'KB');\n   260‚Üí\n   261‚Üí      // Upload to Supabase Storage\n   262‚Üí      try {\n   263‚Üí        console.log('\\n‚òÅÔ∏è  Uploading PDF to Supabase storage...');\n   264‚Üí        const uploadResult = await SupabaseStorage.uploadFile(\n   265‚Üí          pdfOutputPath,\n   266‚Üí          'neurosense_bucketreports', // bucket name\n   267‚Üí          `reports/${pdfFilename}` // path in bucket\n   268‚Üí        );\n   269‚Üí\n   270‚Üí        // Verify upload was successful and URL is valid\n   271‚Üí        if (uploadResult && uploadResult.url) {\n   272‚Üí          pdfUrl = uploadResult.url;\n   273‚Üí          console.log('‚úÖ PDF uploaded to Supabase successfully');\n   274‚Üí          console.log('üîó Supabase URL:', pdfUrl);\n   275‚Üí\n   276‚Üí          // Delete local file after successful Supabase upload\n   277‚Üí          try {\n   278‚Üí            fs.unlinkSync(pdfOutputPath);\n   279‚Üí            console.log('üóëÔ∏è  Local PDF file deleted after successful upload');\n   280‚Üí          } catch (deleteError) {\n   281‚Üí            console.warn('‚ö†Ô∏è  Could not delete local PDF file:', deleteError.message);\n   282‚Üí          }\n   283‚Üí        } else {\n   284‚Üí          throw new Error('Supabase upload returned invalid result');\n   285‚Üí        }\n   286‚Üí      } catch (supabaseError) {\n   287‚Üí        console.error('‚ö†Ô∏è  Supabase upload failed, using local storage');\n   288‚Üí        console.error('   Error message:', supabaseError.message);\n   289‚Üí        console.error('   Error stack:', supabaseError.stack);\n   290‚Üí        console.error('   Full error:', JSON.stringify(supabaseError, null, 2));\n   291‚Üí        // Fallback to local storage\n   292‚Üí        pdfUrl = `/uploads/${pdfFilename}`;\n   293‚Üí        console.log('üìÅ Using local file as fallback:', pdfUrl);\n   294‚Üí      }\n   295‚Üí\n   296‚Üí    } catch (pdfError) {\n   297‚Üí      console.error('\\n‚ùå === PDF GENERATION FAILED ===');\n   298‚Üí      console.error('Error message:', pdfError.message);\n   299‚Üí      console.error('Error stack:', pdfError.stack);\n   300‚Üí      console.error('Full error:', pdfError);\n   301‚Üí      console.error('=================================\\n');\n   302‚Üí\n   303‚Üí      // Set pdfUrl to null so frontend knows PDF failed\n   304‚Üí      pdfUrl = null;\n   305‚Üí\n   306‚Üí      // Don't fail the whole request if PDF fails - processing still succeeded\n   307‚Üí      console.log('‚ö†Ô∏è Continuing without PDF - processing succeeded');\n   308‚Üí    }\n   309‚Üí\n   310‚Üí    // Clean up uploaded files\n   311‚Üí    try {\n   312‚Üí      fs.unlinkSync(eyesOpenFile.path);\n   313‚Üí      fs.unlinkSync(eyesClosedFile.path);\n   314‚Üí      console.log('\\nüóëÔ∏è  Temporary files cleaned up');\n   315‚Üí    } catch (cleanupError) {\n   316‚Üí      console.error('‚ö†Ô∏è  Error cleaning up files:', cleanupError.message);\n   317‚Üí    }\n   318‚Üí\n   319‚Üí    console.log('\\nüèÅ === QEEG Processing Completed ===\\n');\n   320‚Üí\n   321‚Üí    // Final check for PDF URL\n   322‚Üí    if (!pdfUrl) {\n   323‚Üí      console.warn('‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è WARNING: No PDF URL available in response!');\n   324‚Üí      console.warn('   pdfFilename was:', pdfFilename || 'NOT SET');\n   325‚Üí      console.warn('   This means PDF generation completely failed');\n   326‚Üí    } else {\n   327‚Üí      console.log('‚úÖ PDF URL ready:', pdfUrl);\n   328‚Üí      console.log('   Type:', pdfUrl.startsWith('http') ? 'Supabase' : 'Local');\n   329‚Üí    }\n   330‚Üí\n   331‚Üí    // Send response\n   332‚Üí    res.json({\n   333‚Üí      success: true,\n   334‚Üí      data: {\n   335‚Üí        patientId,\n   336‚Üí        patientName,\n   337‚Üí        clinicName,\n   338‚Üí        processedAt: new Date().toISOString(),\n   339‚Üí        results: results.parameters,\n   340‚Üí        overallScore: results.overallScore,\n   341‚Üí        maxScore: 21,\n   342‚Üí        pdfUrl: pdfUrl,\n   343‚Üí        pdfFilename: pdfFilename\n   344‚Üí      }\n   345‚Üí    });\n   346‚Üí\n   347‚Üí  } catch (error) {\n   348‚Üí    console.error('\\n‚ùå === QEEG Processing Failed ===');\n   349‚Üí    console.error('Error:', error.message);\n   350‚Üí    console.error('Error Code:', error.code || 'UNKNOWN');\n   351‚Üí    console.error('Stack:', error.stack);\n   352‚Üí\n   353‚Üí    // Clean up files on error\n   354‚Üí    if (eyesOpenFile && fs.existsSync(eyesOpenFile.path)) {\n   355‚Üí      try {\n   356‚Üí        fs.unlinkSync(eyesOpenFile.path);\n   357‚Üí      } catch (e) {\n   358‚Üí        console.error('Error deleting Eyes Open file:', e.message);\n   359‚Üí      }\n   360‚Üí    }\n   361‚Üí    if (eyesClosedFile && fs.existsSync(eyesClosedFile.path)) {\n   362‚Üí      try {\n   363‚Üí        fs.unlinkSync(eyesClosedFile.path);\n   364‚Üí      } catch (e) {\n   365‚Üí        console.error('Error deleting Eyes Closed file:', e.message);\n   366‚Üí      }\n   367‚Üí    }\n   368‚Üí\n   369‚Üí    // Categorize errors for better user feedback\n   370‚Üí    let statusCode = 500;\n   371‚Üí    let userMessage = error.message;\n   372‚Üí\n   373‚Üí    switch (error.code) {\n   374‚Üí      case 'MISSING_API_KEY':\n   375‚Üí      case 'INVALID_API_KEY':\n   376‚Üí      case 'INVALID_API_KEY_FORMAT':\n   377‚Üí      case 'API_CONNECTION_FAILED':\n   378‚Üí        statusCode = 503; // Service Unavailable\n   379‚Üí        userMessage = 'System configuration error: OpenAI API key not properly configured. Please contact support.';\n   380‚Üí        break;\n   381‚Üí\n   382‚Üí      case 'PDF_EXTRACTION_FAILED':\n   383‚Üí        statusCode = 422; // Unprocessable Entity\n   384‚Üí        userMessage = 'Failed to extract QEEG data from PDF. Please ensure the PDF contains valid QEEG tables with absolute and relative power values.';\n   385‚Üí        break;\n   386‚Üí\n   387‚Üí      default:\n   388‚Üí        userMessage = error.message || 'Failed to process QEEG files';\n   389‚Üí    }\n   390‚Üí\n   391‚Üí    res.status(statusCode).json({\n   392‚Üí      error: true,\n   393‚Üí      message: userMessage,\n   394‚Üí      code: error.code || 'UNKNOWN_ERROR',\n   395‚Üí      technicalDetails: process.env.NODE_ENV === 'development' ? {\n   396‚Üí        originalMessage: error.message,\n   397‚Üí        stack: error.stack,\n   398‚Üí        condition: error.condition\n   399‚Üí      } : undefined\n   400‚Üí    });\n   401‚Üí  }\n   402‚Üí});\n   403‚Üí\n   404‚Üí/**\n   405‚Üí * POST /api/qeeg/generate-pdf\n   406‚Üí * Generate PDF report from algorithm results\n   407‚Üí */\n   408‚Üírouter.post('/generate-pdf', async (req, res) => {\n   409‚Üí  try {\n   410‚Üí    console.log('\\nüìÑ === PDF Report Generation Started ===\\n');\n   411‚Üí\n   412‚Üí    const { patientData, algorithmResults, qeegData } = req.body;\n   413‚Üí\n   414‚Üí    // Validate input\n   415‚Üí    if (!patientData || !algorithmResults || !qeegData) {\n   416‚Üí      return res.status(400).json({\n   417‚Üí        error: true,\n   418‚Üí        message: 'Missing required data: patientData, algorithmResults, and qeegData are required'\n   419‚Üí      });\n   420‚Üí    }\n   421‚Üí\n   422‚Üí    console.log('üë§ Patient:', patientData.name);\n   423‚Üí    console.log('üìä Parameters:', algorithmResults.parameters?.length);\n   424‚Üí\n   425‚Üí    // === USE GEMINI PDF GENERATOR (if available) ===\n   426‚Üí    let generator;\n   427‚Üí    if (GeminiPdfGenerator) {\n   428‚Üí      console.log('ü§ñ Using Gemini AI PDF Generator (Google Gemini + PDFKit)');\n   429‚Üí      generator = new GeminiPdfGenerator(patientData, algorithmResults, qeegData);\n   430‚Üí    } else if (EnhancedAIPdfGenerator) {\n   431‚Üí      console.log('ü§ñ Using Enhanced AI PDF Generator (OpenAI + PDFKit - Fallback)');\n   432‚Üí      generator = new EnhancedAIPdfGenerator(patientData, algorithmResults, qeegData);\n   433‚Üí    } else {\n   434‚Üí      console.log('üìÑ Using Standard PDF Generator (Basic fallback)');\n   435‚Üí      generator = new PDFReportGenerator(patientData, algorithmResults, qeegData);\n   436‚Üí    }\n   437‚Üí\n   438‚Üí    // Create output filename\n   439‚Üí    const timestamp = Date.now();\n   440‚Üí    const sanitizedName = (patientData.name || 'patient').replace(/[^a-z0-9]/gi, '_').toLowerCase();\n   441‚Üí    const filename = `neurosense-report-${sanitizedName}-${timestamp}.pdf`;\n   442‚Üí    const outputPath = path.join(__dirname, '../uploads', filename);\n   443‚Üí\n   444‚Üí    console.log('üìù Generating AI-powered PDF to:', filename);\n   445‚Üí\n   446‚Üí    // Generate the PDF with AI insights\n   447‚Üí    const pdfPath = await generator.generateReport(outputPath);\n   448‚Üí\n   449‚Üí    console.log('\\n‚úÖ PDF Report Generated Successfully!');\n   450‚Üí    console.log('üìÑ File:', filename);\n   451‚Üí    console.log('üìä Size:', (fs.statSync(pdfPath).size / 1024).toFixed(2), 'KB');\n   452‚Üí\n   453‚Üí    // Upload to Supabase Storage - TEMPORARILY DISABLED\n   454‚Üí    let supabaseUrl = null;\n   455‚Üí    let supabasePath = null;\n   456‚Üí    let uploadError = null;\n   457‚Üí\n   458‚Üí    // DISABLE SUPABASE UPLOAD FOR NOW - USE LOCAL STORAGE ONLY\n   459‚Üí    console.log('\\nüìÅ Using local storage (Supabase upload disabled)');\n   460‚Üí    uploadError = 'Supabase upload disabled - using local storage';\n   461‚Üí\n   462‚Üí    /* COMMENTED OUT - Enable when Supabase is configured properly\n   463‚Üí    try {\n   464‚Üí      console.log('\\n‚òÅÔ∏è  Uploading PDF to Supabase storage...');\n   465‚Üí      const uploadResult = await SupabaseStorage.uploadFile(\n   466‚Üí        pdfPath,\n   467‚Üí        'patient-reports', // bucket name\n   468‚Üí        `reports/${filename}` // path in bucket\n   469‚Üí      );\n   470‚Üí\n   471‚Üí      // Verify upload was successful and URL is valid\n   472‚Üí      if (uploadResult && uploadResult.url) {\n   473‚Üí        supabaseUrl = uploadResult.url;\n   474‚Üí        supabasePath = uploadResult.path;\n   475‚Üí\n   476‚Üí        console.log('‚úÖ PDF uploaded to Supabase successfully');\n   477‚Üí        console.log('üîó Supabase URL:', supabaseUrl);\n   478‚Üí\n   479‚Üí        // Only delete local file after SUCCESSFUL Supabase upload\n   480‚Üí        try {\n   481‚Üí          fs.unlinkSync(pdfPath);\n   482‚Üí          console.log('üóëÔ∏è  Local PDF file deleted after successful upload');\n   483‚Üí        } catch (deleteError) {\n   484‚Üí          console.warn('‚ö†Ô∏è  Could not delete local PDF file:', deleteError.message);\n   485‚Üí        }\n   486‚Üí      } else {\n   487‚Üí        throw new Error('Supabase upload returned invalid result');\n   488‚Üí      }\n   489‚Üí\n   490‚Üí    } catch (error) {\n   491‚Üí      console.error('‚ö†Ô∏è  Supabase upload failed, using local storage:', error.message);\n   492‚Üí      uploadError = error.message;\n   493‚Üí      // Keep local file as fallback - DO NOT DELETE\n   494‚Üí      console.log('üìÅ Using local file as fallback');\n   495‚Üí    }\n   496‚Üí    */\n   497‚Üí\n   498‚Üí    console.log('\\nüèÅ === PDF Generation Completed ===\\n');\n   499‚Üí\n   500‚Üí    // Return PDF info - prioritize Supabase URL\n   501‚Üí    res.json({\n   502‚Üí      success: true,\n   503‚Üí      data: {\n   504‚Üí        filename: filename,\n   505‚Üí        path: supabasePath || `/uploads/${filename}`,\n   506‚Üí        url: supabaseUrl || `${req.protocol}://${req.get('host')}/uploads/${filename}`,\n   507‚Üí        size: fs.existsSync(pdfPath) ? fs.statSync(pdfPath).size : 0,\n   508‚Üí        generatedAt: new Date().toISOString(),\n   509‚Üí        storage: supabaseUrl ? 'supabase' : 'local',\n   510‚Üí        uploadError: uploadError\n   511‚Üí      }\n   512‚Üí    });\n   513‚Üí\n   514‚Üí  } catch (error) {\n   515‚Üí    console.error('\\n‚ùå === PDF Generation Failed ===');\n   516‚Üí    console.error('Error:', error.message);\n   517‚Üí    console.error('Stack:', error.stack);\n   518‚Üí\n   519‚Üí    res.status(500).json({\n   520‚Üí      error: true,\n   521‚Üí      message: error.message || 'Failed to generate PDF report',\n   522‚Üí      details: process.env.NODE_ENV === 'development' ? error.stack : undefined\n   523‚Üí    });\n   524‚Üí  }\n   525‚Üí});\n   526‚Üí\n   527‚Üí/**\n   528‚Üí * POST /api/qeeg/generate-sample-pdf\n   529‚Üí * Generate a sample PDF report for testing\n   530‚Üí */\n   531‚Üírouter.post('/generate-sample-pdf', async (req, res) => {\n   532‚Üí  try {\n   533‚Üí    console.log('\\nüìÑ === Sample PDF Generation Started ===\\n');\n   534‚Üí\n   535‚Üí    const pdfPath = await PDFReportGenerator.generateSampleReport();\n   536‚Üí\n   537‚Üí    console.log('‚úÖ Sample PDF Generated!');\n   538‚Üí    console.log('üìÑ Path:', pdfPath);\n   539‚Üí\n   540‚Üí    const filename = path.basename(pdfPath);\n   541‚Üí\n   542‚Üí    res.json({\n   543‚Üí      success: true,\n   544‚Üí      data: {\n   545‚Üí        filename: filename,\n   546‚Üí        path: `/uploads/${filename}`,\n   547‚Üí        url: `${req.protocol}://${req.get('host')}/uploads/${filename}`,\n   548‚Üí        size: fs.statSync(pdfPath).size\n   549‚Üí      }\n   550‚Üí    });\n   551‚Üí\n   552‚Üí  } catch (error) {\n   553‚Üí    console.error('‚ùå Sample PDF generation failed:', error);\n   554‚Üí\n   555‚Üí    res.status(500).json({\n   556‚Üí      error: true,\n   557‚Üí      message: error.message\n   558‚Üí    });\n   559‚Üí  }\n   560‚Üí});\n   561‚Üí\n   562‚Üí/**\n   563‚Üí * POST /api/qeeg/generate-ai-pdf\n   564‚Üí * Generate AI-powered PDF report with enhanced design and content\n   565‚Üí */\n   566‚Üírouter.post('/generate-ai-pdf', async (req, res) => {\n   567‚Üí  try {\n   568‚Üí    console.log('\\nü§ñ === AI PDF Report Generation Started ===\\n');\n   569‚Üí\n   570‚Üí    const { patientData, algorithmResults, qeegData } = req.body;\n   571‚Üí\n   572‚Üí    // Validate input\n   573‚Üí    if (!patientData || !algorithmResults || !qeegData) {\n   574‚Üí      return res.status(400).json({\n   575‚Üí        error: true,\n   576‚Üí        message: 'Missing required data: patientData, algorithmResults, and qeegData are required'\n   577‚Üí      });\n   578‚Üí    }\n   579‚Üí\n   580‚Üí    console.log('üë§ Patient:', patientData.name);\n   581‚Üí    console.log('üìä Parameters:', algorithmResults.parameters?.length);\n   582‚Üí    console.log('üéØ Using AI-powered generation with enhanced prompt');\n   583‚Üí\n   584‚Üí    // Generate AI PDF\n   585‚Üí    const generator = new AIPdfGenerator(patientData, algorithmResults, qeegData);\n   586‚Üí\n   587‚Üí    // Create output filename\n   588‚Üí    const timestamp = Date.now();\n   589‚Üí    const sanitizedName = (patientData.name || 'patient').replace(/[^a-z0-9]/gi, '_').toLowerCase();\n   590‚Üí    const filename = `ai-neurosense-report-${sanitizedName}-${timestamp}.pdf`;\n   591‚Üí    const outputPath = path.join(__dirname, '../uploads', filename);\n   592‚Üí\n   593‚Üí    console.log('üìù Generating AI PDF to:', filename);\n   594‚Üí\n   595‚Üí    // Generate the PDF\n   596‚Üí    const result = await generator.generateReport(outputPath);\n   597‚Üí\n   598‚Üí    console.log('\\n‚úÖ AI NeuroSense Report Generated Successfully!');\n   599‚Üí    console.log('üìÑ Text File:', path.basename(result.textOutputPath));\n   600‚Üí    console.log('üìÑ JSON File:', path.basename(result.outputPath));\n   601‚Üí    console.log('üìä Tokens Used:', result.tokensUsed);\n   602‚Üí    console.log('üìè Content Length:', result.contentLength, 'characters');\n   603‚Üí    console.log('\\nüèÅ === AI PDF Generation Completed ===\\n');\n   604‚Üí\n   605‚Üí    // Return report info\n   606‚Üí    res.json({\n   607‚Üí      success: true,\n   608‚Üí      data: {\n   609‚Üí        textFile: {\n   610‚Üí          filename: path.basename(result.textOutputPath),\n   611‚Üí          path: `/uploads/${path.basename(result.textOutputPath)}`,\n   612‚Üí          url: `${req.protocol}://${req.get('host')}/uploads/${path.basename(result.textOutputPath)}`,\n   613‚Üí          type: 'Plain Text Report'\n   614‚Üí        },\n   615‚Üí        jsonFile: {\n   616‚Üí          filename: path.basename(result.outputPath),\n   617‚Üí          path: `/uploads/${path.basename(result.outputPath)}`,\n   618‚Üí          url: `${req.protocol}://${req.get('host')}/uploads/${path.basename(result.outputPath)}`,\n   619‚Üí          type: 'Structured Data (JSON)'\n   620‚Üí        },\n   621‚Üí        contentLength: result.contentLength,\n   622‚Üí        tokensUsed: result.tokensUsed,\n   623‚Üí        generatedAt: new Date().toISOString()\n   624‚Üí      },\n   625‚Üí      message: 'AI-powered NeuroSense report generated successfully. Text file contains formatted report ready for PDF conversion.'\n   626‚Üí    });\n   627‚Üí\n   628‚Üí  } catch (error) {\n   629‚Üí    console.error('\\n‚ùå === AI PDF Generation Failed ===');\n   630‚Üí    console.error('Error:', error.message);\n   631‚Üí    console.error('Stack:', error.stack);\n   632‚Üí\n   633‚Üí    res.status(500).json({\n   634‚Üí      error: true,\n   635‚Üí      message: error.message || 'Failed to generate AI PDF report',\n   636‚Üí      details: process.env.NODE_ENV === 'development' ? error.stack : undefined\n   637‚Üí    });\n   638‚Üí  }\n   639‚Üí});\n   640‚Üí\n   641‚Üí/**\n   642‚Üí * POST /api/qeeg/generate-ai-sample-pdf\n   643‚Üí * Generate a sample AI-powered PDF report for testing\n   644‚Üí */\n   645‚Üírouter.post('/generate-ai-sample-pdf', async (req, res) => {\n   646‚Üí  try {\n   647‚Üí    console.log('\\nü§ñ === Sample AI PDF Generation Started ===\\n');\n   648‚Üí\n   649‚Üí    const result = await AIPdfGenerator.generateSampleReport();\n   650‚Üí\n   651‚Üí    console.log('‚úÖ Sample AI PDF Generated!');\n   652‚Üí    console.log('üìÑ Path:', result.outputPath);\n   653‚Üí\n   654‚Üí    const filename = path.basename(result.outputPath);\n   655‚Üí\n   656‚Üí    res.json({\n   657‚Üí      success: true,\n   658‚Üí      data: {\n   659‚Üí        filename: filename,\n   660‚Üí        path: `/uploads/${filename}`,\n   661‚Üí        url: `${req.protocol}://${req.get('host')}/uploads/${filename}`,\n   662‚Üí        contentLength: result.contentLength,\n   663‚Üí        tokensUsed: result.tokensUsed,\n   664‚Üí        type: 'AI-Generated Sample (JSON format)'\n   665‚Üí      }\n   666‚Üí    });\n   667‚Üí\n   668‚Üí  } catch (error) {\n   669‚Üí    console.error('‚ùå Sample AI PDF generation failed:', error);\n   670‚Üí\n   671‚Üí    res.status(500).json({\n   672‚Üí      error: true,\n   673‚Üí      message: error.message\n   674‚Üí    });\n   675‚Üí  }\n   676‚Üí});\n   677‚Üí\n   678‚Üí/**\n   679‚Üí * GET /api/qeeg/supabase-pdfs\n   680‚Üí * List all PDFs from Supabase bucket\n   681‚Üí */\n   682‚Üírouter.get('/supabase-pdfs', async (req, res) => {\n   683‚Üí  try {\n   684‚Üí    console.log('üìã Fetching PDFs from Supabase bucket...');\n   685‚Üí\n   686‚Üí    const files = await SupabaseStorage.listFiles('neurosense_bucketreports', 'reports');\n   687‚Üí\n   688‚Üí    // Get public URLs for all files\n   689‚Üí    const pdfs = files.map(file => {\n   690‚Üí      const { createClient } = require('@supabase/supabase-js');\n   691‚Üí      const supabase = createClient(process.env.SUPABASE_URL, process.env.SUPABASE_SERVICE_ROLE_KEY);\n   692‚Üí      const { data: urlData } = supabase.storage\n   693‚Üí        .from('neurosense_bucketreports')\n   694‚Üí        .getPublicUrl(`reports/${file.name}`);\n   695‚Üí\n   696‚Üí      return {\n   697‚Üí        name: file.name,\n   698‚Üí        url: urlData.publicUrl,\n   699‚Üí        created_at: file.created_at,\n   700‚Üí        size: file.metadata?.size\n   701‚Üí      };\n   702‚Üí    });\n   703‚Üí\n   704‚Üí    console.log(`‚úÖ Found ${pdfs.length} PDFs in Supabase bucket`);\n   705‚Üí\n   706‚Üí    res.json({\n   707‚Üí      success: true,\n   708‚Üí      count: pdfs.length,\n   709‚Üí      pdfs: pdfs\n   710‚Üí    });\n   711‚Üí\n   712‚Üí  } catch (error) {\n   713‚Üí    console.error('‚ùå Error listing Supabase PDFs:', error);\n   714‚Üí    res.status(500).json({\n   715‚Üí      success: false,\n   716‚Üí      error: error.message\n   717‚Üí    });\n   718‚Üí  }\n   719‚Üí});\n   720‚Üí\n   721‚Üí/**\n   722‚Üí * GET /api/qeeg/test\n   723‚Üí * Test endpoint to verify API is working\n   724‚Üí */\n   725‚Üírouter.get('/test', (req, res) => {\n   726‚Üí  res.json({\n   727‚Üí    success: true,\n   728‚Üí    message: 'QEEG Processing API is working',\n   729‚Üí    endpoints: {\n   730‚Üí      process: 'POST /api/qeeg/process - Upload and process QEEG files',\n   731‚Üí      generatePdf: 'POST /api/qeeg/generate-pdf - Generate PDF report from results (PDFKit)',\n   732‚Üí      generateSamplePdf: 'POST /api/qeeg/generate-sample-pdf - Generate sample PDF report (PDFKit)',\n   733‚Üí      generateAiPdf: 'POST /api/qeeg/generate-ai-pdf - Generate AI-powered PDF report (OpenAI)',\n   734‚Üí      generateAiSamplePdf: 'POST /api/qeeg/generate-ai-sample-pdf - Generate AI sample PDF report (OpenAI)',\n   735‚Üí      generateGeminiReport: 'POST /api/qeeg/generate-gemini-report - Generate AI report structure using Gemini',\n   736‚Üí      supabasePdfs: 'GET /api/qeeg/supabase-pdfs - List all PDFs from Supabase bucket'\n   737‚Üí    }\n   738‚Üí  });\n   739‚Üí});\n   740‚Üí\n   741‚Üí/**\n   742‚Üí * POST /api/qeeg/generate-gemini-report\n   743‚Üí * Generate AI-powered report structure using Google Gemini\n   744‚Üí */\n   745‚Üírouter.post('/generate-gemini-report', async (req, res) => {\n   746‚Üí  try {\n   747‚Üí    console.log('\\nü§ñ === Gemini AI Report Generation Started ===\\n');\n   748‚Üí\n   749‚Üí    if (!GeminiService) {\n   750‚Üí      return res.status(503).json({\n   751‚Üí        error: true,\n   752‚Üí        message: 'Gemini AI service is not available. Please check server configuration.'\n   753‚Üí      });\n   754‚Üí    }\n   755‚Üí\n   756‚Üí    const { algorithmResults } = req.body;\n   757‚Üí\n   758‚Üí    // Validate input\n   759‚Üí    if (!algorithmResults || !algorithmResults.parameters) {\n   760‚Üí      return res.status(400).json({\n   761‚Üí        error: true,\n   762‚Üí        message: 'Missing required data: algorithmResults with parameters array is required'\n   763‚Üí      });\n   764‚Üí    }\n   765‚Üí\n   766‚Üí    console.log('üìä Processing', algorithmResults.parameters.length, 'brain parameters');\n   767‚Üí\n   768‚Üí    // Transform algorithm results to the format expected by Gemini\n   769‚Üí    const brainParameters = {\n   770‚Üí      Cognition: null,\n   771‚Üí      Stress: null,\n   772‚Üí      FocusAndAttention: null,\n   773‚Üí      BurnoutAndFatigue: null,\n   774‚Üí      EmotionalRegulation: null,\n   775‚Üí      Learning: null,\n   776‚Üí      Creativity: null\n   777‚Üí    };\n   778‚Üí\n   779‚Üí    // Map the parameters from algorithm results\n   780‚Üí    algorithmResults.parameters.forEach(param => {\n   781‚Üí      const paramName = param.name.replace(/\\s+/g, '');\n   782‚Üí      if (brainParameters.hasOwnProperty(paramName)) {\n   783‚Üí        brainParameters[paramName] = {\n   784‚Üí          score: param.score,\n   785‚Üí          bucket: param.bucket,\n   786‚Üí          subparameters: param.subParameters || []\n   787‚Üí        };\n   788‚Üí      }\n   789‚Üí    });\n   790‚Üí\n   791‚Üí    console.log('üß† Brain Parameters prepared for Gemini');\n   792‚Üí\n   793‚Üí    // Generate report using Gemini AI\n   794‚Üí    const result = await GeminiService.generateBrainPerformanceReport(brainParameters);\n   795‚Üí\n   796‚Üí    if (!result.success) {\n   797‚Üí      return res.status(500).json({\n   798‚Üí        error: true,\n   799‚Üí        message: 'Failed to generate report with Gemini AI',\n   800‚Üí        details: result.error\n   801‚Üí      });\n   802‚Üí    }\n   803‚Üí\n   804‚Üí    console.log('‚úÖ Gemini AI report generated successfully');\n   805‚Üí\n   806‚Üí    res.json({\n   807‚Üí      success: true,\n   808‚Üí      message: 'AI-powered report structure generated successfully',\n   809‚Üí      reportData: result.data,\n   810‚Üí      rawResponse: result.rawResponse\n   811‚Üí    });\n   812‚Üí\n   813‚Üí  } catch (error) {\n   814‚Üí    console.error('‚ùå Error generating Gemini report:', error);\n   815‚Üí    res.status(500).json({\n   816‚Üí      error: true,\n   817‚Üí      message: 'Internal server error while generating Gemini report',\n   818‚Üí      details: error.message\n   819‚Üí    });\n   820‚Üí  }\n   821‚Üí});\n   822‚Üí\n   823‚Üímodule.exports = router;\n   824‚Üí\n   825‚Üí\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"263ad256-0ce0-43b6-ac3e-1d5be87abdd8","timestamp":"2025-12-02T09:00:47.973Z","toolUseResult":{"type":"text","file":{"filePath":"D:\\Todays\\Neuro360\\server\\routes\\qeegRoutes.js","content":"const express = require('express');\nconst multer = require('multer');\nconst path = require('path');\nconst fs = require('fs');\nconst QEEGParser = require('../services/qeegParser');\nconst AlgorithmCalculator = require('../services/algorithmCalculator');\n// OLD generators (keeping for fallback)\nconst PDFReportGenerator = require('../services/pdfGenerator');\nconst TemplateBasedPDFGenerator = require('../services/pdfGeneratorTemplate');\nconst templateManager = require('../services/pdf/templateManager');\nconst AIPdfGenerator = require('../services/aiPdfGenerator');\nconst SupabaseStorage = require('../services/supabaseStorage');\n\n// NEW: Gemini AI Service for report generation\nlet GeminiService = null;\ntry {\n  GeminiService = require('../services/geminiService');\n  console.log('‚úÖ Gemini AI Service loaded successfully');\n} catch (error) {\n  console.error('‚ùå CRITICAL: Gemini AI Service failed to load!');\n  console.error('   Error:', error.message);\n  console.error('   Stack:', error.stack);\n}\n\n// NEW: Gemini PDF Generator - Uses Gemini AI for content generation\nlet GeminiPdfGenerator = null;\ntry {\n  GeminiPdfGenerator = require('../services/geminiPdfGenerator');\n  console.log('‚úÖ Gemini PDF Generator loaded successfully');\n  console.log('   Generator available:', !!GeminiPdfGenerator);\n} catch (error) {\n  console.error('‚ùå CRITICAL: Gemini PDF Generator failed to load!');\n  console.error('   Error:', error.message);\n  console.error('   Stack:', error.stack);\n}\n\n// OLD: Enhanced AI PDF Generator with OpenAI (keeping as fallback)\nlet EnhancedAIPdfGenerator = null;\ntry {\n  EnhancedAIPdfGenerator = require('../services/aiPdfGeneratorEnhanced');\n  console.log('‚úÖ Enhanced AI PDF Generator loaded successfully');\n} catch (error) {\n  console.warn('‚ö†Ô∏è  Enhanced AI PDF Generator failed to load:', error.message);\n  console.warn('   Will use fallback PDF generator');\n}\n\nconst router = express.Router();\n\n// Configure multer for file uploads\nconst storage = multer.diskStorage({\n  destination: function (req, file, cb) {\n    const uploadDir = path.join(__dirname, '../uploads');\n    // Ensure upload directory exists\n    if (!fs.existsSync(uploadDir)) {\n      fs.mkdirSync(uploadDir, { recursive: true });\n    }\n    cb(null, uploadDir);\n  },\n  filename: function (req, file, cb) {\n    const uniqueSuffix = Date.now() + '-' + Math.round(Math.random() * 1E9);\n    cb(null, file.fieldname + '-' + uniqueSuffix + path.extname(file.originalname));\n  }\n});\n\nconst upload = multer({\n  storage: storage,\n  limits: {\n    fileSize: 10 * 1024 * 1024 // 10MB limit\n  },\n  fileFilter: function (req, file, cb) {\n    const allowedExtensions = ['.pdf', '.csv', '.xlsx', '.xls'];\n    const ext = path.extname(file.originalname).toLowerCase();\n    if (allowedExtensions.includes(ext)) {\n      cb(null, true);\n    } else {\n      cb(new Error(`Only ${allowedExtensions.join(', ')} files are allowed`));\n    }\n  }\n});\n\n/**\n * POST /api/qeeg/process\n * Process QEEG files and calculate 7 brain health parameters\n */\nrouter.post('/process', upload.fields([\n  { name: 'eyesOpen', maxCount: 1 },\n  { name: 'eyesClosed', maxCount: 1 }\n]), async (req, res) => {\n  let eyesOpenFile = null;\n  let eyesClosedFile = null;\n\n  try {\n    console.log('\\nüî¨ === QEEG Processing Started ===\\n');\n\n    // Get uploaded files\n    const files = req.files;\n    if (!files || !files.eyesOpen || !files.eyesClosed) {\n      return res.status(400).json({\n        error: true,\n        message: 'Both Eyes Open and Eyes Closed files are required'\n      });\n    }\n\n    eyesOpenFile = files.eyesOpen[0];\n    eyesClosedFile = files.eyesClosed[0];\n\n    console.log('üìÅ Files received:');\n    console.log('  - Eyes Open:', eyesOpenFile.originalname, `(${(eyesOpenFile.size / 1024).toFixed(2)} KB)`);\n    console.log('  - Eyes Closed:', eyesClosedFile.originalname, `(${(eyesClosedFile.size / 1024).toFixed(2)} KB)`);\n\n    // Get patient info from request body\n    const {\n      patientId,\n      patientName,\n      clinicName,\n      dateOfBirth,\n      age,\n      gender,\n      handedness\n    } = req.body;\n\n    console.log('\\nüë§ Patient Information:');\n    console.log('  - Patient ID:', patientId);\n    console.log('  - Patient Name:', patientName);\n    console.log('  - Clinic:', clinicName);\n    console.log('  - Date of Birth:', dateOfBirth);\n    console.log('  - Age:', age);\n    console.log('  - Gender:', gender);\n    console.log('  - Handedness:', handedness);\n\n    // Validate OpenAI API configuration before processing (OPTIONAL - don't fail if missing)\n    console.log('\\nüîê Checking OpenAI API configuration...');\n    try {\n      await QEEGParser.testAPIConnection();\n      console.log('‚úÖ OpenAI API configured properly');\n    } catch (apiError) {\n      console.warn('‚ö†Ô∏è  OpenAI API not configured or failed test:', apiError.message);\n      console.warn('   Continuing with processing anyway...');\n      // Don't throw error - allow processing to continue without OpenAI\n    }\n\n    // Step 1: Parse QEEG files\n    console.log('\\nüìä Step 1: Parsing QEEG files...');\n    const qeegData = await QEEGParser.parse(eyesOpenFile, eyesClosedFile);\n\n    // Validate that we got real patient data\n    console.log('\\nüìä QEEG Data Validation:');\n    console.log('  - Eyes Open (EO) channels:', Object.keys(qeegData.EO?.absolute || {}).length);\n    console.log('  - Eyes Closed (EC) channels:', Object.keys(qeegData.EC?.absolute || {}).length);\n    console.log('  - Using REAL PATIENT DATA (not sample data)');\n    console.log('  - Patient:', patientName, `(ID: ${patientId})`);\n\n    // Step 2: Calculate parameters\n    console.log('\\nüßÆ Step 2: Calculating 7 brain health parameters...');\n    const calculator = new AlgorithmCalculator(qeegData);\n    const results = calculator.calculate();\n\n    console.log('\\n‚úÖ Calculation completed successfully!');\n    console.log('üìà Results Summary:');\n    results.parameters.forEach(param => {\n      console.log(`  - ${param.name}: ${param.score}/${param.maxScore} (${param.classification})`);\n    });\n    console.log(`  - Overall Score: ${results.overallScore}/21`);\n\n    // Step 3: Auto-generate PDF report\n    console.log('\\nüìÑ Step 3: Auto-generating PDF report...');\n    let pdfUrl = null;\n    let pdfFilename = null;\n\n    try {\n      // Prepare patient data for PDF\n      const pdfPatientData = {\n        name: patientName,\n        dateOfBirth: dateOfBirth || 'N/A',\n        age: age || 'N/A',\n        gender: gender || 'Not specified',\n        handedness: handedness || 'Not specified',\n        patientId: patientId,\n        clinicName: clinicName\n      };\n\n      // Prepare algorithm results for PDF\n      const pdfAlgorithmResults = {\n        parameters: results.parameters,\n        overallScore: results.overallScore\n      };\n\n      // Debug: Log parameters being sent to PDF\n      console.log('\\nüìä Parameters for PDF:');\n      console.log('  - Total Parameters:', pdfAlgorithmResults.parameters.length);\n      console.log('  - Overall Score:', pdfAlgorithmResults.overallScore);\n      pdfAlgorithmResults.parameters.forEach((param, i) => {\n        console.log(`  ${i + 1}. ${param.name}: ${param.score}/${param.maxScore} (${param.classification})`);\n      });\n\n      // Create output filename\n      const timestamp = Date.now();\n      const sanitizedName = (patientName || 'patient').replace(/[^a-z0-9]/gi, '_').toLowerCase();\n      pdfFilename = `neurosense-report-${sanitizedName}-${timestamp}.pdf`;\n      const uploadsDir = path.join(__dirname, '../uploads');\n      const pdfOutputPath = path.join(uploadsDir, pdfFilename);\n\n      // Ensure uploads directory exists\n      if (!fs.existsSync(uploadsDir)) {\n        console.log('üìÅ Creating uploads directory...');\n        fs.mkdirSync(uploadsDir, { recursive: true });\n      }\n\n      console.log('üìù Generating PDF to:', pdfFilename);\n      console.log('   Full path:', pdfOutputPath);\n\n      // === USE GEMINI PDF GENERATOR (with fallback) ===\n      console.log('\\nüîç Checking available PDF generators...');\n      console.log('   GeminiPdfGenerator available:', !!GeminiPdfGenerator);\n      console.log('   EnhancedAIPdfGenerator available:', !!EnhancedAIPdfGenerator);\n      console.log('   PDFReportGenerator available:', !!PDFReportGenerator);\n\n      let pdfGenerator;\n      if (GeminiPdfGenerator) {\n        console.log('\\nü§ñ === USING GEMINI AI PDF GENERATOR ===');\n        console.log('   Engine: Google Gemini + PDFKit');\n        console.log('   Patient:', pdfPatientData.name);\n        console.log('   Parameters:', pdfAlgorithmResults.parameters.length);\n        try {\n          pdfGenerator = new GeminiPdfGenerator(pdfPatientData, pdfAlgorithmResults, qeegData);\n          console.log('‚úÖ Gemini PDF Generator instantiated successfully');\n        } catch (instantiateError) {\n          console.error('‚ùå Failed to instantiate Gemini PDF Generator:', instantiateError.message);\n          throw instantiateError;\n        }\n      } else if (EnhancedAIPdfGenerator) {\n        console.log('ü§ñ Using Enhanced AI PDF Generator (OpenAI + PDFKit - Fallback)');\n        pdfGenerator = new EnhancedAIPdfGenerator(pdfPatientData, pdfAlgorithmResults, qeegData);\n      } else {\n        console.log('üìÑ Using Standard PDF Generator (Basic fallback)');\n        pdfGenerator = new PDFReportGenerator(pdfPatientData, pdfAlgorithmResults, qeegData);\n      }\n\n      // Generate the PDF\n      console.log('\\nüìù Calling pdfGenerator.generateReport()...');\n      console.log('   Output path:', pdfOutputPath);\n\n      try {\n        await pdfGenerator.generateReport(pdfOutputPath);\n        console.log('‚úÖ PDF generation completed!');\n      } catch (genError) {\n        console.error('‚ùå PDF generation threw error:', genError.message);\n        console.error('   Stack:', genError.stack);\n        throw genError;\n      }\n\n      // Verify file was created\n      if (!fs.existsSync(pdfOutputPath)) {\n        throw new Error('PDF file was not created at expected path: ' + pdfOutputPath);\n      }\n\n      console.log('‚úÖ PDF file verified at:', pdfOutputPath);\n      console.log('üìÑ File:', pdfFilename);\n      console.log('üìä Size:', (fs.statSync(pdfOutputPath).size / 1024).toFixed(2), 'KB');\n\n      // Upload to Supabase Storage\n      try {\n        console.log('\\n‚òÅÔ∏è  Uploading PDF to Supabase storage...');\n        const uploadResult = await SupabaseStorage.uploadFile(\n          pdfOutputPath,\n          'neurosense_bucketreports', // bucket name\n          `reports/${pdfFilename}` // path in bucket\n        );\n\n        // Verify upload was successful and URL is valid\n        if (uploadResult && uploadResult.url) {\n          pdfUrl = uploadResult.url;\n          console.log('‚úÖ PDF uploaded to Supabase successfully');\n          console.log('üîó Supabase URL:', pdfUrl);\n\n          // Delete local file after successful Supabase upload\n          try {\n            fs.unlinkSync(pdfOutputPath);\n            console.log('üóëÔ∏è  Local PDF file deleted after successful upload');\n          } catch (deleteError) {\n            console.warn('‚ö†Ô∏è  Could not delete local PDF file:', deleteError.message);\n          }\n        } else {\n          throw new Error('Supabase upload returned invalid result');\n        }\n      } catch (supabaseError) {\n        console.error('‚ö†Ô∏è  Supabase upload failed, using local storage');\n        console.error('   Error message:', supabaseError.message);\n        console.error('   Error stack:', supabaseError.stack);\n        console.error('   Full error:', JSON.stringify(supabaseError, null, 2));\n        // Fallback to local storage\n        pdfUrl = `/uploads/${pdfFilename}`;\n        console.log('üìÅ Using local file as fallback:', pdfUrl);\n      }\n\n    } catch (pdfError) {\n      console.error('\\n‚ùå === PDF GENERATION FAILED ===');\n      console.error('Error message:', pdfError.message);\n      console.error('Error stack:', pdfError.stack);\n      console.error('Full error:', pdfError);\n      console.error('=================================\\n');\n\n      // Set pdfUrl to null so frontend knows PDF failed\n      pdfUrl = null;\n\n      // Don't fail the whole request if PDF fails - processing still succeeded\n      console.log('‚ö†Ô∏è Continuing without PDF - processing succeeded');\n    }\n\n    // Clean up uploaded files\n    try {\n      fs.unlinkSync(eyesOpenFile.path);\n      fs.unlinkSync(eyesClosedFile.path);\n      console.log('\\nüóëÔ∏è  Temporary files cleaned up');\n    } catch (cleanupError) {\n      console.error('‚ö†Ô∏è  Error cleaning up files:', cleanupError.message);\n    }\n\n    console.log('\\nüèÅ === QEEG Processing Completed ===\\n');\n\n    // Final check for PDF URL\n    if (!pdfUrl) {\n      console.warn('‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è WARNING: No PDF URL available in response!');\n      console.warn('   pdfFilename was:', pdfFilename || 'NOT SET');\n      console.warn('   This means PDF generation completely failed');\n    } else {\n      console.log('‚úÖ PDF URL ready:', pdfUrl);\n      console.log('   Type:', pdfUrl.startsWith('http') ? 'Supabase' : 'Local');\n    }\n\n    // Send response\n    res.json({\n      success: true,\n      data: {\n        patientId,\n        patientName,\n        clinicName,\n        processedAt: new Date().toISOString(),\n        results: results.parameters,\n        overallScore: results.overallScore,\n        maxScore: 21,\n        pdfUrl: pdfUrl,\n        pdfFilename: pdfFilename\n      }\n    });\n\n  } catch (error) {\n    console.error('\\n‚ùå === QEEG Processing Failed ===');\n    console.error('Error:', error.message);\n    console.error('Error Code:', error.code || 'UNKNOWN');\n    console.error('Stack:', error.stack);\n\n    // Clean up files on error\n    if (eyesOpenFile && fs.existsSync(eyesOpenFile.path)) {\n      try {\n        fs.unlinkSync(eyesOpenFile.path);\n      } catch (e) {\n        console.error('Error deleting Eyes Open file:', e.message);\n      }\n    }\n    if (eyesClosedFile && fs.existsSync(eyesClosedFile.path)) {\n      try {\n        fs.unlinkSync(eyesClosedFile.path);\n      } catch (e) {\n        console.error('Error deleting Eyes Closed file:', e.message);\n      }\n    }\n\n    // Categorize errors for better user feedback\n    let statusCode = 500;\n    let userMessage = error.message;\n\n    switch (error.code) {\n      case 'MISSING_API_KEY':\n      case 'INVALID_API_KEY':\n      case 'INVALID_API_KEY_FORMAT':\n      case 'API_CONNECTION_FAILED':\n        statusCode = 503; // Service Unavailable\n        userMessage = 'System configuration error: OpenAI API key not properly configured. Please contact support.';\n        break;\n\n      case 'PDF_EXTRACTION_FAILED':\n        statusCode = 422; // Unprocessable Entity\n        userMessage = 'Failed to extract QEEG data from PDF. Please ensure the PDF contains valid QEEG tables with absolute and relative power values.';\n        break;\n\n      default:\n        userMessage = error.message || 'Failed to process QEEG files';\n    }\n\n    res.status(statusCode).json({\n      error: true,\n      message: userMessage,\n      code: error.code || 'UNKNOWN_ERROR',\n      technicalDetails: process.env.NODE_ENV === 'development' ? {\n        originalMessage: error.message,\n        stack: error.stack,\n        condition: error.condition\n      } : undefined\n    });\n  }\n});\n\n/**\n * POST /api/qeeg/generate-pdf\n * Generate PDF report from algorithm results\n */\nrouter.post('/generate-pdf', async (req, res) => {\n  try {\n    console.log('\\nüìÑ === PDF Report Generation Started ===\\n');\n\n    const { patientData, algorithmResults, qeegData } = req.body;\n\n    // Validate input\n    if (!patientData || !algorithmResults || !qeegData) {\n      return res.status(400).json({\n        error: true,\n        message: 'Missing required data: patientData, algorithmResults, and qeegData are required'\n      });\n    }\n\n    console.log('üë§ Patient:', patientData.name);\n    console.log('üìä Parameters:', algorithmResults.parameters?.length);\n\n    // === USE GEMINI PDF GENERATOR (if available) ===\n    let generator;\n    if (GeminiPdfGenerator) {\n      console.log('ü§ñ Using Gemini AI PDF Generator (Google Gemini + PDFKit)');\n      generator = new GeminiPdfGenerator(patientData, algorithmResults, qeegData);\n    } else if (EnhancedAIPdfGenerator) {\n      console.log('ü§ñ Using Enhanced AI PDF Generator (OpenAI + PDFKit - Fallback)');\n      generator = new EnhancedAIPdfGenerator(patientData, algorithmResults, qeegData);\n    } else {\n      console.log('üìÑ Using Standard PDF Generator (Basic fallback)');\n      generator = new PDFReportGenerator(patientData, algorithmResults, qeegData);\n    }\n\n    // Create output filename\n    const timestamp = Date.now();\n    const sanitizedName = (patientData.name || 'patient').replace(/[^a-z0-9]/gi, '_').toLowerCase();\n    const filename = `neurosense-report-${sanitizedName}-${timestamp}.pdf`;\n    const outputPath = path.join(__dirname, '../uploads', filename);\n\n    console.log('üìù Generating AI-powered PDF to:', filename);\n\n    // Generate the PDF with AI insights\n    const pdfPath = await generator.generateReport(outputPath);\n\n    console.log('\\n‚úÖ PDF Report Generated Successfully!');\n    console.log('üìÑ File:', filename);\n    console.log('üìä Size:', (fs.statSync(pdfPath).size / 1024).toFixed(2), 'KB');\n\n    // Upload to Supabase Storage - TEMPORARILY DISABLED\n    let supabaseUrl = null;\n    let supabasePath = null;\n    let uploadError = null;\n\n    // DISABLE SUPABASE UPLOAD FOR NOW - USE LOCAL STORAGE ONLY\n    console.log('\\nüìÅ Using local storage (Supabase upload disabled)');\n    uploadError = 'Supabase upload disabled - using local storage';\n\n    /* COMMENTED OUT - Enable when Supabase is configured properly\n    try {\n      console.log('\\n‚òÅÔ∏è  Uploading PDF to Supabase storage...');\n      const uploadResult = await SupabaseStorage.uploadFile(\n        pdfPath,\n        'patient-reports', // bucket name\n        `reports/${filename}` // path in bucket\n      );\n\n      // Verify upload was successful and URL is valid\n      if (uploadResult && uploadResult.url) {\n        supabaseUrl = uploadResult.url;\n        supabasePath = uploadResult.path;\n\n        console.log('‚úÖ PDF uploaded to Supabase successfully');\n        console.log('üîó Supabase URL:', supabaseUrl);\n\n        // Only delete local file after SUCCESSFUL Supabase upload\n        try {\n          fs.unlinkSync(pdfPath);\n          console.log('üóëÔ∏è  Local PDF file deleted after successful upload');\n        } catch (deleteError) {\n          console.warn('‚ö†Ô∏è  Could not delete local PDF file:', deleteError.message);\n        }\n      } else {\n        throw new Error('Supabase upload returned invalid result');\n      }\n\n    } catch (error) {\n      console.error('‚ö†Ô∏è  Supabase upload failed, using local storage:', error.message);\n      uploadError = error.message;\n      // Keep local file as fallback - DO NOT DELETE\n      console.log('üìÅ Using local file as fallback');\n    }\n    */\n\n    console.log('\\nüèÅ === PDF Generation Completed ===\\n');\n\n    // Return PDF info - prioritize Supabase URL\n    res.json({\n      success: true,\n      data: {\n        filename: filename,\n        path: supabasePath || `/uploads/${filename}`,\n        url: supabaseUrl || `${req.protocol}://${req.get('host')}/uploads/${filename}`,\n        size: fs.existsSync(pdfPath) ? fs.statSync(pdfPath).size : 0,\n        generatedAt: new Date().toISOString(),\n        storage: supabaseUrl ? 'supabase' : 'local',\n        uploadError: uploadError\n      }\n    });\n\n  } catch (error) {\n    console.error('\\n‚ùå === PDF Generation Failed ===');\n    console.error('Error:', error.message);\n    console.error('Stack:', error.stack);\n\n    res.status(500).json({\n      error: true,\n      message: error.message || 'Failed to generate PDF report',\n      details: process.env.NODE_ENV === 'development' ? error.stack : undefined\n    });\n  }\n});\n\n/**\n * POST /api/qeeg/generate-sample-pdf\n * Generate a sample PDF report for testing\n */\nrouter.post('/generate-sample-pdf', async (req, res) => {\n  try {\n    console.log('\\nüìÑ === Sample PDF Generation Started ===\\n');\n\n    const pdfPath = await PDFReportGenerator.generateSampleReport();\n\n    console.log('‚úÖ Sample PDF Generated!');\n    console.log('üìÑ Path:', pdfPath);\n\n    const filename = path.basename(pdfPath);\n\n    res.json({\n      success: true,\n      data: {\n        filename: filename,\n        path: `/uploads/${filename}`,\n        url: `${req.protocol}://${req.get('host')}/uploads/${filename}`,\n        size: fs.statSync(pdfPath).size\n      }\n    });\n\n  } catch (error) {\n    console.error('‚ùå Sample PDF generation failed:', error);\n\n    res.status(500).json({\n      error: true,\n      message: error.message\n    });\n  }\n});\n\n/**\n * POST /api/qeeg/generate-ai-pdf\n * Generate AI-powered PDF report with enhanced design and content\n */\nrouter.post('/generate-ai-pdf', async (req, res) => {\n  try {\n    console.log('\\nü§ñ === AI PDF Report Generation Started ===\\n');\n\n    const { patientData, algorithmResults, qeegData } = req.body;\n\n    // Validate input\n    if (!patientData || !algorithmResults || !qeegData) {\n      return res.status(400).json({\n        error: true,\n        message: 'Missing required data: patientData, algorithmResults, and qeegData are required'\n      });\n    }\n\n    console.log('üë§ Patient:', patientData.name);\n    console.log('üìä Parameters:', algorithmResults.parameters?.length);\n    console.log('üéØ Using AI-powered generation with enhanced prompt');\n\n    // Generate AI PDF\n    const generator = new AIPdfGenerator(patientData, algorithmResults, qeegData);\n\n    // Create output filename\n    const timestamp = Date.now();\n    const sanitizedName = (patientData.name || 'patient').replace(/[^a-z0-9]/gi, '_').toLowerCase();\n    const filename = `ai-neurosense-report-${sanitizedName}-${timestamp}.pdf`;\n    const outputPath = path.join(__dirname, '../uploads', filename);\n\n    console.log('üìù Generating AI PDF to:', filename);\n\n    // Generate the PDF\n    const result = await generator.generateReport(outputPath);\n\n    console.log('\\n‚úÖ AI NeuroSense Report Generated Successfully!');\n    console.log('üìÑ Text File:', path.basename(result.textOutputPath));\n    console.log('üìÑ JSON File:', path.basename(result.outputPath));\n    console.log('üìä Tokens Used:', result.tokensUsed);\n    console.log('üìè Content Length:', result.contentLength, 'characters');\n    console.log('\\nüèÅ === AI PDF Generation Completed ===\\n');\n\n    // Return report info\n    res.json({\n      success: true,\n      data: {\n        textFile: {\n          filename: path.basename(result.textOutputPath),\n          path: `/uploads/${path.basename(result.textOutputPath)}`,\n          url: `${req.protocol}://${req.get('host')}/uploads/${path.basename(result.textOutputPath)}`,\n          type: 'Plain Text Report'\n        },\n        jsonFile: {\n          filename: path.basename(result.outputPath),\n          path: `/uploads/${path.basename(result.outputPath)}`,\n          url: `${req.protocol}://${req.get('host')}/uploads/${path.basename(result.outputPath)}`,\n          type: 'Structured Data (JSON)'\n        },\n        contentLength: result.contentLength,\n        tokensUsed: result.tokensUsed,\n        generatedAt: new Date().toISOString()\n      },\n      message: 'AI-powered NeuroSense report generated successfully. Text file contains formatted report ready for PDF conversion.'\n    });\n\n  } catch (error) {\n    console.error('\\n‚ùå === AI PDF Generation Failed ===');\n    console.error('Error:', error.message);\n    console.error('Stack:', error.stack);\n\n    res.status(500).json({\n      error: true,\n      message: error.message || 'Failed to generate AI PDF report',\n      details: process.env.NODE_ENV === 'development' ? error.stack : undefined\n    });\n  }\n});\n\n/**\n * POST /api/qeeg/generate-ai-sample-pdf\n * Generate a sample AI-powered PDF report for testing\n */\nrouter.post('/generate-ai-sample-pdf', async (req, res) => {\n  try {\n    console.log('\\nü§ñ === Sample AI PDF Generation Started ===\\n');\n\n    const result = await AIPdfGenerator.generateSampleReport();\n\n    console.log('‚úÖ Sample AI PDF Generated!');\n    console.log('üìÑ Path:', result.outputPath);\n\n    const filename = path.basename(result.outputPath);\n\n    res.json({\n      success: true,\n      data: {\n        filename: filename,\n        path: `/uploads/${filename}`,\n        url: `${req.protocol}://${req.get('host')}/uploads/${filename}`,\n        contentLength: result.contentLength,\n        tokensUsed: result.tokensUsed,\n        type: 'AI-Generated Sample (JSON format)'\n      }\n    });\n\n  } catch (error) {\n    console.error('‚ùå Sample AI PDF generation failed:', error);\n\n    res.status(500).json({\n      error: true,\n      message: error.message\n    });\n  }\n});\n\n/**\n * GET /api/qeeg/supabase-pdfs\n * List all PDFs from Supabase bucket\n */\nrouter.get('/supabase-pdfs', async (req, res) => {\n  try {\n    console.log('üìã Fetching PDFs from Supabase bucket...');\n\n    const files = await SupabaseStorage.listFiles('neurosense_bucketreports', 'reports');\n\n    // Get public URLs for all files\n    const pdfs = files.map(file => {\n      const { createClient } = require('@supabase/supabase-js');\n      const supabase = createClient(process.env.SUPABASE_URL, process.env.SUPABASE_SERVICE_ROLE_KEY);\n      const { data: urlData } = supabase.storage\n        .from('neurosense_bucketreports')\n        .getPublicUrl(`reports/${file.name}`);\n\n      return {\n        name: file.name,\n        url: urlData.publicUrl,\n        created_at: file.created_at,\n        size: file.metadata?.size\n      };\n    });\n\n    console.log(`‚úÖ Found ${pdfs.length} PDFs in Supabase bucket`);\n\n    res.json({\n      success: true,\n      count: pdfs.length,\n      pdfs: pdfs\n    });\n\n  } catch (error) {\n    console.error('‚ùå Error listing Supabase PDFs:', error);\n    res.status(500).json({\n      success: false,\n      error: error.message\n    });\n  }\n});\n\n/**\n * GET /api/qeeg/test\n * Test endpoint to verify API is working\n */\nrouter.get('/test', (req, res) => {\n  res.json({\n    success: true,\n    message: 'QEEG Processing API is working',\n    endpoints: {\n      process: 'POST /api/qeeg/process - Upload and process QEEG files',\n      generatePdf: 'POST /api/qeeg/generate-pdf - Generate PDF report from results (PDFKit)',\n      generateSamplePdf: 'POST /api/qeeg/generate-sample-pdf - Generate sample PDF report (PDFKit)',\n      generateAiPdf: 'POST /api/qeeg/generate-ai-pdf - Generate AI-powered PDF report (OpenAI)',\n      generateAiSamplePdf: 'POST /api/qeeg/generate-ai-sample-pdf - Generate AI sample PDF report (OpenAI)',\n      generateGeminiReport: 'POST /api/qeeg/generate-gemini-report - Generate AI report structure using Gemini',\n      supabasePdfs: 'GET /api/qeeg/supabase-pdfs - List all PDFs from Supabase bucket'\n    }\n  });\n});\n\n/**\n * POST /api/qeeg/generate-gemini-report\n * Generate AI-powered report structure using Google Gemini\n */\nrouter.post('/generate-gemini-report', async (req, res) => {\n  try {\n    console.log('\\nü§ñ === Gemini AI Report Generation Started ===\\n');\n\n    if (!GeminiService) {\n      return res.status(503).json({\n        error: true,\n        message: 'Gemini AI service is not available. Please check server configuration.'\n      });\n    }\n\n    const { algorithmResults } = req.body;\n\n    // Validate input\n    if (!algorithmResults || !algorithmResults.parameters) {\n      return res.status(400).json({\n        error: true,\n        message: 'Missing required data: algorithmResults with parameters array is required'\n      });\n    }\n\n    console.log('üìä Processing', algorithmResults.parameters.length, 'brain parameters');\n\n    // Transform algorithm results to the format expected by Gemini\n    const brainParameters = {\n      Cognition: null,\n      Stress: null,\n      FocusAndAttention: null,\n      BurnoutAndFatigue: null,\n      EmotionalRegulation: null,\n      Learning: null,\n      Creativity: null\n    };\n\n    // Map the parameters from algorithm results\n    algorithmResults.parameters.forEach(param => {\n      const paramName = param.name.replace(/\\s+/g, '');\n      if (brainParameters.hasOwnProperty(paramName)) {\n        brainParameters[paramName] = {\n          score: param.score,\n          bucket: param.bucket,\n          subparameters: param.subParameters || []\n        };\n      }\n    });\n\n    console.log('üß† Brain Parameters prepared for Gemini');\n\n    // Generate report using Gemini AI\n    const result = await GeminiService.generateBrainPerformanceReport(brainParameters);\n\n    if (!result.success) {\n      return res.status(500).json({\n        error: true,\n        message: 'Failed to generate report with Gemini AI',\n        details: result.error\n      });\n    }\n\n    console.log('‚úÖ Gemini AI report generated successfully');\n\n    res.json({\n      success: true,\n      message: 'AI-powered report structure generated successfully',\n      reportData: result.data,\n      rawResponse: result.rawResponse\n    });\n\n  } catch (error) {\n    console.error('‚ùå Error generating Gemini report:', error);\n    res.status(500).json({\n      error: true,\n      message: 'Internal server error while generating Gemini report',\n      details: error.message\n    });\n  }\n});\n\nmodule.exports = router;\n\n","numLines":825,"startLine":1,"totalLines":825}}}
{"parentUuid":"263ad256-0ce0-43b6-ac3e-1d5be87abdd8","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01PcQP6MNGkP8ATpVa95h1ML","type":"tool_result","content":"     1‚Üíimport React, { useState, useEffect } from 'react';\n     2‚Üíimport { Upload, Play, Download, FileText, CheckCircle, Activity, User, Building2, Calendar, History, X, ArrowLeft, Search, Filter } from 'lucide-react';\n     3‚Üíimport DatabaseService from '../../services/databaseService';\n     4‚Üíimport toast from 'react-hot-toast';\n     5‚Üí\n     6‚Üíconst AlgorithmDataProcessor = () => {\n     7‚Üí  const [patients, setPatients] = useState([]);\n     8‚Üí  const [clinics, setClinics] = useState([]);\n     9‚Üí  const [selectedPatient, setSelectedPatient] = useState(null);\n    10‚Üí  const [showProcessingUI, setShowProcessingUI] = useState(false);\n    11‚Üí  const [processingHistory, setProcessingHistory] = useState([]);\n    12‚Üí  const [loading, setLoading] = useState(true);\n    13‚Üí\n    14‚Üí  // Filter states\n    15‚Üí  const [searchTerm, setSearchTerm] = useState('');\n    16‚Üí  const [selectedClinicFilter, setSelectedClinicFilter] = useState('');\n    17‚Üí  const [dateFilter, setDateFilter] = useState('');\n    18‚Üí\n    19‚Üí  const [eyesOpenFile, setEyesOpenFile] = useState(null);\n    20‚Üí  const [eyesClosedFile, setEyesClosedFile] = useState(null);\n    21‚Üí  const [isProcessing, setIsProcessing] = useState(false);\n    22‚Üí  const [processingComplete, setProcessingComplete] = useState(false);\n    23‚Üí  const [consoleLog, setConsoleLog] = useState([]);\n    24‚Üí  const [progress, setProgress] = useState(0);\n    25‚Üí  const [results, setResults] = useState(null);\n    26‚Üí  const [isSaved, setIsSaved] = useState(false);\n    27‚Üí  const [isSaving, setIsSaving] = useState(false);\n    28‚Üí  const [pdfUrl, setPdfUrl] = useState(null);\n    29‚Üí\n    30‚Üí  // Debug function to check database contents\n    31‚Üí  useEffect(() => {\n    32‚Üí    window.debugAlgorithmResults = async () => {\n    33‚Üí      const allResults = await DatabaseService.get('algorithmResults');\n    34‚Üí      console.log('üîç All Algorithm Results in Database:', allResults);\n    35‚Üí      console.log(`Total records: ${allResults.length}`);\n    36‚Üí      allResults.forEach((record, idx) => {\n    37‚Üí        console.log(`\\nüìä Record ${idx + 1}:`, {\n    38‚Üí          id: record.id,\n    39‚Üí          patientName: record.patientName,\n    40‚Üí          processedAt: record.processedAt,\n    41‚Üí          pdfUrl: record.pdfUrl || '‚ùå MISSING',\n    42‚Üí          hasResults: !!record.results\n    43‚Üí        });\n    44‚Üí      });\n    45‚Üí    };\n    46‚Üí    console.log('üí° Debug: Type window.debugAlgorithmResults() in console to check database');\n    47‚Üí  }, []);\n    48‚Üí\n    49‚Üí  useEffect(() => {\n    50‚Üí    loadPatients();\n    51‚Üí  }, []);\n    52‚Üí\n    53‚Üí  useEffect(() => {\n    54‚Üí    if (selectedPatient && showProcessingUI) {\n    55‚Üí      loadProcessingHistory(selectedPatient.id);\n    56‚Üí    }\n    57‚Üí  }, [selectedPatient, showProcessingUI, isSaved]); // Re-load when saved\n    58‚Üí\n    59‚Üí  const loadPatients = async () => {\n    60‚Üí    try {\n    61‚Üí      const patientsData = await DatabaseService.get('patients');\n    62‚Üí      const clinicsData = await DatabaseService.get('clinics');\n    63‚Üí      const algorithmResults = await DatabaseService.get('algorithmResults') || [];\n    64‚Üí\n    65‚Üí      // Enrich patients with clinic names and algorithm status\n    66‚Üí      const enrichedPatients = patientsData.map(patient => {\n    67‚Üí        const patientResults = algorithmResults.filter(r => r.patientId === patient.id);\n    68‚Üí        const lastResult = patientResults.length > 0\n    69‚Üí          ? patientResults.sort((a, b) => new Date(b.processedAt) - new Date(a.processedAt))[0]\n    70‚Üí          : null;\n    71‚Üí\n    72‚Üí        return {\n    73‚Üí          ...patient,\n    74‚Üí          clinicName: clinicsData.find(c => c.id === patient.clinicId)?.name || 'Unknown Clinic',\n    75‚Üí          algorithmStatus: lastResult ? 'completed' : 'pending',\n    76‚Üí          lastProcessed: lastResult?.processedAt,\n    77‚Üí          totalScans: patientResults.length\n    78‚Üí        };\n    79‚Üí      });\n    80‚Üí\n    81‚Üí      setPatients(enrichedPatients);\n    82‚Üí      setClinics(clinicsData);\n    83‚Üí      setLoading(false);\n    84‚Üí    } catch (error) {\n    85‚Üí      console.error('Error loading patients:', error);\n    86‚Üí      toast.error('Failed to load patients');\n    87‚Üí      setLoading(false);\n    88‚Üí    }\n    89‚Üí  };\n    90‚Üí\n    91‚Üí  const loadProcessingHistory = async (patientId) => {\n    92‚Üí    try {\n    93‚Üí      // Load algorithm results for this patient\n    94‚Üí      const results = await DatabaseService.get('algorithmResults');\n    95‚Üí      const patientResults = results.filter(r => r.patientId === patientId);\n    96‚Üí\n    97‚Üí      console.log(`üìã Loaded ${patientResults.length} records for patient ${patientId}`);\n    98‚Üí\n    99‚Üí      // Log all records for debugging\n   100‚Üí      console.log('üìä All records for this patient:');\n   101‚Üí      patientResults.forEach((rec, idx) => {\n   102‚Üí        console.log(`   ${idx + 1}. ${new Date(rec.processedAt).toLocaleString()} - PDF: ${rec.pdfUrl ? '‚úì' : '‚úó'}`);\n   103‚Üí      });\n   104‚Üí\n   105‚Üí      // Check for records without pdfUrl and try to fix them\n   106‚Üí      const recordsWithoutPdf = patientResults.filter(r => !r.pdfUrl);\n   107‚Üí      if (recordsWithoutPdf.length > 0) {\n   108‚Üí        console.log(`\\n‚ö†Ô∏è Found ${recordsWithoutPdf.length} records without PDF URL - attempting auto-fix...`);\n   109‚Üí\n   110‚Üí        let updatedCount = 0;\n   111‚Üí\n   112‚Üí        // Step 1: Try to fetch PDFs from Supabase bucket\n   113‚Üí        try {\n   114‚Üí          const apiUrl = import.meta.env.VITE_API_URL || 'http://localhost:3001/api';\n   115‚Üí          const response = await fetch(`${apiUrl}/qeeg/supabase-pdfs`);\n   116‚Üí\n   117‚Üí          if (response.ok) {\n   118‚Üí            const data = await response.json();\n   119‚Üí            console.log(`\\n‚òÅÔ∏è Found ${data.count} PDFs in Supabase bucket:`);\n   120‚Üí            data.pdfs.forEach(pdf => console.log(`   - ${pdf.name}`));\n   121‚Üí\n   122‚Üí            // Match PDFs with database records using smart matching\n   123‚Üí            console.log(`\\nüîç Attempting to match ${recordsWithoutPdf.length} records...`);\n   124‚Üí            for (const record of recordsWithoutPdf) {\n   125‚Üí              const recordTimestamp = new Date(record.processedAt).getTime();\n   126‚Üí              const sanitizedName = record.patientName.replace(/[^a-z0-9]/gi, '_').toLowerCase();\n   127‚Üí\n   128‚Üí              console.log(`\\n   Record: ${record.patientName} @ ${new Date(record.processedAt).toLocaleString()}`);\n   129‚Üí              console.log(`   Searching for PDFs matching: neurosense-report-${sanitizedName}-*.pdf`);\n   130‚Üí\n   131‚Üí              // Find PDFs matching patient name\n   132‚Üí              const matchingPdfs = data.pdfs.filter(pdf => {\n   133‚Üí                const pdfNameLower = pdf.name.toLowerCase();\n   134‚Üí                return pdfNameLower.includes(`neurosense-report-${sanitizedName}-`) &&\n   135‚Üí                       pdfNameLower.endsWith('.pdf');\n   136‚Üí              });\n   137‚Üí\n   138‚Üí              console.log(`   Found ${matchingPdfs.length} PDFs for this patient`);\n   139‚Üí\n   140‚Üí              if (matchingPdfs.length > 0) {\n   141‚Üí                // Find PDF with closest timestamp (within 60 seconds)\n   142‚Üí                let bestMatch = null;\n   143‚Üí                let smallestDiff = Infinity;\n   144‚Üí\n   145‚Üí                for (const pdf of matchingPdfs) {\n   146‚Üí                  // Extract timestamp from filename: neurosense-report-name-TIMESTAMP.pdf\n   147‚Üí                  const match = pdf.name.match(/-(\\d+)\\.pdf$/);\n   148‚Üí                  if (match) {\n   149‚Üí                    const pdfTimestamp = parseInt(match[1]);\n   150‚Üí                    const diff = Math.abs(pdfTimestamp - recordTimestamp);\n   151‚Üí                    console.log(`      ${pdf.name}: timestamp diff = ${diff}ms (${(diff/1000).toFixed(1)}s)`);\n   152‚Üí\n   153‚Üí                    // Accept if within 60 seconds (60000ms)\n   154‚Üí                    if (diff < 60000 && diff < smallestDiff) {\n   155‚Üí                      smallestDiff = diff;\n   156‚Üí                      bestMatch = pdf;\n   157‚Üí                    }\n   158‚Üí                  }\n   159‚Üí                }\n   160‚Üí\n   161‚Üí                if (bestMatch) {\n   162‚Üí                  console.log(`   ‚úÖ MATCH FOUND! ${bestMatch.name} (${(smallestDiff/1000).toFixed(1)}s difference)`);\n   163‚Üí                  console.log(`   URL: ${bestMatch.url}`);\n   164‚Üí                  record.pdfUrl = bestMatch.url;\n   165‚Üí                  await DatabaseService.update('algorithmResults', record.id, record);\n   166‚Üí                  updatedCount++;\n   167‚Üí                } else {\n   168‚Üí                  console.log(`   ‚ö†Ô∏è PDFs found but timestamp difference too large (>60s)`);\n   169‚Üí                }\n   170‚Üí              } else {\n   171‚Üí                console.log(`   ‚ùå No PDFs found for patient: ${sanitizedName}`);\n   172‚Üí              }\n   173‚Üí            }\n   174‚Üí          }\n   175‚Üí        } catch (supabaseErr) {\n   176‚Üí          console.log('‚ö†Ô∏è Could not fetch from Supabase, trying local storage...');\n   177‚Üí        }\n   178‚Üí\n   179‚Üí        // Step 2: If Supabase fails, try local storage\n   180‚Üí        for (const record of recordsWithoutPdf) {\n   181‚Üí          if (record.pdfUrl) continue; // Already updated from Supabase\n   182‚Üí\n   183‚Üí          try {\n   184‚Üí            const timestamp = new Date(record.processedAt).getTime();\n   185‚Üí            const sanitizedName = record.patientName.replace(/[^a-z0-9]/gi, '_').toLowerCase();\n   186‚Üí            const possibleFilename = `neurosense-report-${sanitizedName}-${timestamp}.pdf`;\n   187‚Üí            const apiUrl = import.meta.env.VITE_API_URL || 'http://localhost:3001/api';\n   188‚Üí            const backendBaseUrl = apiUrl.replace('/api', '');\n   189‚Üí            const testUrl = `${backendBaseUrl}/uploads/${possibleFilename}`;\n   190‚Üí\n   191‚Üí            // Test if file exists locally\n   192‚Üí            const response = await fetch(testUrl, { method: 'HEAD' });\n   193‚Üí            if (response.ok) {\n   194‚Üí              console.log(`‚úÖ Found local PDF for record ${record.id}: ${testUrl}`);\n   195‚Üí              record.pdfUrl = `/uploads/${possibleFilename}`;\n   196‚Üí              await DatabaseService.update('algorithmResults', record.id, record);\n   197‚Üí              updatedCount++;\n   198‚Üí            }\n   199‚Üí          } catch (err) {\n   200‚Üí            console.log(`‚ùå Could not find PDF for record ${record.id}`);\n   201‚Üí          }\n   202‚Üí        }\n   203‚Üí\n   204‚Üí        if (updatedCount > 0) {\n   205‚Üí          console.log(`‚úÖ Auto-fixed ${updatedCount} records with PDF URLs`);\n   206‚Üí          // Reload the results after updating\n   207‚Üí          const updatedResults = await DatabaseService.get('algorithmResults');\n   208‚Üí          const updatedPatientResults = updatedResults.filter(r => r.patientId === patientId);\n   209‚Üí          setProcessingHistory(updatedPatientResults);\n   210‚Üí\n   211‚Üí          updatedPatientResults.forEach((record, idx) => {\n   212‚Üí            console.log(`   Record ${idx + 1}:`, {\n   213‚Üí              processedAt: record.processedAt,\n   214‚Üí              hasPdfUrl: !!record.pdfUrl,\n   215‚Üí              pdfUrl: record.pdfUrl || 'NOT SET',\n   216‚Üí              pdfType: record.pdfUrl ? (record.pdfUrl.startsWith('http') ? 'Supabase' : 'Local') : 'None'\n   217‚Üí            });\n   218‚Üí          });\n   219‚Üí          return;\n   220‚Üí        }\n   221‚Üí      }\n   222‚Üí\n   223‚Üí      patientResults.forEach((record, idx) => {\n   224‚Üí        console.log(`   Record ${idx + 1}:`, {\n   225‚Üí          processedAt: record.processedAt,\n   226‚Üí          hasPdfUrl: !!record.pdfUrl,\n   227‚Üí          pdfUrl: record.pdfUrl || 'NOT SET',\n   228‚Üí          pdfType: record.pdfUrl ? (record.pdfUrl.startsWith('http') ? 'Supabase' : 'Local') : 'None'\n   229‚Üí        });\n   230‚Üí      });\n   231‚Üí\n   232‚Üí      setProcessingHistory(patientResults);\n   233‚Üí    } catch (error) {\n   234‚Üí      console.error('Error loading processing history:', error);\n   235‚Üí      setProcessingHistory([]);\n   236‚Üí    }\n   237‚Üí  };\n   238‚Üí\n   239‚Üí  const handleGenerateReport = (patient) => {\n   240‚Üí    setSelectedPatient(patient);\n   241‚Üí    setShowProcessingUI(true);\n   242‚Üí    // Reset upload states\n   243‚Üí    setEyesOpenFile(null);\n   244‚Üí    setEyesClosedFile(null);\n   245‚Üí    setResults(null);\n   246‚Üí    setProcessingComplete(false);\n   247‚Üí    setConsoleLog([]);\n   248‚Üí    setIsSaved(false);\n   249‚Üí    setPdfUrl(null);\n   250‚Üí    setIsSaving(false);\n   251‚Üí  };\n   252‚Üí\n   253‚Üí  const handleBackToList = () => {\n   254‚Üí    setShowProcessingUI(false);\n   255‚Üí    setSelectedPatient(null);\n   256‚Üí    setEyesOpenFile(null);\n   257‚Üí    setEyesClosedFile(null);\n   258‚Üí    setResults(null);\n   259‚Üí    setProcessingComplete(false);\n   260‚Üí    setConsoleLog([]);\n   261‚Üí    setProcessingHistory([]);\n   262‚Üí    setIsSaved(false);\n   263‚Üí    setIsSaving(false);\n   264‚Üí    // Reload patients to update status\n   265‚Üí    loadPatients();\n   266‚Üí  };\n   267‚Üí\n   268‚Üí  // Helper function to get patient name (handles different field names)\n   269‚Üí  const getPatientName = (patient) => {\n   270‚Üí    return patient?.fullName || patient?.full_name || patient?.name || patient?.email || 'Unknown Patient';\n   271‚Üí  };\n   272‚Üí\n   273‚Üí  // Helper function to get status badge\n   274‚Üí  const getStatusBadge = (status, lastProcessed) => {\n   275‚Üí    if (status === 'completed') {\n   276‚Üí      return (\n   277‚Üí        <div className=\"flex flex-col items-start\">\n   278‚Üí          <span className=\"inline-flex items-center px-2.5 py-0.5 rounded-full text-xs font-medium bg-green-100 text-green-800 dark:bg-green-900/30 dark:text-green-400\">\n   279‚Üí            <CheckCircle className=\"h-3 w-3 mr-1\" />\n   280‚Üí            Completed\n   281‚Üí          </span>\n   282‚Üí          {lastProcessed && (\n   283‚Üí            <span className=\"text-xs text-gray-500 dark:text-gray-400 mt-1\">\n   284‚Üí              {new Date(lastProcessed).toLocaleDateString('en-US', { month: 'short', day: 'numeric', year: 'numeric' })}\n   285‚Üí            </span>\n   286‚Üí          )}\n   287‚Üí        </div>\n   288‚Üí      );\n   289‚Üí    }\n   290‚Üí    return (\n   291‚Üí      <span className=\"inline-flex items-center px-2.5 py-0.5 rounded-full text-xs font-medium bg-yellow-100 text-yellow-800 dark:bg-yellow-900/30 dark:text-yellow-400\">\n   292‚Üí        <Activity className=\"h-3 w-3 mr-1\" />\n   293‚Üí        Pending\n   294‚Üí      </span>\n   295‚Üí    );\n   296‚Üí  };\n   297‚Üí\n   298‚Üí  // Filter patients based on search and filters\n   299‚Üí  const filteredPatients = patients.filter(patient => {\n   300‚Üí    const matchesSearch = searchTerm === '' ||\n   301‚Üí      getPatientName(patient).toLowerCase().includes(searchTerm.toLowerCase()) ||\n   302‚Üí      patient.email?.toLowerCase().includes(searchTerm.toLowerCase());\n   303‚Üí\n   304‚Üí    const matchesClinic = selectedClinicFilter === '' || patient.clinicId === selectedClinicFilter;\n   305‚Üí\n   306‚Üí    const matchesDate = dateFilter === '' ||\n   307‚Üí      (patient.lastProcessed && new Date(patient.lastProcessed).toISOString().split('T')[0] === dateFilter);\n   308‚Üí\n   309‚Üí    return matchesSearch && matchesClinic && matchesDate;\n   310‚Üí  });\n   311‚Üí\n   312‚Üí  // Group filtered patients by clinic\n   313‚Üí  const groupedPatients = clinics.map(clinic => ({\n   314‚Üí    clinic,\n   315‚Üí    patients: filteredPatients.filter(p => p.clinicId === clinic.id)\n   316‚Üí  })).filter(group => group.patients.length > 0);\n   317‚Üí\n   318‚Üí  const clearFilters = () => {\n   319‚Üí    setSearchTerm('');\n   320‚Üí    setSelectedClinicFilter('');\n   321‚Üí    setDateFilter('');\n   322‚Üí  };\n   323‚Üí\n   324‚Üí  const handleFileUpload = (type, event) => {\n   325‚Üí    const file = event.target.files[0];\n   326‚Üí    if (file) {\n   327‚Üí      if (type === 'eo') {\n   328‚Üí        setEyesOpenFile(file);\n   329‚Üí      } else {\n   330‚Üí        setEyesClosedFile(file);\n   331‚Üí      }\n   332‚Üí      // Reset processing state when new files are uploaded\n   333‚Üí      setProcessingComplete(false);\n   334‚Üí      setResults(null);\n   335‚Üí      setConsoleLog([]);\n   336‚Üí      setProgress(0);\n   337‚Üí      setIsSaved(false);\n   338‚Üí      setIsSaving(false);\n   339‚Üí      setPdfUrl(null);\n   340‚Üí    }\n   341‚Üí  };\n   342‚Üí\n   343‚Üí  const processQEEGFiles = async () => {\n   344‚Üí    setIsProcessing(true);\n   345‚Üí    setConsoleLog([]);\n   346‚Üí    setProgress(0);\n   347‚Üí\n   348‚Üí    try {\n   349‚Üí      // Console log: Starting process\n   350‚Üí      setConsoleLog(prev => [...prev, 'üöÄ Starting QEEG analysis...']);\n   351‚Üí      setProgress(10);\n   352‚Üí\n   353‚Üí      // Create FormData to send files\n   354‚Üí      const formData = new FormData();\n   355‚Üí      formData.append('eyesOpen', eyesOpenFile);\n   356‚Üí      formData.append('eyesClosed', eyesClosedFile);\n   357‚Üí      formData.append('patientId', selectedPatient.id);\n   358‚Üí      formData.append('patientName', getPatientName(selectedPatient));\n   359‚Üí      formData.append('clinicName', selectedPatient.clinicName);\n   360‚Üí      // Add complete patient data for PDF\n   361‚Üí      formData.append('dateOfBirth', selectedPatient.dateOfBirth || selectedPatient.date_of_birth || 'Not specified');\n   362‚Üí      formData.append('age', selectedPatient.age || calculateAge(selectedPatient.dateOfBirth || selectedPatient.date_of_birth) || 'N/A');\n   363‚Üí      formData.append('gender', selectedPatient.gender || 'Not specified');\n   364‚Üí      formData.append('handedness', selectedPatient.handedness || 'Right');\n   365‚Üí\n   366‚Üí      setConsoleLog(prev => [...prev, 'üì§ Uploading files to server...']);\n   367‚Üí      setProgress(20);\n   368‚Üí\n   369‚Üí      // Call backend API\n   370‚Üí      const apiUrl = import.meta.env.VITE_API_URL || 'http://localhost:3001/api';\n   371‚Üí      const response = await fetch(`${apiUrl}/qeeg/process`, {\n   372‚Üí        method: 'POST',\n   373‚Üí        body: formData\n   374‚Üí      });\n   375‚Üí\n   376‚Üí      setConsoleLog(prev => [...prev, 'üìä Parsing QEEG data tables...']);\n   377‚Üí      setProgress(40);\n   378‚Üí\n   379‚Üí      if (!response.ok) {\n   380‚Üí        const errorData = await response.json();\n   381‚Üí        throw new Error(errorData.message || 'Failed to process QEEG files');\n   382‚Üí      }\n   383‚Üí\n   384‚Üí      const data = await response.json();\n   385‚Üí\n   386‚Üí      // Auto-set PDF URL if returned from backend\n   387‚Üí      if (data.data.pdfUrl) {\n   388‚Üí        setPdfUrl(data.data.pdfUrl);\n   389‚Üí        console.log('‚úÖ PDF auto-generated:', data.data.pdfUrl);\n   390‚Üí        setConsoleLog(prev => [...prev, 'üìÑ PDF report generated automatically']);\n   391‚Üí      }\n   392‚Üí\n   393‚Üí      setConsoleLog(prev => [...prev, 'üßÆ Calculating 7 brain health parameters...']);\n   394‚Üí      setProgress(60);\n   395‚Üí\n   396‚Üí      // Simulate calculation steps for better UX\n   397‚Üí      await new Promise(resolve => setTimeout(resolve, 500));\n   398‚Üí      setConsoleLog(prev => [...prev, '  ‚úì Cognition parameter calculated']);\n   399‚Üí      setProgress(65);\n   400‚Üí\n   401‚Üí      await new Promise(resolve => setTimeout(resolve, 400));\n   402‚Üí      setConsoleLog(prev => [...prev, '  ‚úì Stress parameter calculated']);\n   403‚Üí      setProgress(70);\n   404‚Üí\n   405‚Üí      await new Promise(resolve => setTimeout(resolve, 400));\n   406‚Üí      setConsoleLog(prev => [...prev, '  ‚úì Focus & Attention parameter calculated']);\n   407‚Üí      setProgress(75);\n   408‚Üí\n   409‚Üí      await new Promise(resolve => setTimeout(resolve, 400));\n   410‚Üí      setConsoleLog(prev => [...prev, '  ‚úì Burnout & Fatigue parameter calculated']);\n   411‚Üí      setProgress(80);\n   412‚Üí\n   413‚Üí      await new Promise(resolve => setTimeout(resolve, 400));\n   414‚Üí      setConsoleLog(prev => [...prev, '  ‚úì Emotional Regulation parameter calculated']);\n   415‚Üí      setProgress(85);\n   416‚Üí\n   417‚Üí      await new Promise(resolve => setTimeout(resolve, 400));\n   418‚Üí      setConsoleLog(prev => [...prev, '  ‚úì Learning parameter calculated']);\n   419‚Üí      setProgress(90);\n   420‚Üí\n   421‚Üí      await new Promise(resolve => setTimeout(resolve, 400));\n   422‚Üí      setConsoleLog(prev => [...prev, '  ‚úì Creativity parameter calculated']);\n   423‚Üí      setProgress(95);\n   424‚Üí\n   425‚Üí      // Convert API results to display format\n   426‚Üí      const finalResults = data.data.results.map(param => ({\n   427‚Üí        parameter: param.name,\n   428‚Üí        score: Math.round((param.score / param.maxScore) * 100), // Convert to percentage\n   429‚Üí        rawScore: `${param.score}/${param.maxScore}`,\n   430‚Üí        status: param.classification,\n   431‚Üí        color: param.classification === 'High' ? 'green' :\n   432‚Üí               param.classification === 'Medium' ? 'blue' : 'orange',\n   433‚Üí        metrics: param.metrics\n   434‚Üí      }));\n   435‚Üí\n   436‚Üí      setConsoleLog(prev => [...prev, '‚úÖ Analysis complete!']);\n   437‚Üí      setConsoleLog(prev => [...prev, `üìà Overall Score: ${data.data.overallScore}/${data.data.maxScore}`]);\n   438‚Üí      setProgress(100);\n   439‚Üí\n   440‚Üí      setResults(finalResults);\n   441‚Üí      setIsProcessing(false);\n   442‚Üí      setProcessingComplete(true);\n   443‚Üí      setIsSaved(false); // Mark as not saved yet\n   444‚Üí\n   445‚Üí      toast.success('QEEG analysis completed successfully!');\n   446‚Üí\n   447‚Üí    } catch (error) {\n   448‚Üí      console.error('Error processing QEEG files:', error);\n   449‚Üí      setConsoleLog(prev => [...prev, `‚ùå Error: ${error.message}`]);\n   450‚Üí      setIsProcessing(false);\n   451‚Üí      toast.error(error.message || 'Failed to process QEEG files');\n   452‚Üí    }\n   453‚Üí  };\n   454‚Üí\n   455‚Üí  const saveResultsToDatabase = async (resultData) => {\n   456‚Üí    if (!resultData) {\n   457‚Üí      toast.error('No results to save');\n   458‚Üí      return;\n   459‚Üí    }\n   460‚Üí\n   461‚Üí    try {\n   462‚Üí      setIsSaving(true);\n   463‚Üí      toast.loading('Saving results to database...', { id: 'save-results' });\n   464‚Üí\n   465‚Üí      console.log('üíæ Saving results to database...');\n   466‚Üí\n   467‚Üí      // PDF should already exist from auto-generation\n   468‚Üí      if (!pdfUrl) {\n   469‚Üí        console.warn('‚ö†Ô∏è No PDF URL available - PDF may not have been generated');\n   470‚Üí      }\n   471‚Üí\n   472‚Üí      const algorithmResult = {\n   473‚Üí        id: `alg_${Date.now()}_${selectedPatient.id}`,\n   474‚Üí        patientId: selectedPatient.id,\n   475‚Üí        patientName: getPatientName(selectedPatient),\n   476‚Üí        clinicId: selectedPatient.clinicId,\n   477‚Üí        clinicName: selectedPatient.clinicName,\n   478‚Üí        pdfUrl: pdfUrl || null, // Use existing PDF URL from auto-generation\n   479‚Üí        results: resultData,\n   480‚Üí        eyesOpenFile: eyesOpenFile?.name,\n   481‚Üí        eyesClosedFile: eyesClosedFile?.name,\n   482‚Üí        processedAt: new Date().toISOString(),\n   483‚Üí        processedBy: 'super_admin' // Could be dynamic based on logged-in user\n   484‚Üí      };\n   485‚Üí\n   486‚Üí      console.log('üíæ Saving to database...');\n   487‚Üí      console.log('   Patient:', algorithmResult.patientName);\n   488‚Üí      console.log('   PDF URL:', pdfUrl || 'NOT SET');\n   489‚Üí      console.log('   PDF Type:', pdfUrl ? (pdfUrl.startsWith('http') ? 'Supabase' : 'Local') : 'None');\n   490‚Üí\n   491‚Üí      await DatabaseService.add('algorithmResults', algorithmResult);\n   492‚Üí\n   493‚Üí      setIsSaved(true);\n   494‚Üí      setIsSaving(false);\n   495‚Üí\n   496‚Üí      toast.success('‚úÖ Results saved successfully!', { id: 'save-results' });\n   497‚Üí\n   498‚Üí      // Reload history and patient list to update status\n   499‚Üí      loadProcessingHistory(selectedPatient.id);\n   500‚Üí      loadPatients();\n   501‚Üí    } catch (error) {\n   502‚Üí      console.error('‚ùå Error saving results:', error);\n   503‚Üí      setIsSaving(false);\n   504‚Üí      toast.error('‚ùå Failed to save results: ' + error.message, { id: 'save-results' });\n   505‚Üí    }\n   506‚Üí  };\n   507‚Üí\n   508‚Üí  const handleSaveResults = async () => {\n   509‚Üí    if (results) {\n   510‚Üí      await saveResultsToDatabase(results);\n   511‚Üí      // After saving, automatically download PDF if available\n   512‚Üí      if (pdfUrl) {\n   513‚Üí        setTimeout(() => {\n   514‚Üí          handleDownloadPDF();\n   515‚Üí        }, 500); // Small delay to let save complete\n   516‚Üí      }\n   517‚Üí    }\n   518‚Üí  };\n   519‚Üí\n   520‚Üí  const handleExecuteCalculation = () => {\n   521‚Üí    if (eyesOpenFile && eyesClosedFile) {\n   522‚Üí      processQEEGFiles();\n   523‚Üí    } else {\n   524‚Üí      toast.error('Please upload both QEEG data files');\n   525‚Üí    }\n   526‚Üí  };\n   527‚Üí\n   528‚Üí  const handleExportResults = () => {\n   529‚Üí    if (results) {\n   530‚Üí      // Create CSV content\n   531‚Üí      const csvContent = [\n   532‚Üí        ['Parameter', 'Score (%)', 'Status'],\n   533‚Üí        ...results.map(r => [r.parameter, r.score, r.status])\n   534‚Üí      ].map(row => row.join(',')).join('\\n');\n   535‚Üí\n   536‚Üí      // Create and download file\n   537‚Üí      const blob = new Blob([csvContent], { type: 'text/csv' });\n   538‚Üí      const url = window.URL.createObjectURL(blob);\n   539‚Üí      const a = document.createElement('a');\n   540‚Üí      a.href = url;\n   541‚Üí      a.download = 'neurosense-algorithm-results.csv';\n   542‚Üí      a.click();\n   543‚Üí      window.URL.revokeObjectURL(url);\n   544‚Üí    }\n   545‚Üí  };\n   546‚Üí\n   547‚Üí  const generatePDFReport = async (resultData) => {\n   548‚Üí    if (!resultData || !selectedPatient) {\n   549‚Üí      console.error('‚ùå Cannot generate PDF: Missing resultData or selectedPatient');\n   550‚Üí      toast.error('Cannot generate PDF: Missing data');\n   551‚Üí      return null;\n   552‚Üí    }\n   553‚Üí\n   554‚Üí    try {\n   555‚Üí      console.log('üîß Preparing patient data...');\n   556‚Üí\n   557‚Üí      // Prepare patient data - FIXED: Use current date for recording, not DOB\n   558‚Üí      const patientData = {\n   559‚Üí        name: getPatientName(selectedPatient),\n   560‚Üí        dateOfRecording: new Date().toISOString().split('T')[0], // TODAY'S DATE, not DOB!\n   561‚Üí        dateOfBirth: selectedPatient.dateOfBirth || selectedPatient.date_of_birth || 'Not specified',\n   562‚Üí        age: selectedPatient.age || calculateAge(selectedPatient.dateOfBirth || selectedPatient.date_of_birth) || 'N/A',\n   563‚Üí        gender: selectedPatient.gender || 'Not specified',\n   564‚Üí        handedness: selectedPatient.handedness || 'Right', // Default to Right if not specified\n   565‚Üí        patientId: selectedPatient.id,\n   566‚Üí        occupation: selectedPatient.occupation || 'Not specified',\n   567‚Üí        symptoms: selectedPatient.symptoms || []\n   568‚Üí      };\n   569‚Üí\n   570‚Üí      console.log('üë§ Patient Data (Fixed):', patientData);\n   571‚Üí      console.log('   Name:', patientData.name);\n   572‚Üí      console.log('   Recording Date:', patientData.dateOfRecording);\n   573‚Üí      console.log('   DOB:', patientData.dateOfBirth);\n   574‚Üí      console.log('   Age:', patientData.age);\n   575‚Üí      console.log('   Gender:', patientData.gender);\n   576‚Üí      console.log('   Handedness:', patientData.handedness);\n   577‚Üí\n   578‚Üí      // Prepare algorithm results\n   579‚Üí      const algorithmResults = {\n   580‚Üí        parameters: resultData.map(result => ({\n   581‚Üí          name: result.parameter,\n   582‚Üí          score: parseInt(result.rawScore.split('/')[0]),\n   583‚Üí          maxScore: parseInt(result.rawScore.split('/')[1]),\n   584‚Üí          classification: result.status,\n   585‚Üí          metrics: result.metrics || []\n   586‚Üí        })),\n   587‚Üí        overallScore: resultData.reduce((sum, r) => sum + parseInt(r.rawScore.split('/')[0]), 0)\n   588‚Üí      };\n   589‚Üí\n   590‚Üí      console.log('üìä Algorithm Results:', algorithmResults);\n   591‚Üí\n   592‚Üí      // Prepare QEEG data (use sample data if not available)\n   593‚Üí      const qeegData = {\n   594‚Üí        EC: {\n   595‚Üí          absolute: { Fz: { Delta: 5.2, Theta: 4.1, Alpha: 8.3, Beta: 6.2, HiBeta: 3.1 } },\n   596‚Üí          relative: { Pz: { Alpha: 45.2 } },\n   597‚Üí          special: { alphaPeak: 10.3, O1: 10.1 }\n   598‚Üí        },\n   599‚Üí        EO: {\n   600‚Üí          absolute: { Fz: { Theta: 3.8, Beta: 3.2, HiBeta: 2.5 } },\n   601‚Üí          relative: { Pz: { Alpha: 28.7 } }\n   602‚Üí        }\n   603‚Üí      };\n   604‚Üí\n   605‚Üí      // Call backend API to generate PDF\n   606‚Üí      const apiUrl = import.meta.env.VITE_API_URL || 'http://localhost:3001/api';\n   607‚Üí      const pdfEndpoint = `${apiUrl}/qeeg/generate-pdf`;\n   608‚Üí\n   609‚Üí      console.log('üåê Calling backend API:', pdfEndpoint);\n   610‚Üí      console.log('üì° Request payload size:', JSON.stringify({ patientData, algorithmResults, qeegData }).length, 'bytes');\n   611‚Üí\n   612‚Üí      // Add timeout handling\n   613‚Üí      const controller = new AbortController();\n   614‚Üí      const timeoutId = setTimeout(() => controller.abort(), 30000); // 30 second timeout\n   615‚Üí\n   616‚Üí      const response = await fetch(pdfEndpoint, {\n   617‚Üí        method: 'POST',\n   618‚Üí        headers: {\n   619‚Üí          'Content-Type': 'application/json',\n   620‚Üí        },\n   621‚Üí        body: JSON.stringify({\n   622‚Üí          patientData,\n   623‚Üí          algorithmResults,\n   624‚Üí          qeegData\n   625‚Üí        }),\n   626‚Üí        signal: controller.signal\n   627‚Üí      }).catch(error => {\n   628‚Üí        clearTimeout(timeoutId);\n   629‚Üí        if (error.name === 'AbortError') {\n   630‚Üí          throw new Error('PDF generation timed out after 30 seconds. Server might be slow or not responding.');\n   631‚Üí        }\n   632‚Üí        throw error;\n   633‚Üí      });\n   634‚Üí\n   635‚Üí      clearTimeout(timeoutId);\n   636‚Üí\n   637‚Üí      console.log('üì° Backend response status:', response.status);\n   638‚Üí      console.log('üì° Backend response headers:', Object.fromEntries(response.headers.entries()));\n   639‚Üí\n   640‚Üí      if (!response.ok) {\n   641‚Üí        let errorMessage = `Server returned ${response.status}`;\n   642‚Üí        try {\n   643‚Üí          const errorData = await response.json();\n   644‚Üí          errorMessage = errorData.message || errorMessage;\n   645‚Üí          console.error('‚ùå Backend error data:', errorData);\n   646‚Üí        } catch (e) {\n   647‚Üí          const errorText = await response.text();\n   648‚Üí          errorMessage = errorText || errorMessage;\n   649‚Üí          console.error('‚ùå Backend error text:', errorText);\n   650‚Üí        }\n   651‚Üí        throw new Error(`Failed to generate PDF: ${errorMessage}`);\n   652‚Üí      }\n   653‚Üí\n   654‚Üí      const data = await response.json();\n   655‚Üí      console.log('üì¶ Backend response data:', data);\n   656‚Üí\n   657‚Üí      if (!data || !data.success || !data.data) {\n   658‚Üí        console.error('‚ùå Invalid response format:', data);\n   659‚Üí        throw new Error('Invalid response from server');\n   660‚Üí      }\n   661‚Üí\n   662‚Üí      // Use the complete URL from backend instead of constructing it\n   663‚Üí      const pdfResult = {\n   664‚Üí        url: data.data.url, // Backend already provides complete URL\n   665‚Üí        path: data.data.path,\n   666‚Üí        filename: data.data.filename\n   667‚Üí      };\n   668‚Üí\n   669‚Üí      console.log('‚úÖ PDF generated successfully!', pdfResult);\n   670‚Üí      console.log('‚úÖ PDF URL:', pdfResult.url);\n   671‚Üí\n   672‚Üí      return pdfResult;\n   673‚Üí\n   674‚Üí    } catch (error) {\n   675‚Üí      console.error('‚ùå Error generating PDF:', error);\n   676‚Üí      console.error('‚ùå Error name:', error.name);\n   677‚Üí      console.error('‚ùå Error message:', error.message);\n   678‚Üí\n   679‚Üí      if (error.message && error.stack) {\n   680‚Üí        console.error('‚ùå Error stack:', error.stack);\n   681‚Üí      }\n   682‚Üí\n   683‚Üí      // Provide specific error messages based on error type\n   684‚Üí      if (error.name === 'TypeError' && error.message.includes('Failed to fetch')) {\n   685‚Üí        console.error('‚ùå NETWORK ERROR: Cannot connect to backend server');\n   686‚Üí        console.error('‚ùå Please ensure backend server is running on http://localhost:3001');\n   687‚Üí        toast.error('Cannot connect to server. Please ensure backend is running on port 3001.');\n   688‚Üí      } else if (error.name === 'AbortError') {\n   689‚Üí        console.error('‚ùå TIMEOUT ERROR: PDF generation took too long');\n   690‚Üí        toast.error('PDF generation timed out. Server might be overloaded.');\n   691‚Üí      } else {\n   692‚Üí        console.error('‚ùå PDF GENERATION ERROR:', error.message);\n   693‚Üí        toast.error(`PDF generation failed: ${error.message}`);\n   694‚Üí      }\n   695‚Üí\n   696‚Üí      return null;\n   697‚Üí    }\n   698‚Üí  };\n   699‚Üí\n   700‚Üí  const handleDownloadPDF = async () => {\n   701‚Üí    if (!pdfUrl) {\n   702‚Üí      toast.error('PDF not available. Please save results first.');\n   703‚Üí      return;\n   704‚Üí    }\n   705‚Üí\n   706‚Üí    try {\n   707‚Üí      toast.loading('Downloading PDF...', { id: 'download-pdf' });\n   708‚Üí\n   709‚Üí      // Construct full backend URL\n   710‚Üí      const apiUrl = import.meta.env.VITE_API_URL || 'http://localhost:3001/api';\n   711‚Üí      const backendBaseUrl = apiUrl.replace('/api', ''); // Remove /api to get base URL\n   712‚Üí\n   713‚Üí      // Handle both Supabase URLs and local URLs\n   714‚Üí      let fullPdfUrl;\n   715‚Üí      if (pdfUrl.startsWith('http')) {\n   716‚Üí        // It's already a full URL (Supabase)\n   717‚Üí        fullPdfUrl = pdfUrl;\n   718‚Üí      } else {\n   719‚Üí        // It's a local path, construct full URL\n   720‚Üí        fullPdfUrl = `${backendBaseUrl}${pdfUrl}`;\n   721‚Üí      }\n   722‚Üí\n   723‚Üí      console.log('üîΩ Download Info:', {\n   724‚Üí        originalPdfUrl: pdfUrl,\n   725‚Üí        backendBaseUrl,\n   726‚Üí        fullPdfUrl,\n   727‚Üí        isSupabase: pdfUrl.startsWith('http')\n   728‚Üí      });\n   729‚Üí\n   730‚Üí      // For local files, try direct window.open first (simpler approach)\n   731‚Üí      if (!pdfUrl.startsWith('http')) {\n   732‚Üí        console.log('üì• Using direct download method for local file');\n   733‚Üí\n   734‚Üí        // Create a hidden link and click it\n   735‚Üí        const link = document.createElement('a');\n   736‚Üí        link.href = fullPdfUrl;\n   737‚Üí        link.download = pdfUrl.split('/').pop() || 'neurosense-report.pdf';\n   738‚Üí        link.target = '_blank';\n   739‚Üí\n   740‚Üí        document.body.appendChild(link);\n   741‚Üí        link.click();\n   742‚Üí        document.body.removeChild(link);\n   743‚Üí\n   744‚Üí        toast.success('PDF download started!', { id: 'download-pdf' });\n   745‚Üí        return;\n   746‚Üí      }\n   747‚Üí\n   748‚Üí      // For Supabase URLs, use fetch method\n   749‚Üí      console.log('üì• Using fetch method for Supabase URL');\n   750‚Üí\n   751‚Üí      const response = await fetch(fullPdfUrl);\n   752‚Üí\n   753‚Üí      if (!response.ok) {\n   754‚Üí        console.error('‚ùå Download failed:', {\n   755‚Üí          status: response.status,\n   756‚Üí          statusText: response.statusText\n   757‚Üí        });\n   758‚Üí        throw new Error(`Server returned ${response.status}: ${response.statusText}`);\n   759‚Üí      }\n   760‚Üí\n   761‚Üí      // Convert to blob\n   762‚Üí      const blob = await response.blob();\n   763‚Üí\n   764‚Üí      // Verify blob is valid\n   765‚Üí      if (!blob || blob.size === 0) {\n   766‚Üí        throw new Error('Downloaded file is empty');\n   767‚Üí      }\n   768‚Üí\n   769‚Üí      console.log('‚úÖ PDF fetched successfully, size:', (blob.size / 1024).toFixed(2), 'KB');\n   770‚Üí\n   771‚Üí      // Create download link\n   772‚Üí      const downloadUrl = window.URL.createObjectURL(blob);\n   773‚Üí      const link = document.createElement('a');\n   774‚Üí      link.href = downloadUrl;\n   775‚Üí      link.download = pdfUrl.split('/').pop() || 'neurosense-report.pdf';\n   776‚Üí\n   777‚Üí      // Trigger download\n   778‚Üí      document.body.appendChild(link);\n   779‚Üí      link.click();\n   780‚Üí\n   781‚Üí      // Cleanup\n   782‚Üí      setTimeout(() => {\n   783‚Üí        document.body.removeChild(link);\n   784‚Üí        window.URL.revokeObjectURL(downloadUrl);\n   785‚Üí      }, 100);\n   786‚Üí\n   787‚Üí      toast.success('PDF downloaded successfully!', { id: 'download-pdf' });\n   788‚Üí\n   789‚Üí    } catch (error) {\n   790‚Üí      console.error('‚ùå Download error:', {\n   791‚Üí        error: error.message,\n   792‚Üí        pdfUrl,\n   793‚Üí        stack: error.stack\n   794‚Üí      });\n   795‚Üí\n   796‚Üí      // Provide more helpful error messages\n   797‚Üí      let errorMessage = 'Failed to download PDF';\n   798‚Üí      if (error.message.includes('404')) {\n   799‚Üí        errorMessage = 'PDF file not found on server';\n   800‚Üí      } else if (error.message.includes('Failed to fetch')) {\n   801‚Üí        errorMessage = 'Network error. Please check your connection.';\n   802‚Üí      } else {\n   803‚Üí        errorMessage = `Download failed: ${error.message}`;\n   804‚Üí      }\n   805‚Üí\n   806‚Üí      toast.error(errorMessage, { id: 'download-pdf' });\n   807‚Üí    }\n   808‚Üí  };\n   809‚Üí\n   810‚Üí  const calculateAge = (dateOfBirth) => {\n   811‚Üí    if (!dateOfBirth) return 'N/A';\n   812‚Üí    const today = new Date();\n   813‚Üí    const birthDate = new Date(dateOfBirth);\n   814‚Üí    let age = today.getFullYear() - birthDate.getFullYear();\n   815‚Üí    const monthDiff = today.getMonth() - birthDate.getMonth();\n   816‚Üí    if (monthDiff < 0 || (monthDiff === 0 && today.getDate() < birthDate.getDate())) {\n   817‚Üí      age--;\n   818‚Üí    }\n   819‚Üí    return age;\n   820‚Üí  };\n   821‚Üí\n   822‚Üí  // Helper function to get color based on score\n   823‚Üí  // 1/3 = Red, 2/3 = Yellow, 3/3 = Green\n   824‚Üí  const getScoreColor = (rawScore) => {\n   825‚Üí    if (!rawScore) return 'gray';\n   826‚Üí\n   827‚Üí    const [score, maxScore] = rawScore.split('/').map(Number);\n   828‚Üí\n   829‚Üí    if (score === 1) return 'red';      // 1/3\n   830‚Üí    if (score === 2) return 'yellow';   // 2/3\n   831‚Üí    if (score === 3) return 'green';    // 3/3\n   832‚Üí\n   833‚Üí    return 'gray';\n   834‚Üí  };\n   835‚Üí\n   836‚Üí  const getStatusColor = (rawScore) => {\n   837‚Üí    const color = getScoreColor(rawScore);\n   838‚Üí    switch (color) {\n   839‚Üí      case 'red': return 'text-red-500';\n   840‚Üí      case 'yellow': return 'text-yellow-500';\n   841‚Üí      case 'green': return 'text-green-500';\n   842‚Üí      default: return 'text-gray-500';\n   843‚Üí    }\n   844‚Üí  };\n   845‚Üí\n   846‚Üí  const getStatusBgColor = (rawScore) => {\n   847‚Üí    const color = getScoreColor(rawScore);\n   848‚Üí    if (color === 'green') return 'bg-green-100 text-green-800 dark:bg-green-900/30 dark:text-green-400';\n   849‚Üí    if (color === 'yellow') return 'bg-yellow-100 text-yellow-800 dark:bg-yellow-900/30 dark:text-yellow-400';\n   850‚Üí    if (color === 'red') return 'bg-red-100 text-red-800 dark:bg-red-900/30 dark:text-red-400';\n   851‚Üí    return 'bg-gray-100 text-gray-800 dark:bg-gray-900/30 dark:text-gray-400';\n   852‚Üí  };\n   853‚Üí\n   854‚Üí  const getProgressBarColor = (rawScore) => {\n   855‚Üí    const color = getScoreColor(rawScore);\n   856‚Üí    switch (color) {\n   857‚Üí      case 'red': return 'bg-red-500';\n   858‚Üí      case 'yellow': return 'bg-yellow-500';\n   859‚Üí      case 'green': return 'bg-green-500';\n   860‚Üí      default: return 'bg-gray-500';\n   861‚Üí    }\n   862‚Üí  };\n   863‚Üí\n   864‚Üí  if (loading) {\n   865‚Üí    return (\n   866‚Üí      <div className=\"flex items-center justify-center h-64\">\n   867‚Üí        <div className=\"text-center\">\n   868‚Üí          <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary mx-auto\"></div>\n   869‚Üí          <p className=\"mt-4 text-gray-600 dark:text-gray-400\">Loading patients...</p>\n   870‚Üí        </div>\n   871‚Üí      </div>\n   872‚Üí    );\n   873‚Üí  }\n   874‚Üí\n   875‚Üí  // Patient List View\n   876‚Üí  if (!showProcessingUI) {\n   877‚Üí    return (\n   878‚Üí      <div className=\"space-y-6\">\n   879‚Üí        {/* Header */}\n   880‚Üí        <div className=\"bg-gradient-to-r from-primary to-navy-700 rounded-lg p-6 text-white shadow-lg\">\n   881‚Üí          <h1 className=\"text-2xl font-bold\">NeuroSense - Algorithm 1 Data Processor</h1>\n   882‚Üí          <p className=\"text-primary-light mt-2\">Select a patient to generate Algorithm 1 report</p>\n   883‚Üí        </div>\n   884‚Üí\n   885‚Üí        {/* Filter Bar */}\n   886‚Üí        <div className=\"bg-white dark:bg-gray-800 rounded-lg shadow-sm border border-gray-200 dark:border-gray-700 p-4\">\n   887‚Üí          <div className=\"flex flex-col lg:flex-row gap-4\">\n   888‚Üí            {/* Patient Search */}\n   889‚Üí            <div className=\"flex-1\">\n   890‚Üí              <label className=\"block text-xs font-medium text-gray-700 dark:text-gray-300 mb-1\">\n   891‚Üí                Search Patient\n   892‚Üí              </label>\n   893‚Üí              <div className=\"relative\">\n   894‚Üí                <Search className=\"absolute left-3 top-1/2 transform -translate-y-1/2 h-4 w-4 text-gray-400 dark:text-gray-500\" />\n   895‚Üí                <input\n   896‚Üí                  type=\"text\"\n   897‚Üí                  placeholder=\"Search by name or email...\"\n   898‚Üí                  value={searchTerm}\n   899‚Üí                  onChange={(e) => setSearchTerm(e.target.value)}\n   900‚Üí                  className=\"w-full pl-10 pr-4 py-2 border border-gray-300 dark:border-gray-600 rounded-lg bg-white dark:bg-gray-700 text-gray-900 dark:text-white text-sm focus:outline-none focus:ring-2 focus:ring-primary\"\n   901‚Üí                />\n   902‚Üí              </div>\n   903‚Üí            </div>\n   904‚Üí\n   905‚Üí            {/* Clinic Filter */}\n   906‚Üí            <div className=\"flex-1\">\n   907‚Üí              <label className=\"block text-xs font-medium text-gray-700 dark:text-gray-300 mb-1\">\n   908‚Üí                Filter by Clinic\n   909‚Üí              </label>\n   910‚Üí              <div className=\"relative\">\n   911‚Üí                <Building2 className=\"absolute left-3 top-1/2 transform -translate-y-1/2 h-4 w-4 text-gray-400 dark:text-gray-500\" />\n   912‚Üí                <select\n   913‚Üí                  value={selectedClinicFilter}\n   914‚Üí                  onChange={(e) => setSelectedClinicFilter(e.target.value)}\n   915‚Üí                  className=\"w-full pl-10 pr-4 py-2 border border-gray-300 dark:border-gray-600 rounded-lg bg-white dark:bg-gray-700 text-gray-900 dark:text-white text-sm focus:outline-none focus:ring-2 focus:ring-primary appearance-none\"\n   916‚Üí                >\n   917‚Üí                  <option value=\"\">All Clinics</option>\n   918‚Üí                  {clinics.map(clinic => (\n   919‚Üí                    <option key={clinic.id} value={clinic.id}>\n   920‚Üí                      {clinic.name}\n   921‚Üí                    </option>\n   922‚Üí                  ))}\n   923‚Üí                </select>\n   924‚Üí              </div>\n   925‚Üí            </div>\n   926‚Üí\n   927‚Üí            {/* Date Filter */}\n   928‚Üí            <div className=\"flex-1\">\n   929‚Üí              <label className=\"block text-xs font-medium text-gray-700 dark:text-gray-300 mb-1\">\n   930‚Üí                Filter by Date\n   931‚Üí              </label>\n   932‚Üí              <div className=\"relative\">\n   933‚Üí                <Calendar className=\"absolute left-3 top-1/2 transform -translate-y-1/2 h-4 w-4 text-gray-400 dark:text-gray-500\" />\n   934‚Üí                <input\n   935‚Üí                  type=\"date\"\n   936‚Üí                  value={dateFilter}\n   937‚Üí                  onChange={(e) => setDateFilter(e.target.value)}\n   938‚Üí                  className=\"w-full pl-10 pr-4 py-2 border border-gray-300 dark:border-gray-600 rounded-lg bg-white dark:bg-gray-700 text-gray-900 dark:text-white text-sm focus:outline-none focus:ring-2 focus:ring-primary\"\n   939‚Üí                />\n   940‚Üí              </div>\n   941‚Üí            </div>\n   942‚Üí\n   943‚Üí            {/* Clear Filters Button */}\n   944‚Üí            {(searchTerm || selectedClinicFilter || dateFilter) && (\n   945‚Üí              <div className=\"flex items-end\">\n   946‚Üí                <button\n   947‚Üí                  onClick={clearFilters}\n   948‚Üí                  className=\"px-4 py-2 bg-gray-100 hover:bg-gray-200 dark:bg-gray-700 dark:hover:bg-gray-600 text-gray-700 dark:text-gray-300 rounded-lg text-sm font-medium transition-colors flex items-center space-x-2\"\n   949‚Üí                >\n   950‚Üí                  <X className=\"h-4 w-4\" />\n   951‚Üí                  <span>Clear</span>\n   952‚Üí                </button>\n   953‚Üí              </div>\n   954‚Üí            )}\n   955‚Üí          </div>\n   956‚Üí\n   957‚Üí          {/* Active Filters Display */}\n   958‚Üí          {(searchTerm || selectedClinicFilter || dateFilter) && (\n   959‚Üí            <div className=\"mt-3 flex flex-wrap gap-2\">\n   960‚Üí              {searchTerm && (\n   961‚Üí                <span className=\"inline-flex items-center px-3 py-1 rounded-full text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900/30 dark:text-blue-400\">\n   962‚Üí                  Search: \"{searchTerm}\"\n   963‚Üí                </span>\n   964‚Üí              )}\n   965‚Üí              {selectedClinicFilter && (\n   966‚Üí                <span className=\"inline-flex items-center px-3 py-1 rounded-full text-xs font-medium bg-purple-100 text-purple-800 dark:bg-purple-900/30 dark:text-purple-400\">\n   967‚Üí                  Clinic: {clinics.find(c => c.id === selectedClinicFilter)?.name}\n   968‚Üí                </span>\n   969‚Üí              )}\n   970‚Üí              {dateFilter && (\n   971‚Üí                <span className=\"inline-flex items-center px-3 py-1 rounded-full text-xs font-medium bg-green-100 text-green-800 dark:bg-green-900/30 dark:text-green-400\">\n   972‚Üí                  Date: {new Date(dateFilter).toLocaleDateString('en-US', { month: 'short', day: 'numeric', year: 'numeric' })}\n   973‚Üí                </span>\n   974‚Üí              )}\n   975‚Üí              <span className=\"text-xs text-gray-500 dark:text-gray-400 self-center\">\n   976‚Üí                ({filteredPatients.length} {filteredPatients.length === 1 ? 'patient' : 'patients'} found)\n   977‚Üí              </span>\n   978‚Üí            </div>\n   979‚Üí          )}\n   980‚Üí        </div>\n   981‚Üí\n   982‚Üí        {/* Patient List - Clinic-wise */}\n   983‚Üí        <div className=\"space-y-4\">\n   984‚Üí          {groupedPatients.length > 0 ? (\n   985‚Üí            groupedPatients.map(({ clinic, patients: clinicPatients }) => (\n   986‚Üí            <div key={clinic.id} className=\"bg-white dark:bg-gray-800 rounded-lg shadow-sm border border-gray-200 dark:border-gray-700\">\n   987‚Üí              {/* Clinic Header */}\n   988‚Üí              <div className=\"bg-accent-light dark:bg-primary/20 border-b border-primary-light dark:border-primary px-6 py-3\">\n   989‚Üí                <div className=\"flex items-center\">\n   990‚Üí                  <Building2 className=\"h-5 w-5 text-primary mr-2\" />\n   991‚Üí                  <h3 className=\"text-lg font-semibold text-gray-900 dark:text-white\">\n   992‚Üí                    {clinic.name}\n   993‚Üí                  </h3>\n   994‚Üí                  <span className=\"ml-3 text-sm text-gray-600 dark:text-gray-400\">\n   995‚Üí                    ({clinicPatients.length} {clinicPatients.length === 1 ? 'patient' : 'patients'})\n   996‚Üí                  </span>\n   997‚Üí                </div>\n   998‚Üí              </div>\n   999‚Üí\n  1000‚Üí              {/* Patient Table */}\n  1001‚Üí              <div className=\"overflow-x-auto\">\n  1002‚Üí                <table className=\"w-full\">\n  1003‚Üí                  <thead className=\"bg-gray-50 dark:bg-gray-700\">\n  1004‚Üí                    <tr>\n  1005‚Üí                      <th className=\"px-6 py-3 text-left text-xs font-medium text-gray-500 dark:text-gray-300 uppercase tracking-wider\">\n  1006‚Üí                        Patient Name\n  1007‚Üí                      </th>\n  1008‚Üí                      <th className=\"px-6 py-3 text-left text-xs font-medium text-gray-500 dark:text-gray-300 uppercase tracking-wider\">\n  1009‚Üí                        Email\n  1010‚Üí                      </th>\n  1011‚Üí                      <th className=\"px-6 py-3 text-left text-xs font-medium text-gray-500 dark:text-gray-300 uppercase tracking-wider\">\n  1012‚Üí                        Previous Scans\n  1013‚Üí                      </th>\n  1014‚Üí                      <th className=\"px-6 py-3 text-left text-xs font-medium text-gray-500 dark:text-gray-300 uppercase tracking-wider\">\n  1015‚Üí                        Status\n  1016‚Üí                      </th>\n  1017‚Üí                      <th className=\"px-6 py-3 text-right text-xs font-medium text-gray-500 dark:text-gray-300 uppercase tracking-wider\">\n  1018‚Üí                        Action\n  1019‚Üí                      </th>\n  1020‚Üí                    </tr>\n  1021‚Üí                  </thead>\n  1022‚Üí                  <tbody className=\"divide-y divide-gray-200 dark:divide-gray-700\">\n  1023‚Üí                    {clinicPatients.map(patient => (\n  1024‚Üí                      <tr key={patient.id} className=\"hover:bg-gray-50 dark:hover:bg-gray-700/50\">\n  1025‚Üí                        <td className=\"px-6 py-4 whitespace-nowrap\">\n  1026‚Üí                          <div className=\"flex items-center\">\n  1027‚Üí                            <User className=\"h-4 w-4 text-gray-400 dark:text-gray-500 mr-2\" />\n  1028‚Üí                            <span className=\"text-sm font-medium text-gray-900 dark:text-white\">\n  1029‚Üí                              {getPatientName(patient)}\n  1030‚Üí                            </span>\n  1031‚Üí                          </div>\n  1032‚Üí                        </td>\n  1033‚Üí                        <td className=\"px-6 py-4 whitespace-nowrap text-sm text-gray-600 dark:text-gray-400\">\n  1034‚Üí                          {patient.email || 'N/A'}\n  1035‚Üí                        </td>\n  1036‚Üí                        <td className=\"px-6 py-4 whitespace-nowrap text-sm text-gray-600 dark:text-gray-400\">\n  1037‚Üí                          <span className=\"flex items-center\">\n  1038‚Üí                            <History className=\"h-4 w-4 mr-1\" />\n  1039‚Üí                            {patient.totalScans || 0} {patient.totalScans === 1 ? 'scan' : 'scans'}\n  1040‚Üí                          </span>\n  1041‚Üí                        </td>\n  1042‚Üí                        <td className=\"px-6 py-4 whitespace-nowrap\">\n  1043‚Üí                          {getStatusBadge(patient.algorithmStatus, patient.lastProcessed)}\n  1044‚Üí                        </td>\n  1045‚Üí                        <td className=\"px-6 py-4 whitespace-nowrap text-right\">\n  1046‚Üí                          <button\n  1047‚Üí                            onClick={() => handleGenerateReport(patient)}\n  1048‚Üí                            className=\"bg-primary hover:bg-navy-700 text-white px-4 py-2 rounded-lg text-sm font-medium transition-colors shadow-md flex items-center ml-auto\"\n  1049‚Üí                          >\n  1050‚Üí                            <FileText className=\"h-4 w-4 mr-2\" />\n  1051‚Üí                            {patient.algorithmStatus === 'completed' ? 'View/Generate' : 'Generate Report'}\n  1052‚Üí                          </button>\n  1053‚Üí                        </td>\n  1054‚Üí                      </tr>\n  1055‚Üí                    ))}\n  1056‚Üí                  </tbody>\n  1057‚Üí                </table>\n  1058‚Üí              </div>\n  1059‚Üí            </div>\n  1060‚Üí            ))\n  1061‚Üí          ) : (\n  1062‚Üí            <div className=\"bg-white dark:bg-gray-800 rounded-lg shadow-sm border border-gray-200 dark:border-gray-700 p-12 text-center\">\n  1063‚Üí              <Filter className=\"h-16 w-16 text-gray-400 dark:text-gray-500 mx-auto mb-4\" />\n  1064‚Üí              <p className=\"text-gray-600 dark:text-gray-400 font-medium\">\n  1065‚Üí                {searchTerm || selectedClinicFilter || dateFilter\n  1066‚Üí                  ? 'No patients match your filters'\n  1067‚Üí                  : 'No patients found'\n  1068‚Üí                }\n  1069‚Üí              </p>\n  1070‚Üí              <p className=\"text-sm text-gray-500 dark:text-gray-500 mt-2\">\n  1071‚Üí                {searchTerm || selectedClinicFilter || dateFilter\n  1072‚Üí                  ? 'Try adjusting your search criteria or clear filters'\n  1073‚Üí                  : 'Patients will appear here once they are registered in the system'\n  1074‚Üí                }\n  1075‚Üí              </p>\n  1076‚Üí              {(searchTerm || selectedClinicFilter || dateFilter) && (\n  1077‚Üí                <button\n  1078‚Üí                  onClick={clearFilters}\n  1079‚Üí                  className=\"mt-4 px-4 py-2 bg-primary hover:bg-navy-700 text-white rounded-lg text-sm font-medium transition-colors\"\n  1080‚Üí                >\n  1081‚Üí                  Clear Filters\n  1082‚Üí                </button>\n  1083‚Üí              )}\n  1084‚Üí            </div>\n  1085‚Üí          )}\n  1086‚Üí        </div>\n  1087‚Üí      </div>\n  1088‚Üí    );\n  1089‚Üí  }\n  1090‚Üí\n  1091‚Üí  // Processing UI View\n  1092‚Üí  return (\n  1093‚Üí    <div className=\"space-y-6\">\n  1094‚Üí      {/* Header with Back Button */}\n  1095‚Üí      <div className=\"bg-gradient-to-r from-primary to-navy-700 rounded-lg p-6 text-white shadow-lg\">\n  1096‚Üí        <button\n  1097‚Üí          onClick={handleBackToList}\n  1098‚Üí          className=\"flex items-center text-primary-light hover:text-white mb-3 transition-colors\"\n  1099‚Üí        >\n  1100‚Üí          <ArrowLeft className=\"h-5 w-5 mr-2\" />\n  1101‚Üí          Back to Patient List\n  1102‚Üí        </button>\n  1103‚Üí        <h1 className=\"text-2xl font-bold\">NeuroSense - Algorithm 1 Data Processor</h1>\n  1104‚Üí        <p className=\"text-primary-light mt-2\">\n  1105‚Üí          Processing for: <span className=\"font-semibold\">{getPatientName(selectedPatient)}</span> | {selectedPatient?.clinicName}\n  1106‚Üí        </p>\n  1107‚Üí      </div>\n  1108‚Üí\n  1109‚Üí      {/* Main Content Grid */}\n  1110‚Üí      <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-6\">\n  1111‚Üí        {/* Left Panel - QEEG Data Input */}\n  1112‚Üí        <div className=\"bg-white dark:bg-gray-800 rounded-lg shadow-sm border border-gray-200 dark:border-gray-700 p-6\">\n  1113‚Üí          <h2 className=\"text-lg font-semibold text-gray-900 dark:text-white mb-4\">\n  1114‚Üí            QEEG Data Input (Pages 13 & 24)\n  1115‚Üí          </h2>\n  1116‚Üí\n  1117‚Üí          {/* Eyes Open Upload */}\n  1118‚Üí          <div className=\"mb-6\">\n  1119‚Üí            <label className=\"block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2\">\n  1120‚Üí              Page 13 (EO - Eyes Open)\n  1121‚Üí            </label>\n  1122‚Üí            <div className=\"relative border-2 border-dashed border-gray-300 dark:border-gray-600 rounded-lg p-6 text-center hover:border-primary dark:hover:border-primary-light transition-colors\">\n  1123‚Üí              <input\n  1124‚Üí                type=\"file\"\n  1125‚Üí                accept=\".csv,.txt,.dat,.pdf\"\n  1126‚Üí                onChange={(e) => handleFileUpload('eo', e)}\n  1127‚Üí                className=\"absolute inset-0 w-full h-full opacity-0 cursor-pointer\"\n  1128‚Üí              />\n  1129‚Üí              <Upload className=\"h-12 w-12 text-gray-400 dark:text-gray-500 mx-auto mb-2\" />\n  1130‚Üí              <p className=\"text-sm text-gray-600 dark:text-gray-400\">\n  1131‚Üí                {eyesOpenFile ? eyesOpenFile.name : 'Drag & Drop or Click to Upload'}\n  1132‚Üí              </p>\n  1133‚Üí              {eyesOpenFile && (\n  1134‚Üí                <CheckCircle className=\"h-6 w-6 text-green-500 mx-auto mt-2\" />\n  1135‚Üí              )}\n  1136‚Üí            </div>\n  1137‚Üí          </div>\n  1138‚Üí\n  1139‚Üí          {/* Eyes Closed Upload */}\n  1140‚Üí          <div className=\"mb-6\">\n  1141‚Üí            <label className=\"block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2\">\n  1142‚Üí              Page 24 (EC - Eyes Closed)\n  1143‚Üí            </label>\n  1144‚Üí            <div className=\"relative border-2 border-dashed border-gray-300 dark:border-gray-600 rounded-lg p-6 text-center hover:border-primary dark:hover:border-primary-light transition-colors\">\n  1145‚Üí              <input\n  1146‚Üí                type=\"file\"\n  1147‚Üí                accept=\".csv,.txt,.dat,.pdf\"\n  1148‚Üí                onChange={(e) => handleFileUpload('ec', e)}\n  1149‚Üí                className=\"absolute inset-0 w-full h-full opacity-0 cursor-pointer\"\n  1150‚Üí              />\n  1151‚Üí              <Upload className=\"h-12 w-12 text-gray-400 dark:text-gray-500 mx-auto mb-2\" />\n  1152‚Üí              <p className=\"text-sm text-gray-600 dark:text-gray-400\">\n  1153‚Üí                {eyesClosedFile ? eyesClosedFile.name : 'Drag & Drop or Click to Upload'}\n  1154‚Üí              </p>\n  1155‚Üí              {eyesClosedFile && (\n  1156‚Üí                <CheckCircle className=\"h-6 w-6 text-green-500 mx-auto mt-2\" />\n  1157‚Üí              )}\n  1158‚Üí            </div>\n  1159‚Üí          </div>\n  1160‚Üí\n  1161‚Üí          {/* Data Loaded Progress */}\n  1162‚Üí          <div>\n  1163‚Üí            <label className=\"block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2\">\n  1164‚Üí              Data Loaded\n  1165‚Üí            </label>\n  1166‚Üí            <div className=\"w-full bg-gray-200 dark:bg-gray-700 rounded-full h-2.5\">\n  1167‚Üí              <div\n  1168‚Üí                className=\"bg-green-500 h-2.5 rounded-full transition-all duration-300\"\n  1169‚Üí                style={{ width: `${eyesOpenFile && eyesClosedFile ? 100 : eyesOpenFile || eyesClosedFile ? 50 : 0}%` }}\n  1170‚Üí              ></div>\n  1171‚Üí            </div>\n  1172‚Üí          </div>\n  1173‚Üí        </div>\n  1174‚Üí\n  1175‚Üí        {/* Middle Panel - Algorithm Processing */}\n  1176‚Üí        <div className=\"bg-white dark:bg-gray-800 rounded-lg shadow-sm border border-gray-200 dark:border-gray-700 p-6\">\n  1177‚Üí          <h2 className=\"text-lg font-semibold text-gray-900 dark:text-white mb-4\">\n  1178‚Üí            Algorithm 1 Processing\n  1179‚Üí          </h2>\n  1180‚Üí\n  1181‚Üí          {/* Execute Button */}\n  1182‚Üí          <button\n  1183‚Üí            onClick={handleExecuteCalculation}\n  1184‚Üí            disabled={!eyesOpenFile || !eyesClosedFile || isProcessing}\n  1185‚Üí            className={`w-full mb-6 py-3 px-4 rounded-lg font-medium flex items-center justify-center space-x-2 transition-colors shadow-md ${\n  1186‚Üí              eyesOpenFile && eyesClosedFile && !isProcessing\n  1187‚Üí                ? 'bg-primary hover:bg-navy-700 text-white'\n  1188‚Üí                : 'bg-gray-300 dark:bg-gray-600 text-gray-500 dark:text-gray-400 cursor-not-allowed'\n  1189‚Üí            }`}\n  1190‚Üí          >\n  1191‚Üí            <Play className=\"h-5 w-5\" />\n  1192‚Üí            <span>Execute Calculation</span>\n  1193‚Üí          </button>\n  1194‚Üí\n  1195‚Üí          {/* Processing Animation */}\n  1196‚Üí          {isProcessing && (\n  1197‚Üí            <div className=\"bg-gradient-to-r from-primary to-navy-700 rounded-lg p-6 text-center mb-6 shadow-lg\">\n  1198‚Üí              <div className=\"relative inline-block\">\n  1199‚Üí                <Activity className=\"h-16 w-16 text-white animate-pulse\" />\n  1200‚Üí                <div className=\"absolute inset-0 flex items-center justify-center\">\n  1201‚Üí                  <div className=\"w-20 h-20 border-4 border-white/30 border-t-white rounded-full animate-spin\"></div>\n  1202‚Üí                </div>\n  1203‚Üí              </div>\n  1204‚Üí              <p className=\"text-white font-medium mt-4\">Processing...</p>\n  1205‚Üí              <p className=\"text-primary-light text-sm\">{consoleLog.length} actions done</p>\n  1206‚Üí            </div>\n  1207‚Üí          )}\n  1208‚Üí\n  1209‚Üí          {/* Processing Complete */}\n  1210‚Üí          {processingComplete && (\n  1211‚Üí            <div className=\"bg-green-50 dark:bg-green-900/20 border border-green-200 dark:border-green-800 rounded-lg p-4 text-center mb-6\">\n  1212‚Üí              <CheckCircle className=\"h-12 w-12 text-green-500 mx-auto mb-2\" />\n  1213‚Üí              <p className=\"text-green-800 dark:text-green-400 font-medium\">Processing Complete!</p>\n  1214‚Üí            </div>\n  1215‚Üí          )}\n  1216‚Üí\n  1217‚Üí          {/* Console */}\n  1218‚Üí          <div className=\"bg-gray-900 dark:bg-black rounded-lg p-4 min-h-[200px] max-h-[300px] overflow-y-auto\">\n  1219‚Üí            <div className=\"flex items-center justify-between mb-2 pb-2 border-b border-gray-700\">\n  1220‚Üí              <h3 className=\"text-sm font-medium text-gray-300\">Console</h3>\n  1221‚Üí              <button\n  1222‚Üí                onClick={() => setConsoleLog([])}\n  1223‚Üí                className=\"text-xs text-gray-400 hover:text-gray-200\"\n  1224‚Üí              >\n  1225‚Üí                Clear\n  1226‚Üí              </button>\n  1227‚Üí            </div>\n  1228‚Üí            <div className=\"space-y-1 font-mono text-xs\">\n  1229‚Üí              {consoleLog.length > 0 ? (\n  1230‚Üí                consoleLog.map((log, index) => (\n  1231‚Üí                  <div key={index} className=\"text-green-400\">\n  1232‚Üí                    &gt; {log}\n  1233‚Üí                  </div>\n  1234‚Üí                ))\n  1235‚Üí              ) : (\n  1236‚Üí                <div className=\"text-gray-500 italic\">Console output will appear here...</div>\n  1237‚Üí              )}\n  1238‚Üí            </div>\n  1239‚Üí          </div>\n  1240‚Üí        </div>\n  1241‚Üí\n  1242‚Üí        {/* Right Panel - Final 7 Parameter Scores */}\n  1243‚Üí        <div className=\"bg-white dark:bg-gray-800 rounded-lg shadow-sm border border-gray-200 dark:border-gray-700 p-6\">\n  1244‚Üí          <h2 className=\"text-lg font-semibold text-gray-900 dark:text-white mb-4\">\n  1245‚Üí            Final 7 Parameter Scores\n  1246‚Üí          </h2>\n  1247‚Üí\n  1248‚Üí          {results ? (\n  1249‚Üí            <>\n  1250‚Üí              <div className=\"space-y-4 mb-6\">\n  1251‚Üí                {results.map((result, index) => (\n  1252‚Üí                  <div key={index} className=\"border border-gray-200 dark:border-gray-700 rounded-lg p-3\">\n  1253‚Üí                    {/* Main Parameter */}\n  1254‚Üí                    <div className=\"flex items-center justify-between mb-2\">\n  1255‚Üí                      <span className=\"text-sm font-semibold text-gray-800 dark:text-gray-200\">\n  1256‚Üí                        {result.parameter}\n  1257‚Üí                      </span>\n  1258‚Üí                      <div className=\"flex items-center space-x-3\">\n  1259‚Üí                        <span className={`text-base font-bold ${getStatusColor(result.rawScore)}`}>\n  1260‚Üí                          {result.rawScore}\n  1261‚Üí                        </span>\n  1262‚Üí                        <span className={`text-xs px-2.5 py-1 rounded-full font-medium ${getStatusBgColor(result.rawScore)}`}>\n  1263‚Üí                          {result.status}\n  1264‚Üí                        </span>\n  1265‚Üí                      </div>\n  1266‚Üí                    </div>\n  1267‚Üí\n  1268‚Üí                    {/* Progress Bar */}\n  1269‚Üí                    <div className=\"flex-1 bg-gray-200 dark:bg-gray-700 rounded-full h-2 mb-3\">\n  1270‚Üí                      <div\n  1271‚Üí                        className={`h-2 rounded-full ${getProgressBarColor(result.rawScore)}`}\n  1272‚Üí                        style={{ width: `${result.score}%` }}\n  1273‚Üí                      ></div>\n  1274‚Üí                    </div>\n  1275‚Üí\n  1276‚Üí                    {/* Sub-Parameters */}\n  1277‚Üí                    {result.metrics && result.metrics.length > 0 && (\n  1278‚Üí                      <div className=\"mt-3 pt-3 border-t border-gray-200 dark:border-gray-700\">\n  1279‚Üí                        <div className=\"text-xs font-medium text-gray-600 dark:text-gray-400 mb-2\">\n  1280‚Üí                          Sub-Parameters:\n  1281‚Üí                        </div>\n  1282‚Üí                        <div className=\"space-y-2\">\n  1283‚Üí                          {result.metrics.map((metric, mIndex) => (\n  1284‚Üí                            <div key={mIndex} className=\"flex items-center justify-between text-xs pl-2\">\n  1285‚Üí                              <span className=\"text-gray-600 dark:text-gray-400 flex-1\">\n  1286‚Üí                                {metric.name}\n  1287‚Üí                              </span>\n  1288‚Üí                              <div className=\"flex items-center space-x-2\">\n  1289‚Üí                                {metric.score === 1 ? (\n  1290‚Üí                                  <CheckCircle className=\"h-3.5 w-3.5 text-green-500\" />\n  1291‚Üí                                ) : (\n  1292‚Üí                                  <X className=\"h-3.5 w-3.5 text-red-500\" />\n  1293‚Üí                                )}\n  1294‚Üí                                <span className={`font-medium ${metric.score === 1 ? 'text-green-600 dark:text-green-400' : 'text-red-600 dark:text-red-400'}`}>\n  1295‚Üí                                  {metric.score}/1\n  1296‚Üí                                </span>\n  1297‚Üí                              </div>\n  1298‚Üí                            </div>\n  1299‚Üí                          ))}\n  1300‚Üí                        </div>\n  1301‚Üí                      </div>\n  1302‚Üí                    )}\n  1303‚Üí                  </div>\n  1304‚Üí                ))}\n  1305‚Üí              </div>\n  1306‚Üí\n  1307‚Üí              {/* Action Buttons */}\n  1308‚Üí              <div className=\"space-y-3\">\n  1309‚Üí                {/* Save and Download PDF Button */}\n  1310‚Üí                <button\n  1311‚Üí                  onClick={handleSaveResults}\n  1312‚Üí                  disabled={isSaving || isSaved}\n  1313‚Üí                  className={`w-full py-3 px-4 rounded-lg font-medium flex items-center justify-center space-x-2 transition-colors shadow-md ${\n  1314‚Üí                    isSaved\n  1315‚Üí                      ? 'bg-green-100 dark:bg-green-900/30 text-green-700 dark:text-green-400 cursor-not-allowed'\n  1316‚Üí                      : isSaving\n  1317‚Üí                      ? 'bg-blue-400 text-white cursor-wait'\n  1318‚Üí                      : 'bg-primary hover:bg-navy-700 text-white'\n  1319‚Üí                  }`}\n  1320‚Üí                >\n  1321‚Üí                  {isSaving ? (\n  1322‚Üí                    <>\n  1323‚Üí                      <Activity className=\"h-5 w-5 animate-spin\" />\n  1324‚Üí                      <span>Saving...</span>\n  1325‚Üí                    </>\n  1326‚Üí                  ) : isSaved ? (\n  1327‚Üí                    <>\n  1328‚Üí                      <CheckCircle className=\"h-5 w-5\" />\n  1329‚Üí                      <span>Saved ‚úì</span>\n  1330‚Üí                    </>\n  1331‚Üí                  ) : (\n  1332‚Üí                    <>\n  1333‚Üí                      <Download className=\"h-5 w-5\" />\n  1334‚Üí                      <span>Save and Download PDF</span>\n  1335‚Üí                    </>\n  1336‚Üí                  )}\n  1337‚Üí                </button>\n  1338‚Üí\n  1339‚Üí                {/* Export CSV Button */}\n  1340‚Üí                <button\n  1341‚Üí                  onClick={handleExportResults}\n  1342‚Üí                  className=\"w-full bg-green-600 hover:bg-green-700 text-white py-3 px-4 rounded-lg font-medium flex items-center justify-center space-x-2 transition-colors shadow-md\"\n  1343‚Üí                >\n  1344‚Üí                  <Download className=\"h-5 w-5\" />\n  1345‚Üí                  <span>Export CSV</span>\n  1346‚Üí                </button>\n  1347‚Üí\n  1348‚Üí                {/* Single Download PDF Button */}\n  1349‚Üí                {pdfUrl ? (\n  1350‚Üí                  <button\n  1351‚Üí                    onClick={handleDownloadPDF}\n  1352‚Üí                    className=\"w-full bg-blue-600 hover:bg-blue-700 text-white py-3 px-4 rounded-lg font-medium flex items-center justify-center space-x-2 transition-colors shadow-md\"\n  1353‚Üí                  >\n  1354‚Üí                    <Download className=\"h-5 w-5\" />\n  1355‚Üí                    <span>Download PDF Report</span>\n  1356‚Üí                  </button>\n  1357‚Üí                ) : (\n  1358‚Üí                  <div className=\"w-full bg-gray-100 dark:bg-gray-700 border-2 border-dashed border-gray-300 dark:border-gray-600 rounded-lg py-3 px-4 text-center\">\n  1359‚Üí                    <FileText className=\"h-5 w-5 text-gray-400 mx-auto mb-2\" />\n  1360‚Üí                    <p className=\"text-sm text-gray-600 dark:text-gray-400\">\n  1361‚Üí                      PDF will be generated automatically after processing\n  1362‚Üí                    </p>\n  1363‚Üí                  </div>\n  1364‚Üí                )}\n  1365‚Üí              </div>\n  1366‚Üí            </>\n  1367‚Üí          ) : (\n  1368‚Üí            <div className=\"flex flex-col items-center justify-center py-12 text-center\">\n  1369‚Üí              <FileText className=\"h-16 w-16 text-gray-400 dark:text-gray-500 mb-4\" />\n  1370‚Üí              <p className=\"text-sm text-gray-600 dark:text-gray-400\">\n  1371‚Üí                Upload data files and execute calculation to see results\n  1372‚Üí              </p>\n  1373‚Üí            </div>\n  1374‚Üí          )}\n  1375‚Üí        </div>\n  1376‚Üí      </div>\n  1377‚Üí\n  1378‚Üí      {/* Processing History */}\n  1379‚Üí      {selectedPatient && processingHistory.length > 0 && (\n  1380‚Üí        <div className=\"bg-white dark:bg-gray-800 rounded-lg shadow-sm border border-gray-200 dark:border-gray-700 p-6\">\n  1381‚Üí          <div className=\"flex items-center justify-between mb-4\">\n  1382‚Üí            <h2 className=\"text-lg font-semibold text-gray-900 dark:text-white flex items-center\">\n  1383‚Üí              <History className=\"h-5 w-5 mr-2\" />\n  1384‚Üí              Processing History for {getPatientName(selectedPatient)}\n  1385‚Üí            </h2>\n  1386‚Üí            <button\n  1387‚Üí              onClick={async () => {\n  1388‚Üí                console.log('üîÑ Manual sync triggered...');\n  1389‚Üí                toast.loading('Syncing PDFs from Supabase...', { id: 'sync-pdfs' });\n  1390‚Üí\n  1391‚Üí                try {\n  1392‚Üí                  // Force reload from database and sync\n  1393‚Üí                  await loadProcessingHistory(selectedPatient.id);\n  1394‚Üí\n  1395‚Üí                  // Count how many PDFs were found\n  1396‚Üí                  const results = await DatabaseService.get('algorithmResults');\n  1397‚Üí                  const patientResults = results.filter(r => r.patientId === selectedPatient.id);\n  1398‚Üí                  const pdfCount = patientResults.filter(r => r.pdfUrl).length;\n  1399‚Üí                  const totalCount = patientResults.length;\n  1400‚Üí\n  1401‚Üí                  toast.success(`‚úÖ Synced! ${pdfCount}/${totalCount} PDFs available`, { id: 'sync-pdfs' });\n  1402‚Üí                  console.log(`‚úÖ Sync complete: ${pdfCount}/${totalCount} records have PDFs`);\n  1403‚Üí                } catch (error) {\n  1404‚Üí                  console.error('‚ùå Sync failed:', error);\n  1405‚Üí                  toast.error('Failed to sync PDFs', { id: 'sync-pdfs' });\n  1406‚Üí                }\n  1407‚Üí              }}\n  1408‚Üí              className=\"px-3 py-1.5 text-xs bg-blue-600 hover:bg-blue-700 text-white rounded-lg transition-colors flex items-center space-x-1\"\n  1409‚Üí              title=\"Fetch PDFs from Supabase bucket and update database\"\n  1410‚Üí            >\n  1411‚Üí              <Download className=\"h-3 w-3\" />\n  1412‚Üí              <span>Sync PDFs</span>\n  1413‚Üí            </button>\n  1414‚Üí          </div>\n  1415‚Üí          <div className=\"space-y-3\">\n  1416‚Üí            {processingHistory.map((record, index) => (\n  1417‚Üí              <div\n  1418‚Üí                key={record.id}\n  1419‚Üí                className=\"border border-gray-200 dark:border-gray-700 rounded-lg p-4 hover:bg-gray-50 dark:hover:bg-gray-700/50 transition-colors\"\n  1420‚Üí              >\n  1421‚Üí                <div className=\"flex items-center justify-between\">\n  1422‚Üí                  <div className=\"flex-1\">\n  1423‚Üí                    <div className=\"flex items-center space-x-2 mb-2\">\n  1424‚Üí                      <Calendar className=\"h-4 w-4 text-primary\" />\n  1425‚Üí                      <span className=\"text-sm font-medium text-gray-900 dark:text-white\">\n  1426‚Üí                        {new Date(record.processedAt).toLocaleDateString('en-US', {\n  1427‚Üí                          year: 'numeric',\n  1428‚Üí                          month: 'short',\n  1429‚Üí                          day: 'numeric',\n  1430‚Üí                          hour: '2-digit',\n  1431‚Üí                          minute: '2-digit'\n  1432‚Üí                        })}\n  1433‚Üí                      </span>\n  1434‚Üí                      {/* PDF Status Badge */}\n  1435‚Üí                      {record.pdfUrl ? (\n  1436‚Üí                        <span className=\"px-2 py-0.5 text-xs bg-green-100 text-green-700 dark:bg-green-900/30 dark:text-green-400 rounded-full flex items-center space-x-1\">\n  1437‚Üí                          <CheckCircle className=\"h-3 w-3\" />\n  1438‚Üí                          <span>PDF Available</span>\n  1439‚Üí                        </span>\n  1440‚Üí                      ) : (\n  1441‚Üí                        <span className=\"px-2 py-0.5 text-xs bg-gray-100 text-gray-600 dark:bg-gray-700 dark:text-gray-400 rounded-full\">\n  1442‚Üí                          No PDF\n  1443‚Üí                        </span>\n  1444‚Üí                      )}\n  1445‚Üí                    </div>\n  1446‚Üí                    <div className=\"text-xs text-gray-600 dark:text-gray-400 space-y-1 mb-3\">\n  1447‚Üí                      <p>üìÅ Files: {record.eyesOpenFile}, {record.eyesClosedFile}</p>\n  1448‚Üí                      <p>üë§ Processed by: {record.processedBy}</p>\n  1449‚Üí                      {record.pdfUrl && (\n  1450‚Üí                        <p className=\"text-green-600 dark:text-green-400\">\n  1451‚Üí                          üìÑ PDF: {record.pdfUrl.startsWith('http') ? 'Supabase ‚úì' : 'Local ‚úì'}\n  1452‚Üí                        </p>\n  1453‚Üí                      )}\n  1454‚Üí                      {!record.pdfUrl && (\n  1455‚Üí                        <p className=\"text-red-600 dark:text-red-400\">üìÑ PDF: Not available</p>\n  1456‚Üí                      )}\n  1457‚Üí                    </div>\n  1458‚Üí\n  1459‚Üí                    {/* Quick Summary of Results */}\n  1460‚Üí                    {record.results && record.results.length > 0 && (\n  1461‚Üí                      <div className=\"mt-3 grid grid-cols-2 gap-2\">\n  1462‚Üí                        {record.results.slice(0, 4).map((result, idx) => (\n  1463‚Üí                          <div key={idx} className=\"text-xs bg-gray-50 dark:bg-gray-700 rounded p-2\">\n  1464‚Üí                            <span className=\"text-gray-600 dark:text-gray-400\">{result.parameter}:</span>\n  1465‚Üí                            <span className={`ml-2 font-semibold ${getStatusColor(result.rawScore)}`}>\n  1466‚Üí                              {result.rawScore}\n  1467‚Üí                            </span>\n  1468‚Üí                          </div>\n  1469‚Üí                        ))}\n  1470‚Üí                      </div>\n  1471‚Üí                    )}\n  1472‚Üí                  </div>\n  1473‚Üí                  <div className=\"flex flex-col space-y-2\">\n  1474‚Üí                    {/* View Full Results Button */}\n  1475‚Üí                    <button\n  1476‚Üí                      onClick={() => {\n  1477‚Üí                        setResults(record.results);\n  1478‚Üí                        setProcessingComplete(true);\n  1479‚Üí                        setIsSaved(true);\n  1480‚Üí                        // Set PDF URL if available\n  1481‚Üí                        if (record.pdfUrl) {\n  1482‚Üí                          setPdfUrl(record.pdfUrl);\n  1483‚Üí                        }\n  1484‚Üí                        toast.success('Previous results loaded');\n  1485‚Üí                      }}\n  1486‚Üí                      className=\"px-3 py-2 text-sm bg-primary hover:bg-navy-700 text-white rounded-lg transition-colors flex items-center justify-center space-x-1\"\n  1487‚Üí                    >\n  1488‚Üí                      <FileText className=\"h-4 w-4\" />\n  1489‚Üí                      <span>View Results</span>\n  1490‚Üí                    </button>\n  1491‚Üí\n  1492‚Üí                    {/* Download PDF Button - Always visible */}\n  1493‚Üí                    <button\n  1494‚Üí                      onClick={async () => {\n  1495‚Üí                        if (!record.pdfUrl) {\n  1496‚Üí                          toast.error('No PDF available for this record');\n  1497‚Üí                          console.log('‚ùå No PDF URL in record:', record);\n  1498‚Üí                          return;\n  1499‚Üí                        }\n  1500‚Üí\n  1501‚Üí                        console.log('üì• Downloading PDF from record:', {\n  1502‚Üí                          processedAt: record.processedAt,\n  1503‚Üí                          pdfUrl: record.pdfUrl\n  1504‚Üí                        });\n  1505‚Üí\n  1506‚Üí                        try {\n  1507‚Üí                          toast.loading('Downloading PDF...', { id: 'history-download' });\n  1508‚Üí\n  1509‚Üí                          // Construct full URL (works with both local and Supabase URLs)\n  1510‚Üí                          const apiUrl = import.meta.env.VITE_API_URL || 'http://localhost:3001/api';\n  1511‚Üí                          const backendBaseUrl = apiUrl.replace('/api', '');\n  1512‚Üí                          const fullPdfUrl = record.pdfUrl.startsWith('http') ? record.pdfUrl : `${backendBaseUrl}${record.pdfUrl}`;\n  1513‚Üí\n  1514‚Üí                          console.log('üì• Downloading from:', fullPdfUrl);\n  1515‚Üí\n  1516‚Üí                          // Fetch the PDF file\n  1517‚Üí                          const response = await fetch(fullPdfUrl);\n  1518‚Üí                          if (!response.ok) throw new Error('Failed to fetch PDF');\n  1519‚Üí\n  1520‚Üí                          // Convert to blob\n  1521‚Üí                          const blob = await response.blob();\n  1522‚Üí\n  1523‚Üí                          // Create download link\n  1524‚Üí                          const downloadUrl = window.URL.createObjectURL(blob);\n  1525‚Üí                          const link = document.createElement('a');\n  1526‚Üí                          link.href = downloadUrl;\n  1527‚Üí                          link.download = record.pdfUrl.split('/').pop() || 'neurosense-report.pdf';\n  1528‚Üí\n  1529‚Üí                          // Trigger download\n  1530‚Üí                          document.body.appendChild(link);\n  1531‚Üí                          link.click();\n  1532‚Üí\n  1533‚Üí                          // Cleanup\n  1534‚Üí                          document.body.removeChild(link);\n  1535‚Üí                          window.URL.revokeObjectURL(downloadUrl);\n  1536‚Üí\n  1537‚Üí                          toast.success('PDF downloaded successfully!', { id: 'history-download' });\n  1538‚Üí                        } catch (error) {\n  1539‚Üí                          console.error('Download error:', error);\n  1540‚Üí                          toast.error('Failed to download PDF', { id: 'history-download' });\n  1541‚Üí                        }\n  1542‚Üí                      }}\n  1543‚Üí                      disabled={!record.pdfUrl}\n  1544‚Üí                      className={`px-3 py-2 text-sm rounded-lg transition-colors flex items-center justify-center space-x-1 ${\n  1545‚Üí                        record.pdfUrl\n  1546‚Üí                          ? 'bg-blue-600 hover:bg-blue-700 text-white cursor-pointer'\n  1547‚Üí                          : 'bg-gray-300 dark:bg-gray-600 text-gray-500 dark:text-gray-400 cursor-not-allowed'\n  1548‚Üí                      }`}\n  1549‚Üí                      title={record.pdfUrl ? 'Download PDF Report' : 'No PDF available'}\n  1550‚Üí                    >\n  1551‚Üí                      <Download className=\"h-4 w-4\" />\n  1552‚Üí                      <span>Download PDF</span>\n  1553‚Üí                    </button>\n  1554‚Üí                  </div>\n  1555‚Üí                </div>\n  1556‚Üí\n  1557‚Üí                {/* Expandable Details */}\n  1558‚Üí                {record.results && record.results.length > 4 && (\n  1559‚Üí                  <div className=\"mt-3 pt-3 border-t border-gray-200 dark:border-gray-700 text-xs\">\n  1560‚Üí                    <div className=\"grid grid-cols-3 gap-2\">\n  1561‚Üí                      {record.results.slice(4).map((result, idx) => (\n  1562‚Üí                        <div key={idx} className=\"flex justify-between\">\n  1563‚Üí                          <span className=\"text-gray-600 dark:text-gray-400\">{result.parameter}:</span>\n  1564‚Üí                          <span className=\"font-semibold\">{result.rawScore}</span>\n  1565‚Üí                        </div>\n  1566‚Üí                      ))}\n  1567‚Üí                    </div>\n  1568‚Üí                  </div>\n  1569‚Üí                )}\n  1570‚Üí              </div>\n  1571‚Üí            ))}\n  1572‚Üí          </div>\n  1573‚Üí        </div>\n  1574‚Üí      )}\n  1575‚Üí\n  1576‚Üí      {/* Info Section */}\n  1577‚Üí      <div className=\"bg-accent-light dark:bg-primary/20 border border-primary-light dark:border-primary rounded-lg p-4 shadow-sm\">\n  1578‚Üí        <h3 className=\"text-sm font-medium text-primary dark:text-primary-light mb-2\">\n  1579‚Üí          About Algorithm 1 Processing\n  1580‚Üí        </h3>\n  1581‚Üí        <p className=\"text-sm text-navy-800 dark:text-gray-300\">\n  1582‚Üí          This processor analyzes QEEG data files (Eyes Open and Eyes Closed) and generates 7 key parameters using proprietary\n  1583‚Üí          binary scoring logic. The algorithm evaluates brain activity patterns to assess cognitive and emotional health markers.\n  1584‚Üí        </p>\n  1585‚Üí      </div>\n  1586‚Üí    </div>\n  1587‚Üí  );\n  1588‚Üí};\n  1589‚Üí\n  1590‚Üíexport default AlgorithmDataProcessor;\n  1591‚Üí\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"afe65df8-2e9f-4937-9b9b-05babd3a25b1","timestamp":"2025-12-02T09:00:49.387Z","toolUseResult":{"type":"text","file":{"filePath":"D:\\Todays\\Neuro360\\src\\components\\admin\\AlgorithmDataProcessor.jsx","content":"import React, { useState, useEffect } from 'react';\nimport { Upload, Play, Download, FileText, CheckCircle, Activity, User, Building2, Calendar, History, X, ArrowLeft, Search, Filter } from 'lucide-react';\nimport DatabaseService from '../../services/databaseService';\nimport toast from 'react-hot-toast';\n\nconst AlgorithmDataProcessor = () => {\n  const [patients, setPatients] = useState([]);\n  const [clinics, setClinics] = useState([]);\n  const [selectedPatient, setSelectedPatient] = useState(null);\n  const [showProcessingUI, setShowProcessingUI] = useState(false);\n  const [processingHistory, setProcessingHistory] = useState([]);\n  const [loading, setLoading] = useState(true);\n\n  // Filter states\n  const [searchTerm, setSearchTerm] = useState('');\n  const [selectedClinicFilter, setSelectedClinicFilter] = useState('');\n  const [dateFilter, setDateFilter] = useState('');\n\n  const [eyesOpenFile, setEyesOpenFile] = useState(null);\n  const [eyesClosedFile, setEyesClosedFile] = useState(null);\n  const [isProcessing, setIsProcessing] = useState(false);\n  const [processingComplete, setProcessingComplete] = useState(false);\n  const [consoleLog, setConsoleLog] = useState([]);\n  const [progress, setProgress] = useState(0);\n  const [results, setResults] = useState(null);\n  const [isSaved, setIsSaved] = useState(false);\n  const [isSaving, setIsSaving] = useState(false);\n  const [pdfUrl, setPdfUrl] = useState(null);\n\n  // Debug function to check database contents\n  useEffect(() => {\n    window.debugAlgorithmResults = async () => {\n      const allResults = await DatabaseService.get('algorithmResults');\n      console.log('üîç All Algorithm Results in Database:', allResults);\n      console.log(`Total records: ${allResults.length}`);\n      allResults.forEach((record, idx) => {\n        console.log(`\\nüìä Record ${idx + 1}:`, {\n          id: record.id,\n          patientName: record.patientName,\n          processedAt: record.processedAt,\n          pdfUrl: record.pdfUrl || '‚ùå MISSING',\n          hasResults: !!record.results\n        });\n      });\n    };\n    console.log('üí° Debug: Type window.debugAlgorithmResults() in console to check database');\n  }, []);\n\n  useEffect(() => {\n    loadPatients();\n  }, []);\n\n  useEffect(() => {\n    if (selectedPatient && showProcessingUI) {\n      loadProcessingHistory(selectedPatient.id);\n    }\n  }, [selectedPatient, showProcessingUI, isSaved]); // Re-load when saved\n\n  const loadPatients = async () => {\n    try {\n      const patientsData = await DatabaseService.get('patients');\n      const clinicsData = await DatabaseService.get('clinics');\n      const algorithmResults = await DatabaseService.get('algorithmResults') || [];\n\n      // Enrich patients with clinic names and algorithm status\n      const enrichedPatients = patientsData.map(patient => {\n        const patientResults = algorithmResults.filter(r => r.patientId === patient.id);\n        const lastResult = patientResults.length > 0\n          ? patientResults.sort((a, b) => new Date(b.processedAt) - new Date(a.processedAt))[0]\n          : null;\n\n        return {\n          ...patient,\n          clinicName: clinicsData.find(c => c.id === patient.clinicId)?.name || 'Unknown Clinic',\n          algorithmStatus: lastResult ? 'completed' : 'pending',\n          lastProcessed: lastResult?.processedAt,\n          totalScans: patientResults.length\n        };\n      });\n\n      setPatients(enrichedPatients);\n      setClinics(clinicsData);\n      setLoading(false);\n    } catch (error) {\n      console.error('Error loading patients:', error);\n      toast.error('Failed to load patients');\n      setLoading(false);\n    }\n  };\n\n  const loadProcessingHistory = async (patientId) => {\n    try {\n      // Load algorithm results for this patient\n      const results = await DatabaseService.get('algorithmResults');\n      const patientResults = results.filter(r => r.patientId === patientId);\n\n      console.log(`üìã Loaded ${patientResults.length} records for patient ${patientId}`);\n\n      // Log all records for debugging\n      console.log('üìä All records for this patient:');\n      patientResults.forEach((rec, idx) => {\n        console.log(`   ${idx + 1}. ${new Date(rec.processedAt).toLocaleString()} - PDF: ${rec.pdfUrl ? '‚úì' : '‚úó'}`);\n      });\n\n      // Check for records without pdfUrl and try to fix them\n      const recordsWithoutPdf = patientResults.filter(r => !r.pdfUrl);\n      if (recordsWithoutPdf.length > 0) {\n        console.log(`\\n‚ö†Ô∏è Found ${recordsWithoutPdf.length} records without PDF URL - attempting auto-fix...`);\n\n        let updatedCount = 0;\n\n        // Step 1: Try to fetch PDFs from Supabase bucket\n        try {\n          const apiUrl = import.meta.env.VITE_API_URL || 'http://localhost:3001/api';\n          const response = await fetch(`${apiUrl}/qeeg/supabase-pdfs`);\n\n          if (response.ok) {\n            const data = await response.json();\n            console.log(`\\n‚òÅÔ∏è Found ${data.count} PDFs in Supabase bucket:`);\n            data.pdfs.forEach(pdf => console.log(`   - ${pdf.name}`));\n\n            // Match PDFs with database records using smart matching\n            console.log(`\\nüîç Attempting to match ${recordsWithoutPdf.length} records...`);\n            for (const record of recordsWithoutPdf) {\n              const recordTimestamp = new Date(record.processedAt).getTime();\n              const sanitizedName = record.patientName.replace(/[^a-z0-9]/gi, '_').toLowerCase();\n\n              console.log(`\\n   Record: ${record.patientName} @ ${new Date(record.processedAt).toLocaleString()}`);\n              console.log(`   Searching for PDFs matching: neurosense-report-${sanitizedName}-*.pdf`);\n\n              // Find PDFs matching patient name\n              const matchingPdfs = data.pdfs.filter(pdf => {\n                const pdfNameLower = pdf.name.toLowerCase();\n                return pdfNameLower.includes(`neurosense-report-${sanitizedName}-`) &&\n                       pdfNameLower.endsWith('.pdf');\n              });\n\n              console.log(`   Found ${matchingPdfs.length} PDFs for this patient`);\n\n              if (matchingPdfs.length > 0) {\n                // Find PDF with closest timestamp (within 60 seconds)\n                let bestMatch = null;\n                let smallestDiff = Infinity;\n\n                for (const pdf of matchingPdfs) {\n                  // Extract timestamp from filename: neurosense-report-name-TIMESTAMP.pdf\n                  const match = pdf.name.match(/-(\\d+)\\.pdf$/);\n                  if (match) {\n                    const pdfTimestamp = parseInt(match[1]);\n                    const diff = Math.abs(pdfTimestamp - recordTimestamp);\n                    console.log(`      ${pdf.name}: timestamp diff = ${diff}ms (${(diff/1000).toFixed(1)}s)`);\n\n                    // Accept if within 60 seconds (60000ms)\n                    if (diff < 60000 && diff < smallestDiff) {\n                      smallestDiff = diff;\n                      bestMatch = pdf;\n                    }\n                  }\n                }\n\n                if (bestMatch) {\n                  console.log(`   ‚úÖ MATCH FOUND! ${bestMatch.name} (${(smallestDiff/1000).toFixed(1)}s difference)`);\n                  console.log(`   URL: ${bestMatch.url}`);\n                  record.pdfUrl = bestMatch.url;\n                  await DatabaseService.update('algorithmResults', record.id, record);\n                  updatedCount++;\n                } else {\n                  console.log(`   ‚ö†Ô∏è PDFs found but timestamp difference too large (>60s)`);\n                }\n              } else {\n                console.log(`   ‚ùå No PDFs found for patient: ${sanitizedName}`);\n              }\n            }\n          }\n        } catch (supabaseErr) {\n          console.log('‚ö†Ô∏è Could not fetch from Supabase, trying local storage...');\n        }\n\n        // Step 2: If Supabase fails, try local storage\n        for (const record of recordsWithoutPdf) {\n          if (record.pdfUrl) continue; // Already updated from Supabase\n\n          try {\n            const timestamp = new Date(record.processedAt).getTime();\n            const sanitizedName = record.patientName.replace(/[^a-z0-9]/gi, '_').toLowerCase();\n            const possibleFilename = `neurosense-report-${sanitizedName}-${timestamp}.pdf`;\n            const apiUrl = import.meta.env.VITE_API_URL || 'http://localhost:3001/api';\n            const backendBaseUrl = apiUrl.replace('/api', '');\n            const testUrl = `${backendBaseUrl}/uploads/${possibleFilename}`;\n\n            // Test if file exists locally\n            const response = await fetch(testUrl, { method: 'HEAD' });\n            if (response.ok) {\n              console.log(`‚úÖ Found local PDF for record ${record.id}: ${testUrl}`);\n              record.pdfUrl = `/uploads/${possibleFilename}`;\n              await DatabaseService.update('algorithmResults', record.id, record);\n              updatedCount++;\n            }\n          } catch (err) {\n            console.log(`‚ùå Could not find PDF for record ${record.id}`);\n          }\n        }\n\n        if (updatedCount > 0) {\n          console.log(`‚úÖ Auto-fixed ${updatedCount} records with PDF URLs`);\n          // Reload the results after updating\n          const updatedResults = await DatabaseService.get('algorithmResults');\n          const updatedPatientResults = updatedResults.filter(r => r.patientId === patientId);\n          setProcessingHistory(updatedPatientResults);\n\n          updatedPatientResults.forEach((record, idx) => {\n            console.log(`   Record ${idx + 1}:`, {\n              processedAt: record.processedAt,\n              hasPdfUrl: !!record.pdfUrl,\n              pdfUrl: record.pdfUrl || 'NOT SET',\n              pdfType: record.pdfUrl ? (record.pdfUrl.startsWith('http') ? 'Supabase' : 'Local') : 'None'\n            });\n          });\n          return;\n        }\n      }\n\n      patientResults.forEach((record, idx) => {\n        console.log(`   Record ${idx + 1}:`, {\n          processedAt: record.processedAt,\n          hasPdfUrl: !!record.pdfUrl,\n          pdfUrl: record.pdfUrl || 'NOT SET',\n          pdfType: record.pdfUrl ? (record.pdfUrl.startsWith('http') ? 'Supabase' : 'Local') : 'None'\n        });\n      });\n\n      setProcessingHistory(patientResults);\n    } catch (error) {\n      console.error('Error loading processing history:', error);\n      setProcessingHistory([]);\n    }\n  };\n\n  const handleGenerateReport = (patient) => {\n    setSelectedPatient(patient);\n    setShowProcessingUI(true);\n    // Reset upload states\n    setEyesOpenFile(null);\n    setEyesClosedFile(null);\n    setResults(null);\n    setProcessingComplete(false);\n    setConsoleLog([]);\n    setIsSaved(false);\n    setPdfUrl(null);\n    setIsSaving(false);\n  };\n\n  const handleBackToList = () => {\n    setShowProcessingUI(false);\n    setSelectedPatient(null);\n    setEyesOpenFile(null);\n    setEyesClosedFile(null);\n    setResults(null);\n    setProcessingComplete(false);\n    setConsoleLog([]);\n    setProcessingHistory([]);\n    setIsSaved(false);\n    setIsSaving(false);\n    // Reload patients to update status\n    loadPatients();\n  };\n\n  // Helper function to get patient name (handles different field names)\n  const getPatientName = (patient) => {\n    return patient?.fullName || patient?.full_name || patient?.name || patient?.email || 'Unknown Patient';\n  };\n\n  // Helper function to get status badge\n  const getStatusBadge = (status, lastProcessed) => {\n    if (status === 'completed') {\n      return (\n        <div className=\"flex flex-col items-start\">\n          <span className=\"inline-flex items-center px-2.5 py-0.5 rounded-full text-xs font-medium bg-green-100 text-green-800 dark:bg-green-900/30 dark:text-green-400\">\n            <CheckCircle className=\"h-3 w-3 mr-1\" />\n            Completed\n          </span>\n          {lastProcessed && (\n            <span className=\"text-xs text-gray-500 dark:text-gray-400 mt-1\">\n              {new Date(lastProcessed).toLocaleDateString('en-US', { month: 'short', day: 'numeric', year: 'numeric' })}\n            </span>\n          )}\n        </div>\n      );\n    }\n    return (\n      <span className=\"inline-flex items-center px-2.5 py-0.5 rounded-full text-xs font-medium bg-yellow-100 text-yellow-800 dark:bg-yellow-900/30 dark:text-yellow-400\">\n        <Activity className=\"h-3 w-3 mr-1\" />\n        Pending\n      </span>\n    );\n  };\n\n  // Filter patients based on search and filters\n  const filteredPatients = patients.filter(patient => {\n    const matchesSearch = searchTerm === '' ||\n      getPatientName(patient).toLowerCase().includes(searchTerm.toLowerCase()) ||\n      patient.email?.toLowerCase().includes(searchTerm.toLowerCase());\n\n    const matchesClinic = selectedClinicFilter === '' || patient.clinicId === selectedClinicFilter;\n\n    const matchesDate = dateFilter === '' ||\n      (patient.lastProcessed && new Date(patient.lastProcessed).toISOString().split('T')[0] === dateFilter);\n\n    return matchesSearch && matchesClinic && matchesDate;\n  });\n\n  // Group filtered patients by clinic\n  const groupedPatients = clinics.map(clinic => ({\n    clinic,\n    patients: filteredPatients.filter(p => p.clinicId === clinic.id)\n  })).filter(group => group.patients.length > 0);\n\n  const clearFilters = () => {\n    setSearchTerm('');\n    setSelectedClinicFilter('');\n    setDateFilter('');\n  };\n\n  const handleFileUpload = (type, event) => {\n    const file = event.target.files[0];\n    if (file) {\n      if (type === 'eo') {\n        setEyesOpenFile(file);\n      } else {\n        setEyesClosedFile(file);\n      }\n      // Reset processing state when new files are uploaded\n      setProcessingComplete(false);\n      setResults(null);\n      setConsoleLog([]);\n      setProgress(0);\n      setIsSaved(false);\n      setIsSaving(false);\n      setPdfUrl(null);\n    }\n  };\n\n  const processQEEGFiles = async () => {\n    setIsProcessing(true);\n    setConsoleLog([]);\n    setProgress(0);\n\n    try {\n      // Console log: Starting process\n      setConsoleLog(prev => [...prev, 'üöÄ Starting QEEG analysis...']);\n      setProgress(10);\n\n      // Create FormData to send files\n      const formData = new FormData();\n      formData.append('eyesOpen', eyesOpenFile);\n      formData.append('eyesClosed', eyesClosedFile);\n      formData.append('patientId', selectedPatient.id);\n      formData.append('patientName', getPatientName(selectedPatient));\n      formData.append('clinicName', selectedPatient.clinicName);\n      // Add complete patient data for PDF\n      formData.append('dateOfBirth', selectedPatient.dateOfBirth || selectedPatient.date_of_birth || 'Not specified');\n      formData.append('age', selectedPatient.age || calculateAge(selectedPatient.dateOfBirth || selectedPatient.date_of_birth) || 'N/A');\n      formData.append('gender', selectedPatient.gender || 'Not specified');\n      formData.append('handedness', selectedPatient.handedness || 'Right');\n\n      setConsoleLog(prev => [...prev, 'üì§ Uploading files to server...']);\n      setProgress(20);\n\n      // Call backend API\n      const apiUrl = import.meta.env.VITE_API_URL || 'http://localhost:3001/api';\n      const response = await fetch(`${apiUrl}/qeeg/process`, {\n        method: 'POST',\n        body: formData\n      });\n\n      setConsoleLog(prev => [...prev, 'üìä Parsing QEEG data tables...']);\n      setProgress(40);\n\n      if (!response.ok) {\n        const errorData = await response.json();\n        throw new Error(errorData.message || 'Failed to process QEEG files');\n      }\n\n      const data = await response.json();\n\n      // Auto-set PDF URL if returned from backend\n      if (data.data.pdfUrl) {\n        setPdfUrl(data.data.pdfUrl);\n        console.log('‚úÖ PDF auto-generated:', data.data.pdfUrl);\n        setConsoleLog(prev => [...prev, 'üìÑ PDF report generated automatically']);\n      }\n\n      setConsoleLog(prev => [...prev, 'üßÆ Calculating 7 brain health parameters...']);\n      setProgress(60);\n\n      // Simulate calculation steps for better UX\n      await new Promise(resolve => setTimeout(resolve, 500));\n      setConsoleLog(prev => [...prev, '  ‚úì Cognition parameter calculated']);\n      setProgress(65);\n\n      await new Promise(resolve => setTimeout(resolve, 400));\n      setConsoleLog(prev => [...prev, '  ‚úì Stress parameter calculated']);\n      setProgress(70);\n\n      await new Promise(resolve => setTimeout(resolve, 400));\n      setConsoleLog(prev => [...prev, '  ‚úì Focus & Attention parameter calculated']);\n      setProgress(75);\n\n      await new Promise(resolve => setTimeout(resolve, 400));\n      setConsoleLog(prev => [...prev, '  ‚úì Burnout & Fatigue parameter calculated']);\n      setProgress(80);\n\n      await new Promise(resolve => setTimeout(resolve, 400));\n      setConsoleLog(prev => [...prev, '  ‚úì Emotional Regulation parameter calculated']);\n      setProgress(85);\n\n      await new Promise(resolve => setTimeout(resolve, 400));\n      setConsoleLog(prev => [...prev, '  ‚úì Learning parameter calculated']);\n      setProgress(90);\n\n      await new Promise(resolve => setTimeout(resolve, 400));\n      setConsoleLog(prev => [...prev, '  ‚úì Creativity parameter calculated']);\n      setProgress(95);\n\n      // Convert API results to display format\n      const finalResults = data.data.results.map(param => ({\n        parameter: param.name,\n        score: Math.round((param.score / param.maxScore) * 100), // Convert to percentage\n        rawScore: `${param.score}/${param.maxScore}`,\n        status: param.classification,\n        color: param.classification === 'High' ? 'green' :\n               param.classification === 'Medium' ? 'blue' : 'orange',\n        metrics: param.metrics\n      }));\n\n      setConsoleLog(prev => [...prev, '‚úÖ Analysis complete!']);\n      setConsoleLog(prev => [...prev, `üìà Overall Score: ${data.data.overallScore}/${data.data.maxScore}`]);\n      setProgress(100);\n\n      setResults(finalResults);\n      setIsProcessing(false);\n      setProcessingComplete(true);\n      setIsSaved(false); // Mark as not saved yet\n\n      toast.success('QEEG analysis completed successfully!');\n\n    } catch (error) {\n      console.error('Error processing QEEG files:', error);\n      setConsoleLog(prev => [...prev, `‚ùå Error: ${error.message}`]);\n      setIsProcessing(false);\n      toast.error(error.message || 'Failed to process QEEG files');\n    }\n  };\n\n  const saveResultsToDatabase = async (resultData) => {\n    if (!resultData) {\n      toast.error('No results to save');\n      return;\n    }\n\n    try {\n      setIsSaving(true);\n      toast.loading('Saving results to database...', { id: 'save-results' });\n\n      console.log('üíæ Saving results to database...');\n\n      // PDF should already exist from auto-generation\n      if (!pdfUrl) {\n        console.warn('‚ö†Ô∏è No PDF URL available - PDF may not have been generated');\n      }\n\n      const algorithmResult = {\n        id: `alg_${Date.now()}_${selectedPatient.id}`,\n        patientId: selectedPatient.id,\n        patientName: getPatientName(selectedPatient),\n        clinicId: selectedPatient.clinicId,\n        clinicName: selectedPatient.clinicName,\n        pdfUrl: pdfUrl || null, // Use existing PDF URL from auto-generation\n        results: resultData,\n        eyesOpenFile: eyesOpenFile?.name,\n        eyesClosedFile: eyesClosedFile?.name,\n        processedAt: new Date().toISOString(),\n        processedBy: 'super_admin' // Could be dynamic based on logged-in user\n      };\n\n      console.log('üíæ Saving to database...');\n      console.log('   Patient:', algorithmResult.patientName);\n      console.log('   PDF URL:', pdfUrl || 'NOT SET');\n      console.log('   PDF Type:', pdfUrl ? (pdfUrl.startsWith('http') ? 'Supabase' : 'Local') : 'None');\n\n      await DatabaseService.add('algorithmResults', algorithmResult);\n\n      setIsSaved(true);\n      setIsSaving(false);\n\n      toast.success('‚úÖ Results saved successfully!', { id: 'save-results' });\n\n      // Reload history and patient list to update status\n      loadProcessingHistory(selectedPatient.id);\n      loadPatients();\n    } catch (error) {\n      console.error('‚ùå Error saving results:', error);\n      setIsSaving(false);\n      toast.error('‚ùå Failed to save results: ' + error.message, { id: 'save-results' });\n    }\n  };\n\n  const handleSaveResults = async () => {\n    if (results) {\n      await saveResultsToDatabase(results);\n      // After saving, automatically download PDF if available\n      if (pdfUrl) {\n        setTimeout(() => {\n          handleDownloadPDF();\n        }, 500); // Small delay to let save complete\n      }\n    }\n  };\n\n  const handleExecuteCalculation = () => {\n    if (eyesOpenFile && eyesClosedFile) {\n      processQEEGFiles();\n    } else {\n      toast.error('Please upload both QEEG data files');\n    }\n  };\n\n  const handleExportResults = () => {\n    if (results) {\n      // Create CSV content\n      const csvContent = [\n        ['Parameter', 'Score (%)', 'Status'],\n        ...results.map(r => [r.parameter, r.score, r.status])\n      ].map(row => row.join(',')).join('\\n');\n\n      // Create and download file\n      const blob = new Blob([csvContent], { type: 'text/csv' });\n      const url = window.URL.createObjectURL(blob);\n      const a = document.createElement('a');\n      a.href = url;\n      a.download = 'neurosense-algorithm-results.csv';\n      a.click();\n      window.URL.revokeObjectURL(url);\n    }\n  };\n\n  const generatePDFReport = async (resultData) => {\n    if (!resultData || !selectedPatient) {\n      console.error('‚ùå Cannot generate PDF: Missing resultData or selectedPatient');\n      toast.error('Cannot generate PDF: Missing data');\n      return null;\n    }\n\n    try {\n      console.log('üîß Preparing patient data...');\n\n      // Prepare patient data - FIXED: Use current date for recording, not DOB\n      const patientData = {\n        name: getPatientName(selectedPatient),\n        dateOfRecording: new Date().toISOString().split('T')[0], // TODAY'S DATE, not DOB!\n        dateOfBirth: selectedPatient.dateOfBirth || selectedPatient.date_of_birth || 'Not specified',\n        age: selectedPatient.age || calculateAge(selectedPatient.dateOfBirth || selectedPatient.date_of_birth) || 'N/A',\n        gender: selectedPatient.gender || 'Not specified',\n        handedness: selectedPatient.handedness || 'Right', // Default to Right if not specified\n        patientId: selectedPatient.id,\n        occupation: selectedPatient.occupation || 'Not specified',\n        symptoms: selectedPatient.symptoms || []\n      };\n\n      console.log('üë§ Patient Data (Fixed):', patientData);\n      console.log('   Name:', patientData.name);\n      console.log('   Recording Date:', patientData.dateOfRecording);\n      console.log('   DOB:', patientData.dateOfBirth);\n      console.log('   Age:', patientData.age);\n      console.log('   Gender:', patientData.gender);\n      console.log('   Handedness:', patientData.handedness);\n\n      // Prepare algorithm results\n      const algorithmResults = {\n        parameters: resultData.map(result => ({\n          name: result.parameter,\n          score: parseInt(result.rawScore.split('/')[0]),\n          maxScore: parseInt(result.rawScore.split('/')[1]),\n          classification: result.status,\n          metrics: result.metrics || []\n        })),\n        overallScore: resultData.reduce((sum, r) => sum + parseInt(r.rawScore.split('/')[0]), 0)\n      };\n\n      console.log('üìä Algorithm Results:', algorithmResults);\n\n      // Prepare QEEG data (use sample data if not available)\n      const qeegData = {\n        EC: {\n          absolute: { Fz: { Delta: 5.2, Theta: 4.1, Alpha: 8.3, Beta: 6.2, HiBeta: 3.1 } },\n          relative: { Pz: { Alpha: 45.2 } },\n          special: { alphaPeak: 10.3, O1: 10.1 }\n        },\n        EO: {\n          absolute: { Fz: { Theta: 3.8, Beta: 3.2, HiBeta: 2.5 } },\n          relative: { Pz: { Alpha: 28.7 } }\n        }\n      };\n\n      // Call backend API to generate PDF\n      const apiUrl = import.meta.env.VITE_API_URL || 'http://localhost:3001/api';\n      const pdfEndpoint = `${apiUrl}/qeeg/generate-pdf`;\n\n      console.log('üåê Calling backend API:', pdfEndpoint);\n      console.log('üì° Request payload size:', JSON.stringify({ patientData, algorithmResults, qeegData }).length, 'bytes');\n\n      // Add timeout handling\n      const controller = new AbortController();\n      const timeoutId = setTimeout(() => controller.abort(), 30000); // 30 second timeout\n\n      const response = await fetch(pdfEndpoint, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({\n          patientData,\n          algorithmResults,\n          qeegData\n        }),\n        signal: controller.signal\n      }).catch(error => {\n        clearTimeout(timeoutId);\n        if (error.name === 'AbortError') {\n          throw new Error('PDF generation timed out after 30 seconds. Server might be slow or not responding.');\n        }\n        throw error;\n      });\n\n      clearTimeout(timeoutId);\n\n      console.log('üì° Backend response status:', response.status);\n      console.log('üì° Backend response headers:', Object.fromEntries(response.headers.entries()));\n\n      if (!response.ok) {\n        let errorMessage = `Server returned ${response.status}`;\n        try {\n          const errorData = await response.json();\n          errorMessage = errorData.message || errorMessage;\n          console.error('‚ùå Backend error data:', errorData);\n        } catch (e) {\n          const errorText = await response.text();\n          errorMessage = errorText || errorMessage;\n          console.error('‚ùå Backend error text:', errorText);\n        }\n        throw new Error(`Failed to generate PDF: ${errorMessage}`);\n      }\n\n      const data = await response.json();\n      console.log('üì¶ Backend response data:', data);\n\n      if (!data || !data.success || !data.data) {\n        console.error('‚ùå Invalid response format:', data);\n        throw new Error('Invalid response from server');\n      }\n\n      // Use the complete URL from backend instead of constructing it\n      const pdfResult = {\n        url: data.data.url, // Backend already provides complete URL\n        path: data.data.path,\n        filename: data.data.filename\n      };\n\n      console.log('‚úÖ PDF generated successfully!', pdfResult);\n      console.log('‚úÖ PDF URL:', pdfResult.url);\n\n      return pdfResult;\n\n    } catch (error) {\n      console.error('‚ùå Error generating PDF:', error);\n      console.error('‚ùå Error name:', error.name);\n      console.error('‚ùå Error message:', error.message);\n\n      if (error.message && error.stack) {\n        console.error('‚ùå Error stack:', error.stack);\n      }\n\n      // Provide specific error messages based on error type\n      if (error.name === 'TypeError' && error.message.includes('Failed to fetch')) {\n        console.error('‚ùå NETWORK ERROR: Cannot connect to backend server');\n        console.error('‚ùå Please ensure backend server is running on http://localhost:3001');\n        toast.error('Cannot connect to server. Please ensure backend is running on port 3001.');\n      } else if (error.name === 'AbortError') {\n        console.error('‚ùå TIMEOUT ERROR: PDF generation took too long');\n        toast.error('PDF generation timed out. Server might be overloaded.');\n      } else {\n        console.error('‚ùå PDF GENERATION ERROR:', error.message);\n        toast.error(`PDF generation failed: ${error.message}`);\n      }\n\n      return null;\n    }\n  };\n\n  const handleDownloadPDF = async () => {\n    if (!pdfUrl) {\n      toast.error('PDF not available. Please save results first.');\n      return;\n    }\n\n    try {\n      toast.loading('Downloading PDF...', { id: 'download-pdf' });\n\n      // Construct full backend URL\n      const apiUrl = import.meta.env.VITE_API_URL || 'http://localhost:3001/api';\n      const backendBaseUrl = apiUrl.replace('/api', ''); // Remove /api to get base URL\n\n      // Handle both Supabase URLs and local URLs\n      let fullPdfUrl;\n      if (pdfUrl.startsWith('http')) {\n        // It's already a full URL (Supabase)\n        fullPdfUrl = pdfUrl;\n      } else {\n        // It's a local path, construct full URL\n        fullPdfUrl = `${backendBaseUrl}${pdfUrl}`;\n      }\n\n      console.log('üîΩ Download Info:', {\n        originalPdfUrl: pdfUrl,\n        backendBaseUrl,\n        fullPdfUrl,\n        isSupabase: pdfUrl.startsWith('http')\n      });\n\n      // For local files, try direct window.open first (simpler approach)\n      if (!pdfUrl.startsWith('http')) {\n        console.log('üì• Using direct download method for local file');\n\n        // Create a hidden link and click it\n        const link = document.createElement('a');\n        link.href = fullPdfUrl;\n        link.download = pdfUrl.split('/').pop() || 'neurosense-report.pdf';\n        link.target = '_blank';\n\n        document.body.appendChild(link);\n        link.click();\n        document.body.removeChild(link);\n\n        toast.success('PDF download started!', { id: 'download-pdf' });\n        return;\n      }\n\n      // For Supabase URLs, use fetch method\n      console.log('üì• Using fetch method for Supabase URL');\n\n      const response = await fetch(fullPdfUrl);\n\n      if (!response.ok) {\n        console.error('‚ùå Download failed:', {\n          status: response.status,\n          statusText: response.statusText\n        });\n        throw new Error(`Server returned ${response.status}: ${response.statusText}`);\n      }\n\n      // Convert to blob\n      const blob = await response.blob();\n\n      // Verify blob is valid\n      if (!blob || blob.size === 0) {\n        throw new Error('Downloaded file is empty');\n      }\n\n      console.log('‚úÖ PDF fetched successfully, size:', (blob.size / 1024).toFixed(2), 'KB');\n\n      // Create download link\n      const downloadUrl = window.URL.createObjectURL(blob);\n      const link = document.createElement('a');\n      link.href = downloadUrl;\n      link.download = pdfUrl.split('/').pop() || 'neurosense-report.pdf';\n\n      // Trigger download\n      document.body.appendChild(link);\n      link.click();\n\n      // Cleanup\n      setTimeout(() => {\n        document.body.removeChild(link);\n        window.URL.revokeObjectURL(downloadUrl);\n      }, 100);\n\n      toast.success('PDF downloaded successfully!', { id: 'download-pdf' });\n\n    } catch (error) {\n      console.error('‚ùå Download error:', {\n        error: error.message,\n        pdfUrl,\n        stack: error.stack\n      });\n\n      // Provide more helpful error messages\n      let errorMessage = 'Failed to download PDF';\n      if (error.message.includes('404')) {\n        errorMessage = 'PDF file not found on server';\n      } else if (error.message.includes('Failed to fetch')) {\n        errorMessage = 'Network error. Please check your connection.';\n      } else {\n        errorMessage = `Download failed: ${error.message}`;\n      }\n\n      toast.error(errorMessage, { id: 'download-pdf' });\n    }\n  };\n\n  const calculateAge = (dateOfBirth) => {\n    if (!dateOfBirth) return 'N/A';\n    const today = new Date();\n    const birthDate = new Date(dateOfBirth);\n    let age = today.getFullYear() - birthDate.getFullYear();\n    const monthDiff = today.getMonth() - birthDate.getMonth();\n    if (monthDiff < 0 || (monthDiff === 0 && today.getDate() < birthDate.getDate())) {\n      age--;\n    }\n    return age;\n  };\n\n  // Helper function to get color based on score\n  // 1/3 = Red, 2/3 = Yellow, 3/3 = Green\n  const getScoreColor = (rawScore) => {\n    if (!rawScore) return 'gray';\n\n    const [score, maxScore] = rawScore.split('/').map(Number);\n\n    if (score === 1) return 'red';      // 1/3\n    if (score === 2) return 'yellow';   // 2/3\n    if (score === 3) return 'green';    // 3/3\n\n    return 'gray';\n  };\n\n  const getStatusColor = (rawScore) => {\n    const color = getScoreColor(rawScore);\n    switch (color) {\n      case 'red': return 'text-red-500';\n      case 'yellow': return 'text-yellow-500';\n      case 'green': return 'text-green-500';\n      default: return 'text-gray-500';\n    }\n  };\n\n  const getStatusBgColor = (rawScore) => {\n    const color = getScoreColor(rawScore);\n    if (color === 'green') return 'bg-green-100 text-green-800 dark:bg-green-900/30 dark:text-green-400';\n    if (color === 'yellow') return 'bg-yellow-100 text-yellow-800 dark:bg-yellow-900/30 dark:text-yellow-400';\n    if (color === 'red') return 'bg-red-100 text-red-800 dark:bg-red-900/30 dark:text-red-400';\n    return 'bg-gray-100 text-gray-800 dark:bg-gray-900/30 dark:text-gray-400';\n  };\n\n  const getProgressBarColor = (rawScore) => {\n    const color = getScoreColor(rawScore);\n    switch (color) {\n      case 'red': return 'bg-red-500';\n      case 'yellow': return 'bg-yellow-500';\n      case 'green': return 'bg-green-500';\n      default: return 'bg-gray-500';\n    }\n  };\n\n  if (loading) {\n    return (\n      <div className=\"flex items-center justify-center h-64\">\n        <div className=\"text-center\">\n          <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary mx-auto\"></div>\n          <p className=\"mt-4 text-gray-600 dark:text-gray-400\">Loading patients...</p>\n        </div>\n      </div>\n    );\n  }\n\n  // Patient List View\n  if (!showProcessingUI) {\n    return (\n      <div className=\"space-y-6\">\n        {/* Header */}\n        <div className=\"bg-gradient-to-r from-primary to-navy-700 rounded-lg p-6 text-white shadow-lg\">\n          <h1 className=\"text-2xl font-bold\">NeuroSense - Algorithm 1 Data Processor</h1>\n          <p className=\"text-primary-light mt-2\">Select a patient to generate Algorithm 1 report</p>\n        </div>\n\n        {/* Filter Bar */}\n        <div className=\"bg-white dark:bg-gray-800 rounded-lg shadow-sm border border-gray-200 dark:border-gray-700 p-4\">\n          <div className=\"flex flex-col lg:flex-row gap-4\">\n            {/* Patient Search */}\n            <div className=\"flex-1\">\n              <label className=\"block text-xs font-medium text-gray-700 dark:text-gray-300 mb-1\">\n                Search Patient\n              </label>\n              <div className=\"relative\">\n                <Search className=\"absolute left-3 top-1/2 transform -translate-y-1/2 h-4 w-4 text-gray-400 dark:text-gray-500\" />\n                <input\n                  type=\"text\"\n                  placeholder=\"Search by name or email...\"\n                  value={searchTerm}\n                  onChange={(e) => setSearchTerm(e.target.value)}\n                  className=\"w-full pl-10 pr-4 py-2 border border-gray-300 dark:border-gray-600 rounded-lg bg-white dark:bg-gray-700 text-gray-900 dark:text-white text-sm focus:outline-none focus:ring-2 focus:ring-primary\"\n                />\n              </div>\n            </div>\n\n            {/* Clinic Filter */}\n            <div className=\"flex-1\">\n              <label className=\"block text-xs font-medium text-gray-700 dark:text-gray-300 mb-1\">\n                Filter by Clinic\n              </label>\n              <div className=\"relative\">\n                <Building2 className=\"absolute left-3 top-1/2 transform -translate-y-1/2 h-4 w-4 text-gray-400 dark:text-gray-500\" />\n                <select\n                  value={selectedClinicFilter}\n                  onChange={(e) => setSelectedClinicFilter(e.target.value)}\n                  className=\"w-full pl-10 pr-4 py-2 border border-gray-300 dark:border-gray-600 rounded-lg bg-white dark:bg-gray-700 text-gray-900 dark:text-white text-sm focus:outline-none focus:ring-2 focus:ring-primary appearance-none\"\n                >\n                  <option value=\"\">All Clinics</option>\n                  {clinics.map(clinic => (\n                    <option key={clinic.id} value={clinic.id}>\n                      {clinic.name}\n                    </option>\n                  ))}\n                </select>\n              </div>\n            </div>\n\n            {/* Date Filter */}\n            <div className=\"flex-1\">\n              <label className=\"block text-xs font-medium text-gray-700 dark:text-gray-300 mb-1\">\n                Filter by Date\n              </label>\n              <div className=\"relative\">\n                <Calendar className=\"absolute left-3 top-1/2 transform -translate-y-1/2 h-4 w-4 text-gray-400 dark:text-gray-500\" />\n                <input\n                  type=\"date\"\n                  value={dateFilter}\n                  onChange={(e) => setDateFilter(e.target.value)}\n                  className=\"w-full pl-10 pr-4 py-2 border border-gray-300 dark:border-gray-600 rounded-lg bg-white dark:bg-gray-700 text-gray-900 dark:text-white text-sm focus:outline-none focus:ring-2 focus:ring-primary\"\n                />\n              </div>\n            </div>\n\n            {/* Clear Filters Button */}\n            {(searchTerm || selectedClinicFilter || dateFilter) && (\n              <div className=\"flex items-end\">\n                <button\n                  onClick={clearFilters}\n                  className=\"px-4 py-2 bg-gray-100 hover:bg-gray-200 dark:bg-gray-700 dark:hover:bg-gray-600 text-gray-700 dark:text-gray-300 rounded-lg text-sm font-medium transition-colors flex items-center space-x-2\"\n                >\n                  <X className=\"h-4 w-4\" />\n                  <span>Clear</span>\n                </button>\n              </div>\n            )}\n          </div>\n\n          {/* Active Filters Display */}\n          {(searchTerm || selectedClinicFilter || dateFilter) && (\n            <div className=\"mt-3 flex flex-wrap gap-2\">\n              {searchTerm && (\n                <span className=\"inline-flex items-center px-3 py-1 rounded-full text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900/30 dark:text-blue-400\">\n                  Search: \"{searchTerm}\"\n                </span>\n              )}\n              {selectedClinicFilter && (\n                <span className=\"inline-flex items-center px-3 py-1 rounded-full text-xs font-medium bg-purple-100 text-purple-800 dark:bg-purple-900/30 dark:text-purple-400\">\n                  Clinic: {clinics.find(c => c.id === selectedClinicFilter)?.name}\n                </span>\n              )}\n              {dateFilter && (\n                <span className=\"inline-flex items-center px-3 py-1 rounded-full text-xs font-medium bg-green-100 text-green-800 dark:bg-green-900/30 dark:text-green-400\">\n                  Date: {new Date(dateFilter).toLocaleDateString('en-US', { month: 'short', day: 'numeric', year: 'numeric' })}\n                </span>\n              )}\n              <span className=\"text-xs text-gray-500 dark:text-gray-400 self-center\">\n                ({filteredPatients.length} {filteredPatients.length === 1 ? 'patient' : 'patients'} found)\n              </span>\n            </div>\n          )}\n        </div>\n\n        {/* Patient List - Clinic-wise */}\n        <div className=\"space-y-4\">\n          {groupedPatients.length > 0 ? (\n            groupedPatients.map(({ clinic, patients: clinicPatients }) => (\n            <div key={clinic.id} className=\"bg-white dark:bg-gray-800 rounded-lg shadow-sm border border-gray-200 dark:border-gray-700\">\n              {/* Clinic Header */}\n              <div className=\"bg-accent-light dark:bg-primary/20 border-b border-primary-light dark:border-primary px-6 py-3\">\n                <div className=\"flex items-center\">\n                  <Building2 className=\"h-5 w-5 text-primary mr-2\" />\n                  <h3 className=\"text-lg font-semibold text-gray-900 dark:text-white\">\n                    {clinic.name}\n                  </h3>\n                  <span className=\"ml-3 text-sm text-gray-600 dark:text-gray-400\">\n                    ({clinicPatients.length} {clinicPatients.length === 1 ? 'patient' : 'patients'})\n                  </span>\n                </div>\n              </div>\n\n              {/* Patient Table */}\n              <div className=\"overflow-x-auto\">\n                <table className=\"w-full\">\n                  <thead className=\"bg-gray-50 dark:bg-gray-700\">\n                    <tr>\n                      <th className=\"px-6 py-3 text-left text-xs font-medium text-gray-500 dark:text-gray-300 uppercase tracking-wider\">\n                        Patient Name\n                      </th>\n                      <th className=\"px-6 py-3 text-left text-xs font-medium text-gray-500 dark:text-gray-300 uppercase tracking-wider\">\n                        Email\n                      </th>\n                      <th className=\"px-6 py-3 text-left text-xs font-medium text-gray-500 dark:text-gray-300 uppercase tracking-wider\">\n                        Previous Scans\n                      </th>\n                      <th className=\"px-6 py-3 text-left text-xs font-medium text-gray-500 dark:text-gray-300 uppercase tracking-wider\">\n                        Status\n                      </th>\n                      <th className=\"px-6 py-3 text-right text-xs font-medium text-gray-500 dark:text-gray-300 uppercase tracking-wider\">\n                        Action\n                      </th>\n                    </tr>\n                  </thead>\n                  <tbody className=\"divide-y divide-gray-200 dark:divide-gray-700\">\n                    {clinicPatients.map(patient => (\n                      <tr key={patient.id} className=\"hover:bg-gray-50 dark:hover:bg-gray-700/50\">\n                        <td className=\"px-6 py-4 whitespace-nowrap\">\n                          <div className=\"flex items-center\">\n                            <User className=\"h-4 w-4 text-gray-400 dark:text-gray-500 mr-2\" />\n                            <span className=\"text-sm font-medium text-gray-900 dark:text-white\">\n                              {getPatientName(patient)}\n                            </span>\n                          </div>\n                        </td>\n                        <td className=\"px-6 py-4 whitespace-nowrap text-sm text-gray-600 dark:text-gray-400\">\n                          {patient.email || 'N/A'}\n                        </td>\n                        <td className=\"px-6 py-4 whitespace-nowrap text-sm text-gray-600 dark:text-gray-400\">\n                          <span className=\"flex items-center\">\n                            <History className=\"h-4 w-4 mr-1\" />\n                            {patient.totalScans || 0} {patient.totalScans === 1 ? 'scan' : 'scans'}\n                          </span>\n                        </td>\n                        <td className=\"px-6 py-4 whitespace-nowrap\">\n                          {getStatusBadge(patient.algorithmStatus, patient.lastProcessed)}\n                        </td>\n                        <td className=\"px-6 py-4 whitespace-nowrap text-right\">\n                          <button\n                            onClick={() => handleGenerateReport(patient)}\n                            className=\"bg-primary hover:bg-navy-700 text-white px-4 py-2 rounded-lg text-sm font-medium transition-colors shadow-md flex items-center ml-auto\"\n                          >\n                            <FileText className=\"h-4 w-4 mr-2\" />\n                            {patient.algorithmStatus === 'completed' ? 'View/Generate' : 'Generate Report'}\n                          </button>\n                        </td>\n                      </tr>\n                    ))}\n                  </tbody>\n                </table>\n              </div>\n            </div>\n            ))\n          ) : (\n            <div className=\"bg-white dark:bg-gray-800 rounded-lg shadow-sm border border-gray-200 dark:border-gray-700 p-12 text-center\">\n              <Filter className=\"h-16 w-16 text-gray-400 dark:text-gray-500 mx-auto mb-4\" />\n              <p className=\"text-gray-600 dark:text-gray-400 font-medium\">\n                {searchTerm || selectedClinicFilter || dateFilter\n                  ? 'No patients match your filters'\n                  : 'No patients found'\n                }\n              </p>\n              <p className=\"text-sm text-gray-500 dark:text-gray-500 mt-2\">\n                {searchTerm || selectedClinicFilter || dateFilter\n                  ? 'Try adjusting your search criteria or clear filters'\n                  : 'Patients will appear here once they are registered in the system'\n                }\n              </p>\n              {(searchTerm || selectedClinicFilter || dateFilter) && (\n                <button\n                  onClick={clearFilters}\n                  className=\"mt-4 px-4 py-2 bg-primary hover:bg-navy-700 text-white rounded-lg text-sm font-medium transition-colors\"\n                >\n                  Clear Filters\n                </button>\n              )}\n            </div>\n          )}\n        </div>\n      </div>\n    );\n  }\n\n  // Processing UI View\n  return (\n    <div className=\"space-y-6\">\n      {/* Header with Back Button */}\n      <div className=\"bg-gradient-to-r from-primary to-navy-700 rounded-lg p-6 text-white shadow-lg\">\n        <button\n          onClick={handleBackToList}\n          className=\"flex items-center text-primary-light hover:text-white mb-3 transition-colors\"\n        >\n          <ArrowLeft className=\"h-5 w-5 mr-2\" />\n          Back to Patient List\n        </button>\n        <h1 className=\"text-2xl font-bold\">NeuroSense - Algorithm 1 Data Processor</h1>\n        <p className=\"text-primary-light mt-2\">\n          Processing for: <span className=\"font-semibold\">{getPatientName(selectedPatient)}</span> | {selectedPatient?.clinicName}\n        </p>\n      </div>\n\n      {/* Main Content Grid */}\n      <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-6\">\n        {/* Left Panel - QEEG Data Input */}\n        <div className=\"bg-white dark:bg-gray-800 rounded-lg shadow-sm border border-gray-200 dark:border-gray-700 p-6\">\n          <h2 className=\"text-lg font-semibold text-gray-900 dark:text-white mb-4\">\n            QEEG Data Input (Pages 13 & 24)\n          </h2>\n\n          {/* Eyes Open Upload */}\n          <div className=\"mb-6\">\n            <label className=\"block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2\">\n              Page 13 (EO - Eyes Open)\n            </label>\n            <div className=\"relative border-2 border-dashed border-gray-300 dark:border-gray-600 rounded-lg p-6 text-center hover:border-primary dark:hover:border-primary-light transition-colors\">\n              <input\n                type=\"file\"\n                accept=\".csv,.txt,.dat,.pdf\"\n                onChange={(e) => handleFileUpload('eo', e)}\n                className=\"absolute inset-0 w-full h-full opacity-0 cursor-pointer\"\n              />\n              <Upload className=\"h-12 w-12 text-gray-400 dark:text-gray-500 mx-auto mb-2\" />\n              <p className=\"text-sm text-gray-600 dark:text-gray-400\">\n                {eyesOpenFile ? eyesOpenFile.name : 'Drag & Drop or Click to Upload'}\n              </p>\n              {eyesOpenFile && (\n                <CheckCircle className=\"h-6 w-6 text-green-500 mx-auto mt-2\" />\n              )}\n            </div>\n          </div>\n\n          {/* Eyes Closed Upload */}\n          <div className=\"mb-6\">\n            <label className=\"block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2\">\n              Page 24 (EC - Eyes Closed)\n            </label>\n            <div className=\"relative border-2 border-dashed border-gray-300 dark:border-gray-600 rounded-lg p-6 text-center hover:border-primary dark:hover:border-primary-light transition-colors\">\n              <input\n                type=\"file\"\n                accept=\".csv,.txt,.dat,.pdf\"\n                onChange={(e) => handleFileUpload('ec', e)}\n                className=\"absolute inset-0 w-full h-full opacity-0 cursor-pointer\"\n              />\n              <Upload className=\"h-12 w-12 text-gray-400 dark:text-gray-500 mx-auto mb-2\" />\n              <p className=\"text-sm text-gray-600 dark:text-gray-400\">\n                {eyesClosedFile ? eyesClosedFile.name : 'Drag & Drop or Click to Upload'}\n              </p>\n              {eyesClosedFile && (\n                <CheckCircle className=\"h-6 w-6 text-green-500 mx-auto mt-2\" />\n              )}\n            </div>\n          </div>\n\n          {/* Data Loaded Progress */}\n          <div>\n            <label className=\"block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2\">\n              Data Loaded\n            </label>\n            <div className=\"w-full bg-gray-200 dark:bg-gray-700 rounded-full h-2.5\">\n              <div\n                className=\"bg-green-500 h-2.5 rounded-full transition-all duration-300\"\n                style={{ width: `${eyesOpenFile && eyesClosedFile ? 100 : eyesOpenFile || eyesClosedFile ? 50 : 0}%` }}\n              ></div>\n            </div>\n          </div>\n        </div>\n\n        {/* Middle Panel - Algorithm Processing */}\n        <div className=\"bg-white dark:bg-gray-800 rounded-lg shadow-sm border border-gray-200 dark:border-gray-700 p-6\">\n          <h2 className=\"text-lg font-semibold text-gray-900 dark:text-white mb-4\">\n            Algorithm 1 Processing\n          </h2>\n\n          {/* Execute Button */}\n          <button\n            onClick={handleExecuteCalculation}\n            disabled={!eyesOpenFile || !eyesClosedFile || isProcessing}\n            className={`w-full mb-6 py-3 px-4 rounded-lg font-medium flex items-center justify-center space-x-2 transition-colors shadow-md ${\n              eyesOpenFile && eyesClosedFile && !isProcessing\n                ? 'bg-primary hover:bg-navy-700 text-white'\n                : 'bg-gray-300 dark:bg-gray-600 text-gray-500 dark:text-gray-400 cursor-not-allowed'\n            }`}\n          >\n            <Play className=\"h-5 w-5\" />\n            <span>Execute Calculation</span>\n          </button>\n\n          {/* Processing Animation */}\n          {isProcessing && (\n            <div className=\"bg-gradient-to-r from-primary to-navy-700 rounded-lg p-6 text-center mb-6 shadow-lg\">\n              <div className=\"relative inline-block\">\n                <Activity className=\"h-16 w-16 text-white animate-pulse\" />\n                <div className=\"absolute inset-0 flex items-center justify-center\">\n                  <div className=\"w-20 h-20 border-4 border-white/30 border-t-white rounded-full animate-spin\"></div>\n                </div>\n              </div>\n              <p className=\"text-white font-medium mt-4\">Processing...</p>\n              <p className=\"text-primary-light text-sm\">{consoleLog.length} actions done</p>\n            </div>\n          )}\n\n          {/* Processing Complete */}\n          {processingComplete && (\n            <div className=\"bg-green-50 dark:bg-green-900/20 border border-green-200 dark:border-green-800 rounded-lg p-4 text-center mb-6\">\n              <CheckCircle className=\"h-12 w-12 text-green-500 mx-auto mb-2\" />\n              <p className=\"text-green-800 dark:text-green-400 font-medium\">Processing Complete!</p>\n            </div>\n          )}\n\n          {/* Console */}\n          <div className=\"bg-gray-900 dark:bg-black rounded-lg p-4 min-h-[200px] max-h-[300px] overflow-y-auto\">\n            <div className=\"flex items-center justify-between mb-2 pb-2 border-b border-gray-700\">\n              <h3 className=\"text-sm font-medium text-gray-300\">Console</h3>\n              <button\n                onClick={() => setConsoleLog([])}\n                className=\"text-xs text-gray-400 hover:text-gray-200\"\n              >\n                Clear\n              </button>\n            </div>\n            <div className=\"space-y-1 font-mono text-xs\">\n              {consoleLog.length > 0 ? (\n                consoleLog.map((log, index) => (\n                  <div key={index} className=\"text-green-400\">\n                    &gt; {log}\n                  </div>\n                ))\n              ) : (\n                <div className=\"text-gray-500 italic\">Console output will appear here...</div>\n              )}\n            </div>\n          </div>\n        </div>\n\n        {/* Right Panel - Final 7 Parameter Scores */}\n        <div className=\"bg-white dark:bg-gray-800 rounded-lg shadow-sm border border-gray-200 dark:border-gray-700 p-6\">\n          <h2 className=\"text-lg font-semibold text-gray-900 dark:text-white mb-4\">\n            Final 7 Parameter Scores\n          </h2>\n\n          {results ? (\n            <>\n              <div className=\"space-y-4 mb-6\">\n                {results.map((result, index) => (\n                  <div key={index} className=\"border border-gray-200 dark:border-gray-700 rounded-lg p-3\">\n                    {/* Main Parameter */}\n                    <div className=\"flex items-center justify-between mb-2\">\n                      <span className=\"text-sm font-semibold text-gray-800 dark:text-gray-200\">\n                        {result.parameter}\n                      </span>\n                      <div className=\"flex items-center space-x-3\">\n                        <span className={`text-base font-bold ${getStatusColor(result.rawScore)}`}>\n                          {result.rawScore}\n                        </span>\n                        <span className={`text-xs px-2.5 py-1 rounded-full font-medium ${getStatusBgColor(result.rawScore)}`}>\n                          {result.status}\n                        </span>\n                      </div>\n                    </div>\n\n                    {/* Progress Bar */}\n                    <div className=\"flex-1 bg-gray-200 dark:bg-gray-700 rounded-full h-2 mb-3\">\n                      <div\n                        className={`h-2 rounded-full ${getProgressBarColor(result.rawScore)}`}\n                        style={{ width: `${result.score}%` }}\n                      ></div>\n                    </div>\n\n                    {/* Sub-Parameters */}\n                    {result.metrics && result.metrics.length > 0 && (\n                      <div className=\"mt-3 pt-3 border-t border-gray-200 dark:border-gray-700\">\n                        <div className=\"text-xs font-medium text-gray-600 dark:text-gray-400 mb-2\">\n                          Sub-Parameters:\n                        </div>\n                        <div className=\"space-y-2\">\n                          {result.metrics.map((metric, mIndex) => (\n                            <div key={mIndex} className=\"flex items-center justify-between text-xs pl-2\">\n                              <span className=\"text-gray-600 dark:text-gray-400 flex-1\">\n                                {metric.name}\n                              </span>\n                              <div className=\"flex items-center space-x-2\">\n                                {metric.score === 1 ? (\n                                  <CheckCircle className=\"h-3.5 w-3.5 text-green-500\" />\n                                ) : (\n                                  <X className=\"h-3.5 w-3.5 text-red-500\" />\n                                )}\n                                <span className={`font-medium ${metric.score === 1 ? 'text-green-600 dark:text-green-400' : 'text-red-600 dark:text-red-400'}`}>\n                                  {metric.score}/1\n                                </span>\n                              </div>\n                            </div>\n                          ))}\n                        </div>\n                      </div>\n                    )}\n                  </div>\n                ))}\n              </div>\n\n              {/* Action Buttons */}\n              <div className=\"space-y-3\">\n                {/* Save and Download PDF Button */}\n                <button\n                  onClick={handleSaveResults}\n                  disabled={isSaving || isSaved}\n                  className={`w-full py-3 px-4 rounded-lg font-medium flex items-center justify-center space-x-2 transition-colors shadow-md ${\n                    isSaved\n                      ? 'bg-green-100 dark:bg-green-900/30 text-green-700 dark:text-green-400 cursor-not-allowed'\n                      : isSaving\n                      ? 'bg-blue-400 text-white cursor-wait'\n                      : 'bg-primary hover:bg-navy-700 text-white'\n                  }`}\n                >\n                  {isSaving ? (\n                    <>\n                      <Activity className=\"h-5 w-5 animate-spin\" />\n                      <span>Saving...</span>\n                    </>\n                  ) : isSaved ? (\n                    <>\n                      <CheckCircle className=\"h-5 w-5\" />\n                      <span>Saved ‚úì</span>\n                    </>\n                  ) : (\n                    <>\n                      <Download className=\"h-5 w-5\" />\n                      <span>Save and Download PDF</span>\n                    </>\n                  )}\n                </button>\n\n                {/* Export CSV Button */}\n                <button\n                  onClick={handleExportResults}\n                  className=\"w-full bg-green-600 hover:bg-green-700 text-white py-3 px-4 rounded-lg font-medium flex items-center justify-center space-x-2 transition-colors shadow-md\"\n                >\n                  <Download className=\"h-5 w-5\" />\n                  <span>Export CSV</span>\n                </button>\n\n                {/* Single Download PDF Button */}\n                {pdfUrl ? (\n                  <button\n                    onClick={handleDownloadPDF}\n                    className=\"w-full bg-blue-600 hover:bg-blue-700 text-white py-3 px-4 rounded-lg font-medium flex items-center justify-center space-x-2 transition-colors shadow-md\"\n                  >\n                    <Download className=\"h-5 w-5\" />\n                    <span>Download PDF Report</span>\n                  </button>\n                ) : (\n                  <div className=\"w-full bg-gray-100 dark:bg-gray-700 border-2 border-dashed border-gray-300 dark:border-gray-600 rounded-lg py-3 px-4 text-center\">\n                    <FileText className=\"h-5 w-5 text-gray-400 mx-auto mb-2\" />\n                    <p className=\"text-sm text-gray-600 dark:text-gray-400\">\n                      PDF will be generated automatically after processing\n                    </p>\n                  </div>\n                )}\n              </div>\n            </>\n          ) : (\n            <div className=\"flex flex-col items-center justify-center py-12 text-center\">\n              <FileText className=\"h-16 w-16 text-gray-400 dark:text-gray-500 mb-4\" />\n              <p className=\"text-sm text-gray-600 dark:text-gray-400\">\n                Upload data files and execute calculation to see results\n              </p>\n            </div>\n          )}\n        </div>\n      </div>\n\n      {/* Processing History */}\n      {selectedPatient && processingHistory.length > 0 && (\n        <div className=\"bg-white dark:bg-gray-800 rounded-lg shadow-sm border border-gray-200 dark:border-gray-700 p-6\">\n          <div className=\"flex items-center justify-between mb-4\">\n            <h2 className=\"text-lg font-semibold text-gray-900 dark:text-white flex items-center\">\n              <History className=\"h-5 w-5 mr-2\" />\n              Processing History for {getPatientName(selectedPatient)}\n            </h2>\n            <button\n              onClick={async () => {\n                console.log('üîÑ Manual sync triggered...');\n                toast.loading('Syncing PDFs from Supabase...', { id: 'sync-pdfs' });\n\n                try {\n                  // Force reload from database and sync\n                  await loadProcessingHistory(selectedPatient.id);\n\n                  // Count how many PDFs were found\n                  const results = await DatabaseService.get('algorithmResults');\n                  const patientResults = results.filter(r => r.patientId === selectedPatient.id);\n                  const pdfCount = patientResults.filter(r => r.pdfUrl).length;\n                  const totalCount = patientResults.length;\n\n                  toast.success(`‚úÖ Synced! ${pdfCount}/${totalCount} PDFs available`, { id: 'sync-pdfs' });\n                  console.log(`‚úÖ Sync complete: ${pdfCount}/${totalCount} records have PDFs`);\n                } catch (error) {\n                  console.error('‚ùå Sync failed:', error);\n                  toast.error('Failed to sync PDFs', { id: 'sync-pdfs' });\n                }\n              }}\n              className=\"px-3 py-1.5 text-xs bg-blue-600 hover:bg-blue-700 text-white rounded-lg transition-colors flex items-center space-x-1\"\n              title=\"Fetch PDFs from Supabase bucket and update database\"\n            >\n              <Download className=\"h-3 w-3\" />\n              <span>Sync PDFs</span>\n            </button>\n          </div>\n          <div className=\"space-y-3\">\n            {processingHistory.map((record, index) => (\n              <div\n                key={record.id}\n                className=\"border border-gray-200 dark:border-gray-700 rounded-lg p-4 hover:bg-gray-50 dark:hover:bg-gray-700/50 transition-colors\"\n              >\n                <div className=\"flex items-center justify-between\">\n                  <div className=\"flex-1\">\n                    <div className=\"flex items-center space-x-2 mb-2\">\n                      <Calendar className=\"h-4 w-4 text-primary\" />\n                      <span className=\"text-sm font-medium text-gray-900 dark:text-white\">\n                        {new Date(record.processedAt).toLocaleDateString('en-US', {\n                          year: 'numeric',\n                          month: 'short',\n                          day: 'numeric',\n                          hour: '2-digit',\n                          minute: '2-digit'\n                        })}\n                      </span>\n                      {/* PDF Status Badge */}\n                      {record.pdfUrl ? (\n                        <span className=\"px-2 py-0.5 text-xs bg-green-100 text-green-700 dark:bg-green-900/30 dark:text-green-400 rounded-full flex items-center space-x-1\">\n                          <CheckCircle className=\"h-3 w-3\" />\n                          <span>PDF Available</span>\n                        </span>\n                      ) : (\n                        <span className=\"px-2 py-0.5 text-xs bg-gray-100 text-gray-600 dark:bg-gray-700 dark:text-gray-400 rounded-full\">\n                          No PDF\n                        </span>\n                      )}\n                    </div>\n                    <div className=\"text-xs text-gray-600 dark:text-gray-400 space-y-1 mb-3\">\n                      <p>üìÅ Files: {record.eyesOpenFile}, {record.eyesClosedFile}</p>\n                      <p>üë§ Processed by: {record.processedBy}</p>\n                      {record.pdfUrl && (\n                        <p className=\"text-green-600 dark:text-green-400\">\n                          üìÑ PDF: {record.pdfUrl.startsWith('http') ? 'Supabase ‚úì' : 'Local ‚úì'}\n                        </p>\n                      )}\n                      {!record.pdfUrl && (\n                        <p className=\"text-red-600 dark:text-red-400\">üìÑ PDF: Not available</p>\n                      )}\n                    </div>\n\n                    {/* Quick Summary of Results */}\n                    {record.results && record.results.length > 0 && (\n                      <div className=\"mt-3 grid grid-cols-2 gap-2\">\n                        {record.results.slice(0, 4).map((result, idx) => (\n                          <div key={idx} className=\"text-xs bg-gray-50 dark:bg-gray-700 rounded p-2\">\n                            <span className=\"text-gray-600 dark:text-gray-400\">{result.parameter}:</span>\n                            <span className={`ml-2 font-semibold ${getStatusColor(result.rawScore)}`}>\n                              {result.rawScore}\n                            </span>\n                          </div>\n                        ))}\n                      </div>\n                    )}\n                  </div>\n                  <div className=\"flex flex-col space-y-2\">\n                    {/* View Full Results Button */}\n                    <button\n                      onClick={() => {\n                        setResults(record.results);\n                        setProcessingComplete(true);\n                        setIsSaved(true);\n                        // Set PDF URL if available\n                        if (record.pdfUrl) {\n                          setPdfUrl(record.pdfUrl);\n                        }\n                        toast.success('Previous results loaded');\n                      }}\n                      className=\"px-3 py-2 text-sm bg-primary hover:bg-navy-700 text-white rounded-lg transition-colors flex items-center justify-center space-x-1\"\n                    >\n                      <FileText className=\"h-4 w-4\" />\n                      <span>View Results</span>\n                    </button>\n\n                    {/* Download PDF Button - Always visible */}\n                    <button\n                      onClick={async () => {\n                        if (!record.pdfUrl) {\n                          toast.error('No PDF available for this record');\n                          console.log('‚ùå No PDF URL in record:', record);\n                          return;\n                        }\n\n                        console.log('üì• Downloading PDF from record:', {\n                          processedAt: record.processedAt,\n                          pdfUrl: record.pdfUrl\n                        });\n\n                        try {\n                          toast.loading('Downloading PDF...', { id: 'history-download' });\n\n                          // Construct full URL (works with both local and Supabase URLs)\n                          const apiUrl = import.meta.env.VITE_API_URL || 'http://localhost:3001/api';\n                          const backendBaseUrl = apiUrl.replace('/api', '');\n                          const fullPdfUrl = record.pdfUrl.startsWith('http') ? record.pdfUrl : `${backendBaseUrl}${record.pdfUrl}`;\n\n                          console.log('üì• Downloading from:', fullPdfUrl);\n\n                          // Fetch the PDF file\n                          const response = await fetch(fullPdfUrl);\n                          if (!response.ok) throw new Error('Failed to fetch PDF');\n\n                          // Convert to blob\n                          const blob = await response.blob();\n\n                          // Create download link\n                          const downloadUrl = window.URL.createObjectURL(blob);\n                          const link = document.createElement('a');\n                          link.href = downloadUrl;\n                          link.download = record.pdfUrl.split('/').pop() || 'neurosense-report.pdf';\n\n                          // Trigger download\n                          document.body.appendChild(link);\n                          link.click();\n\n                          // Cleanup\n                          document.body.removeChild(link);\n                          window.URL.revokeObjectURL(downloadUrl);\n\n                          toast.success('PDF downloaded successfully!', { id: 'history-download' });\n                        } catch (error) {\n                          console.error('Download error:', error);\n                          toast.error('Failed to download PDF', { id: 'history-download' });\n                        }\n                      }}\n                      disabled={!record.pdfUrl}\n                      className={`px-3 py-2 text-sm rounded-lg transition-colors flex items-center justify-center space-x-1 ${\n                        record.pdfUrl\n                          ? 'bg-blue-600 hover:bg-blue-700 text-white cursor-pointer'\n                          : 'bg-gray-300 dark:bg-gray-600 text-gray-500 dark:text-gray-400 cursor-not-allowed'\n                      }`}\n                      title={record.pdfUrl ? 'Download PDF Report' : 'No PDF available'}\n                    >\n                      <Download className=\"h-4 w-4\" />\n                      <span>Download PDF</span>\n                    </button>\n                  </div>\n                </div>\n\n                {/* Expandable Details */}\n                {record.results && record.results.length > 4 && (\n                  <div className=\"mt-3 pt-3 border-t border-gray-200 dark:border-gray-700 text-xs\">\n                    <div className=\"grid grid-cols-3 gap-2\">\n                      {record.results.slice(4).map((result, idx) => (\n                        <div key={idx} className=\"flex justify-between\">\n                          <span className=\"text-gray-600 dark:text-gray-400\">{result.parameter}:</span>\n                          <span className=\"font-semibold\">{result.rawScore}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n              </div>\n            ))}\n          </div>\n        </div>\n      )}\n\n      {/* Info Section */}\n      <div className=\"bg-accent-light dark:bg-primary/20 border border-primary-light dark:border-primary rounded-lg p-4 shadow-sm\">\n        <h3 className=\"text-sm font-medium text-primary dark:text-primary-light mb-2\">\n          About Algorithm 1 Processing\n        </h3>\n        <p className=\"text-sm text-navy-800 dark:text-gray-300\">\n          This processor analyzes QEEG data files (Eyes Open and Eyes Closed) and generates 7 key parameters using proprietary\n          binary scoring logic. The algorithm evaluates brain activity patterns to assess cognitive and emotional health markers.\n        </p>\n      </div>\n    </div>\n  );\n};\n\nexport default AlgorithmDataProcessor;\n","numLines":1591,"startLine":1,"totalLines":1591}}}
{"parentUuid":"afe65df8-2e9f-4937-9b9b-05babd3a25b1","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01Jt1uyTSGX9RCCWk34heJtA","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me search for sample QEEG reports to understand the data structures better:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":49541,"cache_read_input_tokens":10627,"cache_creation":{"ephemeral_5m_input_tokens":49541,"ephemeral_1h_input_tokens":0},"output_tokens":147,"service_tier":"standard"}},"requestId":"req_011CVhb3hFH57jRUW1gqakcr","type":"assistant","uuid":"95bfcb0a-36cb-44af-900a-cf8d30fc7d74","timestamp":"2025-12-02T09:01:07.061Z"}
{"parentUuid":"95bfcb0a-36cb-44af-900a-cf8d30fc7d74","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01Jt1uyTSGX9RCCWk34heJtA","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01RTum7VzigM7kKZhnUDMSpR","name":"Glob","input":{"pattern":"**/*sample*.{pdf,json,js}"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":49541,"cache_read_input_tokens":10627,"cache_creation":{"ephemeral_5m_input_tokens":49541,"ephemeral_1h_input_tokens":0},"output_tokens":147,"service_tier":"standard"}},"requestId":"req_011CVhb3hFH57jRUW1gqakcr","type":"assistant","uuid":"b3e792a1-63d3-40ab-b0c6-2db838331ad5","timestamp":"2025-12-02T09:01:07.887Z"}
{"parentUuid":"b3e792a1-63d3-40ab-b0c6-2db838331ad5","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01Jt1uyTSGX9RCCWk34heJtA","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01MfLkhxRJ58ptsvDEP8jFqr","name":"Grep","input":{"pattern":"Z-score|z-score|zscore","output_mode":"files_with_matches"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":49541,"cache_read_input_tokens":10627,"cache_creation":{"ephemeral_5m_input_tokens":49541,"ephemeral_1h_input_tokens":0},"output_tokens":147,"service_tier":"standard"}},"requestId":"req_011CVhb3hFH57jRUW1gqakcr","type":"assistant","uuid":"bce4f460-0723-4481-9969-5f8df16a6bce","timestamp":"2025-12-02T09:01:08.946Z"}
{"parentUuid":"bce4f460-0723-4481-9969-5f8df16a6bce","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01MfLkhxRJ58ptsvDEP8jFqr","type":"tool_result","content":"Found 1 file limit: 20, offset: 0\nserver\\services\\aiPdfGenerator.js"}]},"uuid":"28aa9387-8307-4977-a642-0f36deccd4c1","timestamp":"2025-12-02T09:01:13.451Z","toolUseResult":{"mode":"files_with_matches","filenames":["server\\services\\aiPdfGenerator.js"],"numFiles":1,"appliedLimit":20}}
{"parentUuid":"28aa9387-8307-4977-a642-0f36deccd4c1","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01RTum7VzigM7kKZhnUDMSpR","type":"tool_result","content":"D:\\Todays\\Neuro360\\node_modules\\lodash\\_arraySample.js\nD:\\Todays\\Neuro360\\node_modules\\smtpjs\\node_modules\\lodash\\_arraySample.js\nD:\\Todays\\Neuro360\\node_modules\\lodash\\_arraySampleSize.js\nD:\\Todays\\Neuro360\\node_modules\\smtpjs\\node_modules\\lodash\\_arraySampleSize.js\nD:\\Todays\\Neuro360\\node_modules\\inquirer\\node_modules\\lodash\\collection\\sample.js\nD:\\Todays\\Neuro360\\node_modules\\smtpjs\\node_modules\\lodash\\_baseSample.js\nD:\\Todays\\Neuro360\\node_modules\\lodash\\_baseSample.js\nD:\\Todays\\Neuro360\\node_modules\\lodash\\_baseSampleSize.js\nD:\\Todays\\Neuro360\\node_modules\\smtpjs\\node_modules\\lodash\\_baseSampleSize.js\nD:\\Todays\\Neuro360\\node_modules\\lodash\\sample.js\nD:\\Todays\\Neuro360\\node_modules\\lodash\\fp\\sampleSize.js\nD:\\Todays\\Neuro360\\node_modules\\lodash\\fp\\sample.js\nD:\\Todays\\Neuro360\\node_modules\\smtpjs\\node_modules\\lodash\\sampleSize.js\nD:\\Todays\\Neuro360\\node_modules\\smtpjs\\node_modules\\lodash\\sample.js\nD:\\Todays\\Neuro360\\node_modules\\smtpjs\\node_modules\\lodash\\fp\\sample.js\nD:\\Todays\\Neuro360\\node_modules\\smtpjs\\node_modules\\lodash\\fp\\sampleSize.js\nD:\\Todays\\Neuro360\\node_modules\\lodash\\sampleSize.js\nD:\\Todays\\Neuro360\\node_modules\\rxjs\\dist\\cjs\\internal\\operators\\sample.js\nD:\\Todays\\Neuro360\\node_modules\\rxjs\\dist\\esm5\\internal\\operators\\sampleTime.js\nD:\\Todays\\Neuro360\\node_modules\\rxjs\\dist\\esm5\\internal\\operators\\sample.js\nD:\\Todays\\Neuro360\\node_modules\\rxjs\\dist\\esm\\internal\\operators\\sampleTime.js\nD:\\Todays\\Neuro360\\node_modules\\rxjs\\dist\\esm\\internal\\operators\\sample.js\nD:\\Todays\\Neuro360\\node_modules\\rxjs\\dist\\cjs\\internal\\operators\\sampleTime.js\nD:\\Todays\\Neuro360\\server\\uploads\\sample-neurosense-report.pdf"}]},"uuid":"25bff9bc-7952-4e15-af8d-33e5797f532b","timestamp":"2025-12-02T09:01:13.743Z","toolUseResult":{"filenames":["D:\\Todays\\Neuro360\\node_modules\\lodash\\_arraySample.js","D:\\Todays\\Neuro360\\node_modules\\smtpjs\\node_modules\\lodash\\_arraySample.js","D:\\Todays\\Neuro360\\node_modules\\lodash\\_arraySampleSize.js","D:\\Todays\\Neuro360\\node_modules\\smtpjs\\node_modules\\lodash\\_arraySampleSize.js","D:\\Todays\\Neuro360\\node_modules\\inquirer\\node_modules\\lodash\\collection\\sample.js","D:\\Todays\\Neuro360\\node_modules\\smtpjs\\node_modules\\lodash\\_baseSample.js","D:\\Todays\\Neuro360\\node_modules\\lodash\\_baseSample.js","D:\\Todays\\Neuro360\\node_modules\\lodash\\_baseSampleSize.js","D:\\Todays\\Neuro360\\node_modules\\smtpjs\\node_modules\\lodash\\_baseSampleSize.js","D:\\Todays\\Neuro360\\node_modules\\lodash\\sample.js","D:\\Todays\\Neuro360\\node_modules\\lodash\\fp\\sampleSize.js","D:\\Todays\\Neuro360\\node_modules\\lodash\\fp\\sample.js","D:\\Todays\\Neuro360\\node_modules\\smtpjs\\node_modules\\lodash\\sampleSize.js","D:\\Todays\\Neuro360\\node_modules\\smtpjs\\node_modules\\lodash\\sample.js","D:\\Todays\\Neuro360\\node_modules\\smtpjs\\node_modules\\lodash\\fp\\sample.js","D:\\Todays\\Neuro360\\node_modules\\smtpjs\\node_modules\\lodash\\fp\\sampleSize.js","D:\\Todays\\Neuro360\\node_modules\\lodash\\sampleSize.js","D:\\Todays\\Neuro360\\node_modules\\rxjs\\dist\\cjs\\internal\\operators\\sample.js","D:\\Todays\\Neuro360\\node_modules\\rxjs\\dist\\esm5\\internal\\operators\\sampleTime.js","D:\\Todays\\Neuro360\\node_modules\\rxjs\\dist\\esm5\\internal\\operators\\sample.js","D:\\Todays\\Neuro360\\node_modules\\rxjs\\dist\\esm\\internal\\operators\\sampleTime.js","D:\\Todays\\Neuro360\\node_modules\\rxjs\\dist\\esm\\internal\\operators\\sample.js","D:\\Todays\\Neuro360\\node_modules\\rxjs\\dist\\cjs\\internal\\operators\\sampleTime.js","D:\\Todays\\Neuro360\\server\\uploads\\sample-neurosense-report.pdf"],"durationMs":581,"numFiles":24,"truncated":false}}
{"parentUuid":"25bff9bc-7952-4e15-af8d-33e5797f532b","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01VxXiH2bfkR1uKoiiWvD14Y","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_015WvxyLrjWB3LiydSjy4s83","name":"Read","input":{"file_path":"D:\\Todays\\Neuro360\\server\\services\\aiPdfGenerator.js"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":56,"cache_creation_input_tokens":1204,"cache_read_input_tokens":60168,"cache_creation":{"ephemeral_5m_input_tokens":1204,"ephemeral_1h_input_tokens":0},"output_tokens":73,"service_tier":"standard"}},"requestId":"req_011CVhb5ATAoYgfrKT4go8LN","type":"assistant","uuid":"be946904-ff72-4b45-b353-c31043f7112d","timestamp":"2025-12-02T09:01:27.277Z"}
{"parentUuid":"be946904-ff72-4b45-b353-c31043f7112d","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_015WvxyLrjWB3LiydSjy4s83","type":"tool_result","content":"     1‚Üí/**\n     2‚Üí * AI-Powered PDF Report Generator\n     3‚Üí * Uses OpenAI to generate comprehensive, modern QEEG reports\n     4‚Üí * Based on the enhanced prompt specifications\n     5‚Üí */\n     6‚Üí\n     7‚Üíconst OpenAI = require('openai');\n     8‚Üíconst fs = require('fs');\n     9‚Üíconst path = require('path');\n    10‚Üí\n    11‚Üí// Initialize OpenAI client\n    12‚Üíconst openai = new OpenAI({\n    13‚Üí  apiKey: process.env.OPENAI_API_KEY\n    14‚Üí});\n    15‚Üí\n    16‚Üíclass AIPdfGenerator {\n    17‚Üí  constructor(patientData, algorithmResults, qeegData) {\n    18‚Üí    this.patientData = patientData;\n    19‚Üí    this.algorithmResults = algorithmResults;\n    20‚Üí    this.qeegData = qeegData;\n    21‚Üí  }\n    22‚Üí\n    23‚Üí  /**\n    24‚Üí   * Generate the NeuroSense report system prompt\n    25‚Üí   * Senior neurotech data analyst specialized in QEEG analysis and patient-friendly reporting\n    26‚Üí   */\n    27‚Üí  getSystemPrompt() {\n    28‚Üí    return `You are a senior neurotech data analyst and report generator for the NeuroSense platform. Your task is to read the uploaded QEEG patient data and generate the final NeuroSense report in PDF-ready formatted content.\n    29‚Üí\n    30‚Üí## GOAL\n    31‚ÜíInput: QEEG report data with Z-score tables and formulas\n    32‚ÜíOutput: A final NeuroSense report written in clean formatted text containing:\n    33‚Üí- Patient details\n    34‚Üí- 7 parameter score cards (with score, bucket, explanation)\n    35‚Üí- Brain-type compact pattern summary line\n    36‚Üí- Key highlights section\n    37‚Üí- Individual detailed narrative explanations\n    38‚Üí- Recommendations / coaching focus\n    39‚Üí- Final conclusion in patient-friendly language\n    40‚Üí\n    41‚Üí## IMPORTANT GUIDELINES\n    42‚Üí‚úì Use only data found inside the patient data provided\n    43‚Üí‚úì Follow the formulas and thresholds listed\n    44‚Üí‚úì DO NOT return JSON - return formatted text ready for PDF\n    45‚Üí‚úì DO NOT give any medical diagnosis\n    46‚Üí‚úì Write in simple language for patients\n    47‚Üí‚úì If any metric is missing or unclear, mention it politely instead of guessing\n    48‚Üí\n    49‚Üí## CALCULATIONS\n    50‚ÜíExtract the following metrics from the QEEG tables and compute them exactly using formulas:\n    51‚Üí\n    52‚Üí### 1. FocusThetaPercent\n    53‚Üí- EO Relative Power: Theta % at Fz and Cz\n    54‚Üí- FocusThetaPercent = average of the two\n    55‚Üí- Normal < 20 percent\n    56‚Üí\n    57‚Üí### 2. ThetaBetaRatio\n    58‚Üí- EO Absolute Power: Theta and Beta at Fz and Cz\n    59‚Üí- Ratio per site = Theta / Beta\n    60‚Üí- ThetaBetaRatio = average of both\n    61‚Üí- < 1.5 excellent, 1.5‚Äì2.5 mild drift, > 3.0 strong mind wandering\n    62‚Üí\n    63‚Üí### 3. ArousalScore\n    64‚Üí- EO Absolute Power: hiBeta and Beta at Fz and Cz\n    65‚Üí- Ratio = hiBeta / Beta for each site\n    66‚Üí- ArousalScore = average of both\n    67‚Üí- < 1.0 balanced, 1.0‚Äì1.2 slightly raised, > 1.2 elevated\n    68‚Üí\n    69‚Üí### 4. ExcessiveDeltaIndicator\n    70‚Üí- EO Relative Power: Average Delta % at Fz, C3, Cz, C4, P3, Pz, P4\n    71‚Üí- < 70 percent normal\n    72‚Üí\n    73‚Üí### 5. RelaxationScore_Pz\n    74‚Üí- EC Relative Power at Pz\n    75‚Üí- Alpha % / Beta %\n    76‚Üí- 10 is healthy\n    77‚Üí\n    78‚Üí### 6. AlphaModulation_Pz\n    79‚Üí- ((Alpha_EC_Pz ‚Äì Alpha_EO_Pz) / Alpha_EC_Pz) √ó 100\n    80‚Üí- 30 percent healthy\n    81‚Üí\n    82‚Üí### 7. PeakAlphaFreq_Pz\n    83‚Üí- EC Alpha Peak table ‚Äî highest posterior alpha value\n    84‚Üí- 9 Hz normal\n    85‚Üí\n    86‚Üí### 8. AlphaThetaRatio_Fz_Cz_Pz\n    87‚Üí- EC Absolute Power Alpha / Theta for each site\n    88‚Üí- \"Normal pattern\": Fz > Cz > Pz\n    89‚Üí\n    90‚Üí### 9. FrontalAlphaAsymmetry\n    91‚Üí- EC Absolute Power Alpha at F3 and F4\n    92‚Üí- Ratio = F4 / F3\n    93‚Üí- < 1 is balanced\n    94‚Üí\n    95‚Üí## PARAMETER SCORING (0‚Äì3)\n    96‚ÜíEach of these 7 parameters gets a score 0‚Äì3 based on formulas:\n    97‚Üí1. Cognition\n    98‚Üí2. Stress\n    99‚Üí3. Focus & Attention\n   100‚Üí4. Burnout & Fatigue\n   101‚Üí5. Emotional Regulation\n   102‚Üí6. Learning\n   103‚Üí7. Creativity\n   104‚Üí\n   105‚ÜíScore to bucket mapping:\n   106‚Üí- 0‚Äì1 = Low\n   107‚Üí- 2 = Medium\n   108‚Üí- 3 = High\n   109‚Üí\n   110‚Üí## BRAIN-TYPE PATTERN LINE\n   111‚ÜíBased on each score convert to L / M / H and format like:\n   112‚ÜíCognition M ¬∑ Stress L ¬∑ Focus L ¬∑ Burnout/Fatigue L ¬∑ Emotional Reg H ¬∑ Learning M ¬∑ Creativity M\n   113‚Üí\n   114‚Üí## FINAL OUTPUT FORMAT (NO JSON)\n   115‚ÜíReturn the report exactly in this structure:\n   116‚Üí\n   117‚Üí==============================\n   118‚ÜíNEUROSENSE BRAIN FUNCTION REPORT\n   119‚Üí\n   120‚ÜíPatient Information\n   121‚ÜíName: <if available>\n   122‚ÜíAge: <if available>\n   123‚ÜíRecording Date: <if available>\n   124‚ÜíNotes: <if available>\n   125‚Üí\n   126‚ÜíBrain-Type Pattern Summary\n   127‚Üí<pattern line with L/M/H letters>\n   128‚Üí<short 2‚Äì4 sentence overview in simple language>\n   129‚Üí\n   130‚ÜíKey Highlights\n   131‚Üí‚Ä¢ <3‚Äì6 bullet points summarizing the patient brain profile>\n   132‚Üí\n   133‚ÜíParameter Score Cards\n   134‚Üí\n   135‚ÜíCognition: <bucket> (Score <0‚Äì3>)\n   136‚ÜíShort status: <1-line summary>\n   137‚ÜíExplanation: <2‚Äì4 sentences explaining pattern and what it means for the patient>\n   138‚Üí\n   139‚ÜíStress: <bucket> (Score <0‚Äì3>)\n   140‚ÜíShort status: <1-line summary>\n   141‚ÜíExplanation: <2‚Äì4 sentences>\n   142‚Üí\n   143‚ÜíFocus & Attention: <bucket> (Score <0‚Äì3>)\n   144‚ÜíShort status: <1-line summary>\n   145‚ÜíExplanation: <2‚Äì4 sentences>\n   146‚Üí\n   147‚ÜíBurnout & Fatigue: <bucket> (...)\n   148‚ÜíEmotional Regulation: <bucket> (...)\n   149‚ÜíLearning: <bucket> (...)\n   150‚ÜíCreativity: <bucket> (...)\n   151‚Üí\n   152‚ÜíDetailed Narrative\n   153‚ÜíA longer plain-language explanation that connects how stress, focus, learning, emotional balance and creativity interact in this person's profile.\n   154‚Üí\n   155‚ÜíCoaching Focus & Next Steps\n   156‚Üí‚Ä¢ <priority #1>\n   157‚Üí‚Ä¢ <priority #2>\n   158‚Üí‚Ä¢ <priority #3>\n   159‚Üí<2 sentences on expected improvement outcome>\n   160‚Üí\n   161‚ÜíEnd Note\n   162‚ÜíA warm positive closing note written for the patient about brain improvement and self-development.\n   163‚Üí\n   164‚Üí==============================`;\n   165‚Üí  }\n   166‚Üí\n   167‚Üí  /**\n   168‚Üí   * Generate user prompt with actual patient data\n   169‚Üí   */\n   170‚Üí  getUserPrompt() {\n   171‚Üí    const parametersText = this.algorithmResults.parameters.map((param, index) => {\n   172‚Üí      const metricsText = param.metrics.map((metric, idx) => {\n   173‚Üí        return `      ${idx + 1}. **${metric.name}**: Score ${metric.score}/1\n   174‚Üí         - Value: ${typeof metric.value === 'object' ? JSON.stringify(metric.value) : metric.value}\n   175‚Üí         - Description: ${metric.description}`;\n   176‚Üí      }).join('\\n');\n   177‚Üí\n   178‚Üí      return `${index + 1}. **${param.name}**: ${param.score}/${param.maxScore} (${param.classification})\n   179‚Üí   Subparameters:\n   180‚Üí${metricsText}`;\n   181‚Üí    }).join('\\n\\n');\n   182‚Üí\n   183‚Üí    return `Generate a comprehensive QEEG Intelligence report for the following patient:\n   184‚Üí\n   185‚Üí## PATIENT INFORMATION:\n   186‚Üí- Name: ${this.patientData.name}\n   187‚Üí- Date of Recording: ${this.patientData.dateOfRecording}\n   188‚Üí- Age: ${this.patientData.age}\n   189‚Üí- Gender: ${this.patientData.gender}\n   190‚Üí- Handedness: ${this.patientData.handedness}\n   191‚Üí- Symptoms: ${this.patientData.symptoms ? this.patientData.symptoms.join(', ') : 'Not specified'}\n   192‚Üí\n   193‚Üí## ALGORITHM RESULTS:\n   194‚ÜíOverall Brain Health Score: ${this.algorithmResults.overallScore}/21\n   195‚Üí\n   196‚Üí### Parameter Scores:\n   197‚Üí${parametersText}\n   198‚Üí\n   199‚Üí## QEEG DATA SUMMARY:\n   200‚Üí### Eyes Closed (EC):\n   201‚Üí- Alpha Peak: ${this.qeegData.EC?.special?.alphaPeak || 'N/A'} Hz\n   202‚Üí- Key Locations: Fz, Cz, Pz\n   203‚Üí- Absolute Power Available: ${this.qeegData.EC?.absolute ? 'Yes' : 'No'}\n   204‚Üí- Relative Power Available: ${this.qeegData.EC?.relative ? 'Yes' : 'No'}\n   205‚Üí\n   206‚Üí### Eyes Open (EO):\n   207‚Üí- Absolute Power Available: ${this.qeegData.EO?.absolute ? 'Yes' : 'No'}\n   208‚Üí- Relative Power Available: ${this.qeegData.EO?.relative ? 'Yes' : 'No'}\n   209‚Üí\n   210‚Üí---\n   211‚Üí\n   212‚ÜíPlease generate a complete, professional QEEG report following the design requirements and structure specified in the system prompt. Include all sections with detailed explanations, health implications, and improvement recommendations for each parameter and subparameter.`;\n   213‚Üí  }\n   214‚Üí\n   215‚Üí  /**\n   216‚Üí   * Generate PDF report using OpenAI\n   217‚Üí   * @param {string} outputPath - Path to save the generated PDF\n   218‚Üí   * @returns {Promise<Object>} Generated report data and metadata\n   219‚Üí   */\n   220‚Üí  async generateReport(outputPath) {\n   221‚Üí    try {\n   222‚Üí      console.log('\\nü§ñ === AI PDF Generation Started ===\\n');\n   223‚Üí      console.log('üë§ Patient:', this.patientData.name);\n   224‚Üí      console.log('üìä Parameters:', this.algorithmResults.parameters.length);\n   225‚Üí      console.log('üéØ Overall Score:', this.algorithmResults.overallScore, '/21');\n   226‚Üí\n   227‚Üí      // Step 1: Generate report content using OpenAI\n   228‚Üí      console.log('\\nüìù Generating report content with AI...');\n   229‚Üí\n   230‚Üí      const response = await openai.chat.completions.create({\n   231‚Üí        model: 'gpt-4-turbo-preview',\n   232‚Üí        messages: [\n   233‚Üí          {\n   234‚Üí            role: 'system',\n   235‚Üí            content: this.getSystemPrompt()\n   236‚Üí          },\n   237‚Üí          {\n   238‚Üí            role: 'user',\n   239‚Üí            content: this.getUserPrompt()\n   240‚Üí          }\n   241‚Üí        ],\n   242‚Üí        temperature: 0.7,\n   243‚Üí        max_tokens: 4000\n   244‚Üí        // Note: No response_format specified - we want plain text, not JSON\n   245‚Üí      });\n   246‚Üí\n   247‚Üí      const reportContent = response.choices[0].message.content;\n   248‚Üí\n   249‚Üí      console.log('‚úÖ AI content generated successfully');\n   250‚Üí      console.log('üìÑ Content length:', reportContent.length, 'characters');\n   251‚Üí\n   252‚Üí      // Step 2: Save report content as plain text\n   253‚Üí      const reportData = {\n   254‚Üí        patientInfo: this.patientData,\n   255‚Üí        algorithmResults: this.algorithmResults,\n   256‚Üí        qeegData: this.qeegData,\n   257‚Üí        aiGeneratedContent: reportContent,\n   258‚Üí        metadata: {\n   259‚Üí          generatedAt: new Date().toISOString(),\n   260‚Üí          generatedBy: 'NeuroSense AI Report Generator',\n   261‚Üí          model: 'gpt-4-turbo-preview',\n   262‚Üí          version: '2.0.0'\n   263‚Üí        }\n   264‚Üí      };\n   265‚Üí\n   266‚Üí      // Save both text and JSON versions\n   267‚Üí      const textOutputPath = outputPath.replace('.pdf', '.txt');\n   268‚Üí      const jsonOutputPath = outputPath.replace('.pdf', '.json');\n   269‚Üí\n   270‚Üí      // Save plain text report\n   271‚Üí      fs.writeFileSync(textOutputPath, reportContent);\n   272‚Üí\n   273‚Üí      // Save structured data with metadata\n   274‚Üí      fs.writeFileSync(jsonOutputPath, JSON.stringify(reportData, null, 2));\n   275‚Üí\n   276‚Üí      console.log('\\n‚úÖ === AI NeuroSense Report Generation Completed ===');\n   277‚Üí      console.log('üìÑ Text Report saved to:', textOutputPath);\n   278‚Üí      console.log('üìÑ Data saved to:', jsonOutputPath);\n   279‚Üí      console.log('üí° Note: Text report is ready for PDF conversion or direct use.\\n');\n   280‚Üí\n   281‚Üí      return {\n   282‚Üí        success: true,\n   283‚Üí        reportData,\n   284‚Üí        reportText: reportContent,\n   285‚Üí        textOutputPath: textOutputPath,\n   286‚Üí        outputPath: jsonOutputPath,\n   287‚Üí        contentLength: reportContent.length,\n   288‚Üí        tokensUsed: response.usage.total_tokens\n   289‚Üí      };\n   290‚Üí\n   291‚Üí    } catch (error) {\n   292‚Üí      console.error('\\n‚ùå === AI PDF Generation Failed ===');\n   293‚Üí      console.error('Error:', error.message);\n   294‚Üí      throw error;\n   295‚Üí    }\n   296‚Üí  }\n   297‚Üí\n   298‚Üí  /**\n   299‚Üí   * Generate sample report for testing\n   300‚Üí   */\n   301‚Üí  static async generateSampleReport() {\n   302‚Üí    const samplePatient = {\n   303‚Üí      name: 'Jane Smith',\n   304‚Üí      dateOfRecording: new Date().toISOString().split('T')[0],\n   305‚Üí      age: 42,\n   306‚Üí      gender: 'Female',\n   307‚Üí      handedness: 'Right',\n   308‚Üí      symptoms: ['Stress', 'Focus Issues', 'Sleep Problems']\n   309‚Üí    };\n   310‚Üí\n   311‚Üí    const sampleResults = {\n   312‚Üí      parameters: [\n   313‚Üí        {\n   314‚Üí          name: 'Cognition',\n   315‚Üí          score: 2,\n   316‚Üí          maxScore: 3,\n   317‚Üí          classification: 'Medium',\n   318‚Üí          metrics: [\n   319‚Üí            { name: 'Focus Score (Theta:Beta)', value: 1.2, score: 1, description: 'Healthy theta:beta ratio indicating good attention' },\n   320‚Üí            { name: 'Alpha Peak', value: 10.3, score: 1, description: 'Strong alpha peak showing good mental relaxation capability' },\n   321‚Üí            { name: 'Alpha:Theta Balance', value: 'Normal', score: 0, description: 'Balanced state between alertness and relaxation' }\n   322‚Üí          ]\n   323‚Üí        },\n   324‚Üí        {\n   325‚Üí          name: 'Stress',\n   326‚Üí          score: 1,\n   327‚Üí          maxScore: 3,\n   328‚Üí          classification: 'Low',\n   329‚Üí          metrics: [\n   330‚Üí            { name: 'Arousal Score', value: 0.8, score: 1, description: 'Low arousal indicating minimal stress' },\n   331‚Üí            { name: 'Relaxation Score', value: 8.5, score: 0, description: 'Moderate relaxation capacity' },\n   332‚Üí            { name: 'Regeneration', value: 35.2, score: 1, description: 'Good alpha modulation for recovery' }\n   333‚Üí          ]\n   334‚Üí        }\n   335‚Üí      ],\n   336‚Üí      overallScore: 14\n   337‚Üí    };\n   338‚Üí\n   339‚Üí    const sampleQEEG = {\n   340‚Üí      EC: {\n   341‚Üí        absolute: { Fz: { Delta: 5.2, Theta: 4.1, Alpha: 8.3, Beta: 6.2, HiBeta: 3.1 } },\n   342‚Üí        relative: { Pz: { Alpha: 45.2 } },\n   343‚Üí        special: { alphaPeak: 10.3, O1: 10.1 }\n   344‚Üí      },\n   345‚Üí      EO: {\n   346‚Üí        absolute: { Fz: { Theta: 3.8, Beta: 3.2, HiBeta: 2.5 } },\n   347‚Üí        relative: { Pz: { Alpha: 28.7 } }\n   348‚Üí      }\n   349‚Üí    };\n   350‚Üí\n   351‚Üí    const generator = new AIPdfGenerator(samplePatient, sampleResults, sampleQEEG);\n   352‚Üí    const outputPath = path.join(__dirname, '../uploads/ai-sample-report.pdf');\n   353‚Üí\n   354‚Üí    return await generator.generateReport(outputPath);\n   355‚Üí  }\n   356‚Üí}\n   357‚Üí\n   358‚Üímodule.exports = AIPdfGenerator;\n   359‚Üí\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"93f1f238-bbbb-4cb5-aff6-cdb1dfe00435","timestamp":"2025-12-02T09:01:29.852Z","toolUseResult":{"type":"text","file":{"filePath":"D:\\Todays\\Neuro360\\server\\services\\aiPdfGenerator.js","content":"/**\n * AI-Powered PDF Report Generator\n * Uses OpenAI to generate comprehensive, modern QEEG reports\n * Based on the enhanced prompt specifications\n */\n\nconst OpenAI = require('openai');\nconst fs = require('fs');\nconst path = require('path');\n\n// Initialize OpenAI client\nconst openai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY\n});\n\nclass AIPdfGenerator {\n  constructor(patientData, algorithmResults, qeegData) {\n    this.patientData = patientData;\n    this.algorithmResults = algorithmResults;\n    this.qeegData = qeegData;\n  }\n\n  /**\n   * Generate the NeuroSense report system prompt\n   * Senior neurotech data analyst specialized in QEEG analysis and patient-friendly reporting\n   */\n  getSystemPrompt() {\n    return `You are a senior neurotech data analyst and report generator for the NeuroSense platform. Your task is to read the uploaded QEEG patient data and generate the final NeuroSense report in PDF-ready formatted content.\n\n## GOAL\nInput: QEEG report data with Z-score tables and formulas\nOutput: A final NeuroSense report written in clean formatted text containing:\n- Patient details\n- 7 parameter score cards (with score, bucket, explanation)\n- Brain-type compact pattern summary line\n- Key highlights section\n- Individual detailed narrative explanations\n- Recommendations / coaching focus\n- Final conclusion in patient-friendly language\n\n## IMPORTANT GUIDELINES\n‚úì Use only data found inside the patient data provided\n‚úì Follow the formulas and thresholds listed\n‚úì DO NOT return JSON - return formatted text ready for PDF\n‚úì DO NOT give any medical diagnosis\n‚úì Write in simple language for patients\n‚úì If any metric is missing or unclear, mention it politely instead of guessing\n\n## CALCULATIONS\nExtract the following metrics from the QEEG tables and compute them exactly using formulas:\n\n### 1. FocusThetaPercent\n- EO Relative Power: Theta % at Fz and Cz\n- FocusThetaPercent = average of the two\n- Normal < 20 percent\n\n### 2. ThetaBetaRatio\n- EO Absolute Power: Theta and Beta at Fz and Cz\n- Ratio per site = Theta / Beta\n- ThetaBetaRatio = average of both\n- < 1.5 excellent, 1.5‚Äì2.5 mild drift, > 3.0 strong mind wandering\n\n### 3. ArousalScore\n- EO Absolute Power: hiBeta and Beta at Fz and Cz\n- Ratio = hiBeta / Beta for each site\n- ArousalScore = average of both\n- < 1.0 balanced, 1.0‚Äì1.2 slightly raised, > 1.2 elevated\n\n### 4. ExcessiveDeltaIndicator\n- EO Relative Power: Average Delta % at Fz, C3, Cz, C4, P3, Pz, P4\n- < 70 percent normal\n\n### 5. RelaxationScore_Pz\n- EC Relative Power at Pz\n- Alpha % / Beta %\n- 10 is healthy\n\n### 6. AlphaModulation_Pz\n- ((Alpha_EC_Pz ‚Äì Alpha_EO_Pz) / Alpha_EC_Pz) √ó 100\n- 30 percent healthy\n\n### 7. PeakAlphaFreq_Pz\n- EC Alpha Peak table ‚Äî highest posterior alpha value\n- 9 Hz normal\n\n### 8. AlphaThetaRatio_Fz_Cz_Pz\n- EC Absolute Power Alpha / Theta for each site\n- \"Normal pattern\": Fz > Cz > Pz\n\n### 9. FrontalAlphaAsymmetry\n- EC Absolute Power Alpha at F3 and F4\n- Ratio = F4 / F3\n- < 1 is balanced\n\n## PARAMETER SCORING (0‚Äì3)\nEach of these 7 parameters gets a score 0‚Äì3 based on formulas:\n1. Cognition\n2. Stress\n3. Focus & Attention\n4. Burnout & Fatigue\n5. Emotional Regulation\n6. Learning\n7. Creativity\n\nScore to bucket mapping:\n- 0‚Äì1 = Low\n- 2 = Medium\n- 3 = High\n\n## BRAIN-TYPE PATTERN LINE\nBased on each score convert to L / M / H and format like:\nCognition M ¬∑ Stress L ¬∑ Focus L ¬∑ Burnout/Fatigue L ¬∑ Emotional Reg H ¬∑ Learning M ¬∑ Creativity M\n\n## FINAL OUTPUT FORMAT (NO JSON)\nReturn the report exactly in this structure:\n\n==============================\nNEUROSENSE BRAIN FUNCTION REPORT\n\nPatient Information\nName: <if available>\nAge: <if available>\nRecording Date: <if available>\nNotes: <if available>\n\nBrain-Type Pattern Summary\n<pattern line with L/M/H letters>\n<short 2‚Äì4 sentence overview in simple language>\n\nKey Highlights\n‚Ä¢ <3‚Äì6 bullet points summarizing the patient brain profile>\n\nParameter Score Cards\n\nCognition: <bucket> (Score <0‚Äì3>)\nShort status: <1-line summary>\nExplanation: <2‚Äì4 sentences explaining pattern and what it means for the patient>\n\nStress: <bucket> (Score <0‚Äì3>)\nShort status: <1-line summary>\nExplanation: <2‚Äì4 sentences>\n\nFocus & Attention: <bucket> (Score <0‚Äì3>)\nShort status: <1-line summary>\nExplanation: <2‚Äì4 sentences>\n\nBurnout & Fatigue: <bucket> (...)\nEmotional Regulation: <bucket> (...)\nLearning: <bucket> (...)\nCreativity: <bucket> (...)\n\nDetailed Narrative\nA longer plain-language explanation that connects how stress, focus, learning, emotional balance and creativity interact in this person's profile.\n\nCoaching Focus & Next Steps\n‚Ä¢ <priority #1>\n‚Ä¢ <priority #2>\n‚Ä¢ <priority #3>\n<2 sentences on expected improvement outcome>\n\nEnd Note\nA warm positive closing note written for the patient about brain improvement and self-development.\n\n==============================`;\n  }\n\n  /**\n   * Generate user prompt with actual patient data\n   */\n  getUserPrompt() {\n    const parametersText = this.algorithmResults.parameters.map((param, index) => {\n      const metricsText = param.metrics.map((metric, idx) => {\n        return `      ${idx + 1}. **${metric.name}**: Score ${metric.score}/1\n         - Value: ${typeof metric.value === 'object' ? JSON.stringify(metric.value) : metric.value}\n         - Description: ${metric.description}`;\n      }).join('\\n');\n\n      return `${index + 1}. **${param.name}**: ${param.score}/${param.maxScore} (${param.classification})\n   Subparameters:\n${metricsText}`;\n    }).join('\\n\\n');\n\n    return `Generate a comprehensive QEEG Intelligence report for the following patient:\n\n## PATIENT INFORMATION:\n- Name: ${this.patientData.name}\n- Date of Recording: ${this.patientData.dateOfRecording}\n- Age: ${this.patientData.age}\n- Gender: ${this.patientData.gender}\n- Handedness: ${this.patientData.handedness}\n- Symptoms: ${this.patientData.symptoms ? this.patientData.symptoms.join(', ') : 'Not specified'}\n\n## ALGORITHM RESULTS:\nOverall Brain Health Score: ${this.algorithmResults.overallScore}/21\n\n### Parameter Scores:\n${parametersText}\n\n## QEEG DATA SUMMARY:\n### Eyes Closed (EC):\n- Alpha Peak: ${this.qeegData.EC?.special?.alphaPeak || 'N/A'} Hz\n- Key Locations: Fz, Cz, Pz\n- Absolute Power Available: ${this.qeegData.EC?.absolute ? 'Yes' : 'No'}\n- Relative Power Available: ${this.qeegData.EC?.relative ? 'Yes' : 'No'}\n\n### Eyes Open (EO):\n- Absolute Power Available: ${this.qeegData.EO?.absolute ? 'Yes' : 'No'}\n- Relative Power Available: ${this.qeegData.EO?.relative ? 'Yes' : 'No'}\n\n---\n\nPlease generate a complete, professional QEEG report following the design requirements and structure specified in the system prompt. Include all sections with detailed explanations, health implications, and improvement recommendations for each parameter and subparameter.`;\n  }\n\n  /**\n   * Generate PDF report using OpenAI\n   * @param {string} outputPath - Path to save the generated PDF\n   * @returns {Promise<Object>} Generated report data and metadata\n   */\n  async generateReport(outputPath) {\n    try {\n      console.log('\\nü§ñ === AI PDF Generation Started ===\\n');\n      console.log('üë§ Patient:', this.patientData.name);\n      console.log('üìä Parameters:', this.algorithmResults.parameters.length);\n      console.log('üéØ Overall Score:', this.algorithmResults.overallScore, '/21');\n\n      // Step 1: Generate report content using OpenAI\n      console.log('\\nüìù Generating report content with AI...');\n\n      const response = await openai.chat.completions.create({\n        model: 'gpt-4-turbo-preview',\n        messages: [\n          {\n            role: 'system',\n            content: this.getSystemPrompt()\n          },\n          {\n            role: 'user',\n            content: this.getUserPrompt()\n          }\n        ],\n        temperature: 0.7,\n        max_tokens: 4000\n        // Note: No response_format specified - we want plain text, not JSON\n      });\n\n      const reportContent = response.choices[0].message.content;\n\n      console.log('‚úÖ AI content generated successfully');\n      console.log('üìÑ Content length:', reportContent.length, 'characters');\n\n      // Step 2: Save report content as plain text\n      const reportData = {\n        patientInfo: this.patientData,\n        algorithmResults: this.algorithmResults,\n        qeegData: this.qeegData,\n        aiGeneratedContent: reportContent,\n        metadata: {\n          generatedAt: new Date().toISOString(),\n          generatedBy: 'NeuroSense AI Report Generator',\n          model: 'gpt-4-turbo-preview',\n          version: '2.0.0'\n        }\n      };\n\n      // Save both text and JSON versions\n      const textOutputPath = outputPath.replace('.pdf', '.txt');\n      const jsonOutputPath = outputPath.replace('.pdf', '.json');\n\n      // Save plain text report\n      fs.writeFileSync(textOutputPath, reportContent);\n\n      // Save structured data with metadata\n      fs.writeFileSync(jsonOutputPath, JSON.stringify(reportData, null, 2));\n\n      console.log('\\n‚úÖ === AI NeuroSense Report Generation Completed ===');\n      console.log('üìÑ Text Report saved to:', textOutputPath);\n      console.log('üìÑ Data saved to:', jsonOutputPath);\n      console.log('üí° Note: Text report is ready for PDF conversion or direct use.\\n');\n\n      return {\n        success: true,\n        reportData,\n        reportText: reportContent,\n        textOutputPath: textOutputPath,\n        outputPath: jsonOutputPath,\n        contentLength: reportContent.length,\n        tokensUsed: response.usage.total_tokens\n      };\n\n    } catch (error) {\n      console.error('\\n‚ùå === AI PDF Generation Failed ===');\n      console.error('Error:', error.message);\n      throw error;\n    }\n  }\n\n  /**\n   * Generate sample report for testing\n   */\n  static async generateSampleReport() {\n    const samplePatient = {\n      name: 'Jane Smith',\n      dateOfRecording: new Date().toISOString().split('T')[0],\n      age: 42,\n      gender: 'Female',\n      handedness: 'Right',\n      symptoms: ['Stress', 'Focus Issues', 'Sleep Problems']\n    };\n\n    const sampleResults = {\n      parameters: [\n        {\n          name: 'Cognition',\n          score: 2,\n          maxScore: 3,\n          classification: 'Medium',\n          metrics: [\n            { name: 'Focus Score (Theta:Beta)', value: 1.2, score: 1, description: 'Healthy theta:beta ratio indicating good attention' },\n            { name: 'Alpha Peak', value: 10.3, score: 1, description: 'Strong alpha peak showing good mental relaxation capability' },\n            { name: 'Alpha:Theta Balance', value: 'Normal', score: 0, description: 'Balanced state between alertness and relaxation' }\n          ]\n        },\n        {\n          name: 'Stress',\n          score: 1,\n          maxScore: 3,\n          classification: 'Low',\n          metrics: [\n            { name: 'Arousal Score', value: 0.8, score: 1, description: 'Low arousal indicating minimal stress' },\n            { name: 'Relaxation Score', value: 8.5, score: 0, description: 'Moderate relaxation capacity' },\n            { name: 'Regeneration', value: 35.2, score: 1, description: 'Good alpha modulation for recovery' }\n          ]\n        }\n      ],\n      overallScore: 14\n    };\n\n    const sampleQEEG = {\n      EC: {\n        absolute: { Fz: { Delta: 5.2, Theta: 4.1, Alpha: 8.3, Beta: 6.2, HiBeta: 3.1 } },\n        relative: { Pz: { Alpha: 45.2 } },\n        special: { alphaPeak: 10.3, O1: 10.1 }\n      },\n      EO: {\n        absolute: { Fz: { Theta: 3.8, Beta: 3.2, HiBeta: 2.5 } },\n        relative: { Pz: { Alpha: 28.7 } }\n      }\n    };\n\n    const generator = new AIPdfGenerator(samplePatient, sampleResults, sampleQEEG);\n    const outputPath = path.join(__dirname, '../uploads/ai-sample-report.pdf');\n\n    return await generator.generateReport(outputPath);\n  }\n}\n\nmodule.exports = AIPdfGenerator;\n","numLines":359,"startLine":1,"totalLines":359}}}
{"parentUuid":"93f1f238-bbbb-4cb5-aff6-cdb1dfe00435","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_011JzmPMweoDhrEhCg1g2eUE","type":"message","role":"assistant","content":[{"type":"text","text":"Perfect! I now have a comprehensive understanding of the codebase. Let me analyze and provide recommendations for implementing the dual-mode QEEG system.\n\n## COMPREHENSIVE ANALYSIS & RECOMMENDATIONS\n\n### CURRENT ARCHITECTURE SUMMARY\n\n**Files Analyzed:**\n1. **D:\\Todays\\Neuro360\\server\\services\\qeegParser.js** - OpenAI-powered PDF extraction (raw values)\n2. **D:\\Todays\\Neuro360\\server\\services\\algorithmCalculator.js** - Calculates 7 parameters from raw values\n3. **D:\\Todays\\Neuro360\\server\\routes\\qeegRoutes.js** - API endpoints orchestrating the flow\n4. **D:\\Todays\\Neuro360\\src\\components\\admin\\AlgorithmDataProcessor.jsx** - Frontend UI\n\n### KEY FINDINGS\n\nThe current system:\n- Uses OpenAI GPT-4 to extract Absolute Power (ŒºV¬≤) and Relative Power (%) from PDFs\n- Calculates ratios from raw values (e.g., Theta/Beta, HiBeta/Beta, Alpha/Theta)\n- Applies binary thresholds (1.5, 10, 20, etc.) to score metrics\n- Outputs 7 parameters scored 0-3 each\n\n---\n\n## RECOMMENDED ARCHITECTURE: DUAL-MODE SYSTEM\n\n### Strategy: **Option B - Dual Formula Sets with Automatic Detection**\n\n**Why this approach:**\n1. **Scientifically Sound** - Z-scores and raw values represent fundamentally different metrics; converting between them requires normative databases we may not have\n2. **Flexibility** - Supports both report types without data loss\n3. **Maintainability** - Separate calculation paths are clearer than trying to normalize data\n4. **Future-Proof** - Easy to add more modes (e.g., coherence-based reports)\n\n---\n\n## IMPLEMENTATION PLAN\n\n### PHASE 1: Detection Logic (Priority: HIGH)\n\n**File: `server/services/qeegParser.js`**\n\nAdd detection method BEFORE parsing:\n\n```javascript\n/**\n * Detect QEEG report type from PDF content\n * @returns {string} 'raw' | 'zscore' | 'unknown'\n */\nstatic async detectReportType(file) {\n  try {\n    const dataBuffer = fs.readFileSync(file.path);\n    const pdfData = await pdfParse(dataBuffer);\n    const pdfText = pdfData.text.toLowerCase();\n    \n    // Detection Logic:\n    // 1. Check for explicit Z-score headers\n    const hasZScoreHeaders = \n      pdfText.includes('z-score') || \n      pdfText.includes('z score') ||\n      pdfText.includes('standard deviations');\n    \n    // 2. Check for raw power headers\n    const hasRawHeaders = \n      pdfText.includes('absolute power (Œºv¬≤)') ||\n      pdfText.includes('absolute power (uv¬≤)') ||\n      pdfText.includes('relative power (%)');\n    \n    // 3. Statistical analysis of extracted values\n    // Z-scores typically range -3 to +3\n    // Raw absolute power typically 0.5 to 500 ŒºV¬≤\n    // (Will implement after OpenAI extraction)\n    \n    if (hasZScoreHeaders && !hasRawHeaders) return 'zscore';\n    if (hasRawHeaders && !hasZScoreHeaders) return 'raw';\n    if (hasZScoreHeaders && hasRawHeaders) {\n      console.warn('‚ö†Ô∏è Report contains BOTH Z-scores and raw values - defaulting to raw');\n      return 'raw';\n    }\n    \n    return 'unknown';\n  } catch (error) {\n    console.error('Error detecting report type:', error);\n    return 'unknown';\n  }\n}\n```\n\n**Modify `parse()` method:**\n\n```javascript\nstatic async parse(eyesOpenFile, eyesClosedFile) {\n  // Detect report types\n  const eoType = await this.detectReportType(eyesOpenFile);\n  const ecType = await this.detectReportType(eyesClosedFile);\n  \n  if (eoType !== ecType) {\n    throw new Error('Mismatched report types: Eyes Open is ${eoType}, Eyes Closed is ${ecType}');\n  }\n  \n  console.log(`üìä Report Type Detected: ${eoType.toUpperCase()}`);\n  \n  // Parse based on type\n  const eyesOpenData = await this.parseFile(eyesOpenFile, eoType, 'EO');\n  const eyesClosedData = await this.parseFile(eyesClosedFile, ecType, 'EC');\n  \n  return {\n    EO: eyesOpenData,\n    EC: eyesClosedData,\n    dataType: eoType // Add metadata\n  };\n}\n```\n\n---\n\n### PHASE 2: Dual Extraction Prompts (Priority: HIGH)\n\n**File: `server/services/qeegParser.js`**\n\nCreate separate OpenAI prompts:\n\n```javascript\nstatic getExtractionPrompt(condition, reportType) {\n  if (reportType === 'zscore') {\n    return `You are a QEEG Z-score data extraction expert. Extract Z-score tables from this ${condition === 'EO' ? 'Eyes Open' : 'Eyes Closed'} QEEG report:\n\nExtract Z-score values (typically ranging from -3 to +3) for:\n- Channels: FP1, FP2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2\n- Frequency Bands: Delta, Theta, Alpha, Beta, HiBeta\n\nReturn in this JSON format:\n{\n  \"zscores\": {\n    \"absolute\": {\n      \"Fz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n      ...\n    },\n    \"relative\": { ... }\n  },\n  \"special\": {\n    \"alphaPeak\": 10.0,\n    \"alphaPeakZscore\": 0.0\n  }\n}\n\nPDF Content:\n${pdfText.substring(0, 15000)}`;\n  } else {\n    // Original raw power prompt (lines 159-207 in current code)\n    return `You are a QEEG data extraction expert...`;\n  }\n}\n```\n\n---\n\n### PHASE 3: Dual Calculation Logic (Priority: HIGH)\n\n**File: `server/services/algorithmCalculator.js`**\n\nModify constructor and add mode detection:\n\n```javascript\nconstructor(qeegData) {\n  this.data = qeegData;\n  this.dataType = qeegData.dataType || 'raw'; // Auto-detect or default\n  this.results = {\n    parameters: [],\n    rawCalculations: {},\n    overallScore: 0,\n    dataType: this.dataType // Include in results\n  };\n  \n  console.log(`üßÆ Algorithm Calculator initialized in ${this.dataType.toUpperCase()} mode`);\n}\n```\n\n**Add Z-score specific calculation methods:**\n\n```javascript\n/**\n * Calculate Focus Score from Z-scores\n * Uses direct Z-score thresholds instead of raw ratios\n */\ncalculateFocusScoreFromZScores() {\n  const fzThetaZ = this.getValue('EO', 'zscores', 'Fz', 'Theta');\n  const fzBetaZ = this.getValue('EO', 'zscores', 'Fz', 'Beta');\n  const czThetaZ = this.getValue('EO', 'zscores', 'Cz', 'Theta');\n  const czBetaZ = this.getValue('EO', 'zscores', 'Cz', 'Beta');\n  \n  if (!fzThetaZ || !fzBetaZ || !czThetaZ || !czBetaZ) \n    return { value: null, score: 0 };\n  \n  // Z-score logic:\n  // Normal: Both theta < +1 SD AND beta within ¬±1 SD\n  // Abnormal: Theta > +1 SD OR beta < -1 SD\n  \n  const fzNormal = (fzThetaZ < 1.0) && (Math.abs(fzBetaZ) < 1.0);\n  const czNormal = (czThetaZ < 1.0) && (Math.abs(czBetaZ) < 1.0);\n  \n  const score = (fzNormal && czNormal) ? 1 : 0;\n  \n  return {\n    value: { fzThetaZ, fzBetaZ, czThetaZ, czBetaZ },\n    score,\n    description: `Focus Z-scores: Fz(Œ∏=${fzThetaZ.toFixed(1)}, Œ≤=${fzBetaZ.toFixed(1)}), Cz(Œ∏=${czThetaZ.toFixed(1)}, Œ≤=${czBetaZ.toFixed(1)}) - ${score === 1 ? 'Normal' : 'Abnormal'}`,\n    details: { fzNormal, czNormal }\n  };\n}\n\n/**\n * Calculate Alpha Peak from Z-scores\n */\ncalculateAlphaPeakFromZScores() {\n  const alphaPeak = this.data.EC?.special?.alphaPeak || 10.0;\n  const alphaPeakZ = this.data.EC?.special?.alphaPeakZscore || 0;\n  \n  // Normal if peak > 9 Hz AND Z-score within ¬±1 SD\n  const score = (alphaPeak > 9 && Math.abs(alphaPeakZ) < 1.0) ? 1 : 0;\n  \n  return {\n    value: alphaPeak,\n    zscore: alphaPeakZ,\n    score,\n    description: `Alpha Peak = ${alphaPeak.toFixed(1)} Hz (Z=${alphaPeakZ.toFixed(1)}) - ${score === 1 ? 'Normal' : 'Abnormal'}`\n  };\n}\n```\n\n**Modify main calculation methods:**\n\n```javascript\ncalculateFocusScore() {\n  if (this.dataType === 'zscore') {\n    return this.calculateFocusScoreFromZScores();\n  } else {\n    // Original raw value calculation (lines 87-104)\n    return this.calculateFocusScoreFromRawValues();\n  }\n}\n```\n\n---\n\n### PHASE 4: Z-Score Thresholds & Formulas (Priority: MEDIUM)\n\n**Create new file: `server/services/zscoreThresholds.js`**\n\n```javascript\n/**\n * Z-Score Thresholds for QEEG Analysis\n * Based on clinical neurophysiology standards\n */\n\nmodule.exports = {\n  // Normal range: -1 to +1 SD (68% of population)\n  NORMAL_RANGE: { min: -1.0, max: 1.0 },\n  \n  // Mild abnormality: ¬±1 to ¬±2 SD\n  MILD_RANGE: { min: -2.0, max: -1.0, max2: 2.0 },\n  \n  // Significant abnormality: beyond ¬±2 SD (outliers)\n  SIGNIFICANT_THRESHOLD: 2.0,\n  \n  // Parameter-specific thresholds\n  FOCUS: {\n    theta_elevated: 1.0,    // Theta Z > +1 = elevated slow waves\n    beta_reduced: -1.0       // Beta Z < -1 = reduced fast waves\n  },\n  \n  AROUSAL: {\n    hibeta_elevated: 1.0,    // HiBeta Z > +1 = hyperarousal\n    beta_normal_range: 1.0\n  },\n  \n  ALPHA: {\n    peak_normal: 9.0,        // Hz (not Z-score)\n    peak_zscore_normal: 1.0,\n    asymmetry_threshold: 1.0\n  },\n  \n  DELTA: {\n    excessive_threshold: 2.0 // Z > +2 = excessive delta\n  }\n};\n```\n\n---\n\n### PHASE 5: Frontend UI Updates (Priority: MEDIUM)\n\n**File: `src/components/admin/AlgorithmDataProcessor.jsx`**\n\nAdd report type indicator:\n\n```javascript\n// After line 387 in processQEEGFiles():\nconst data = await response.json();\n\n// Display detected report type\nsetConsoleLog(prev => [...prev, `üìã Report Type: ${data.data.dataType.toUpperCase()}`]);\n\nif (data.data.dataType === 'zscore') {\n  setConsoleLog(prev => [...prev, '‚ö° Using Z-score calculation mode']);\n} else {\n  setConsoleLog(prev => [...prev, 'üìä Using raw power calculation mode']);\n}\n```\n\nAdd manual override option (OPTIONAL):\n\n```jsx\n{/* In the file upload section, add: */}\n<div className=\"mb-4\">\n  <label className=\"block text-sm font-medium mb-2\">\n    Report Type (Auto-detected, or override):\n  </label>\n  <select \n    value={reportTypeOverride} \n    onChange={(e) => setReportTypeOverride(e.target.value)}\n    className=\"w-full px-3 py-2 border rounded-lg\"\n  >\n    <option value=\"auto\">Auto-Detect</option>\n    <option value=\"raw\">Raw Power Values</option>\n    <option value=\"zscore\">Z-Score Tables</option>\n  </select>\n</div>\n```\n\n---\n\n### PHASE 6: Testing & Validation (Priority: HIGH)\n\n**Create test file: `server/tests/dualModeTests.js`**\n\n```javascript\nconst QEEGParser = require('../services/qeegParser');\nconst AlgorithmCalculator = require('../services/algorithmCalculator');\n\n// Test 1: Raw Value Report\nasync function testRawValueReport() {\n  const mockRawData = {\n    EO: {\n      absolute: { Fz: { Theta: 3.8, Beta: 3.2 }, Cz: { Theta: 4.1, Beta: 2.9 } },\n      relative: { Fz: { Theta: 18.5 } }\n    },\n    EC: {\n      absolute: { Fz: { Alpha: 8.3, Theta: 4.1 } },\n      special: { alphaPeak: 10.3 }\n    },\n    dataType: 'raw'\n  };\n  \n  const calculator = new AlgorithmCalculator(mockRawData);\n  const results = calculator.calculate();\n  \n  console.assert(results.dataType === 'raw', 'Should be raw mode');\n  console.log('‚úÖ Raw value test passed');\n}\n\n// Test 2: Z-Score Report\nasync function testZScoreReport() {\n  const mockZScoreData = {\n    EO: {\n      zscores: { \n        absolute: { \n          Fz: { Theta: 1.5, Beta: -0.5 }, \n          Cz: { Theta: 1.2, Beta: 0.2 } \n        }\n      }\n    },\n    EC: {\n      zscores: {\n        absolute: { Fz: { Alpha: 0.5, Theta: 1.0 } }\n      },\n      special: { alphaPeak: 10.3, alphaPeakZscore: 0.2 }\n    },\n    dataType: 'zscore'\n  };\n  \n  const calculator = new AlgorithmCalculator(mockZScoreData);\n  const results = calculator.calculate();\n  \n  console.assert(results.dataType === 'zscore', 'Should be zscore mode');\n  console.log('‚úÖ Z-score test passed');\n}\n\n// Run tests\n(async () => {\n  await testRawValueReport();\n  await testZScoreReport();\n})();\n```\n\n---\n\n## DECISION MATRIX\n\n### Detection Strategy: **AUTOMATIC with Manual Override**\n- **Primary**: Automatic detection via keyword matching + value range analysis\n- **Fallback**: Manual selection dropdown in UI\n- **Validation**: Warn if mismatch between EO and EC reports\n\n### Calculation Strategy: **SEPARATE FORMULA SETS**\n- **Raw Mode**: Keep existing formulas (Theta/Beta ratios, thresholds)\n- **Z-Score Mode**: New formulas based on standard deviation thresholds\n- **No Conversion**: Avoid converting Z ‚Üí Raw or Raw ‚Üí Z (requires normative DB)\n\n### Clinical Thresholds:\n| Metric | Raw Threshold | Z-Score Threshold |\n|--------|---------------|-------------------|\n| Focus (Theta:Beta) | < 1.5 | Theta Z < +1, Beta Z > -1 |\n| Alpha Peak | > 9 Hz | > 9 Hz AND Z within ¬±1 |\n| Arousal (HiBeta:Beta) | < 1.0 | HiBeta Z < +1 |\n| Excessive Delta | < 70% | Delta Z < +2 |\n\n---\n\n## IMPLEMENTATION PRIORITIES\n\n### MUST HAVE (Phase 1-3):\n1. **Detection logic** - Prevent mixed report types\n2. **Dual extraction prompts** - OpenAI can handle both\n3. **Dual calculation logic** - Core algorithm split\n\n### SHOULD HAVE (Phase 4-5):\n4. **Z-score thresholds** - Clinically validated values\n5. **Frontend indicators** - Show which mode is active\n\n### NICE TO HAVE (Phase 6):\n6. **Manual override** - For edge cases\n7. **Comprehensive tests** - Validate both modes\n8. **Mixed report handling** - If some channels are Z, some are raw\n\n---\n\n## NORMATIVE DATABASE CONSIDERATIONS\n\n**DO WE NEED IT?**\n- **For Z ‚Üí Raw conversion**: YES (requires mean/SD for each channel/band/age)\n- **For our recommended approach**: NO (direct Z-score assessment)\n\n**If you decide to add conversion later:**\n- Source: Neuroguide, Brain Resource Database, or proprietary norms\n- Structure: `{ channel: { band: { ageGroup: { mean, sd } } } }`\n- Age-matching is critical (alpha peak changes with age)\n\n---\n\n## RISKS & MITIGATION\n\n| Risk | Mitigation |\n|------|-----------|\n| Incorrect detection | Validate with value range analysis + manual override |\n| Mixed report types | Reject upload with clear error message |\n| OpenAI extraction errors | Add validation: check if extracted values are in expected range |\n| Threshold mismatch | Create clinical validation tests with known cases |\n| Performance | Cache report type detection result |\n\n---\n\n## EDGE CASES TO HANDLE\n\n1. **Report with BOTH raw and Z-scores**: Default to raw, warn user\n2. **Partially missing data**: Calculate available parameters, mark others as N/A\n3. **Non-standard Z-score ranges**: Detect if values exceed ¬±5 SD (likely raw values mislabeled)\n4. **Different units**: Some reports use ŒºV¬≤ vs ŒºV - detect and normalize\n\n---\n\n## TESTING CHECKLIST\n\n- [ ] Raw value report (current system)\n- [ ] Z-score only report\n- [ ] Report with both types (should reject or prefer raw)\n- [ ] Mismatched EO/EC types (should reject)\n- [ ] Edge case: All Z-scores = 0 (ideal brain)\n- [ ] Edge case: Z-scores > ¬±3 (extreme outliers)\n- [ ] Frontend displays correct mode indicator\n- [ ] PDF generation works for both modes\n- [ ] Manual override switches modes correctly\n\n---\n\n## MIGRATION PATH\n\n**For Existing Users:**\n1. Current system continues working (raw mode is default)\n2. New system auto-detects report type\n3. Old saved reports remain compatible\n4. Database schema doesn't need changes (just add `dataType` field)\n\n---\n\n## QUESTIONS FOR YOU\n\nBefore I create a detailed implementation plan, please answer:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":5199,"cache_read_input_tokens":61372,"cache_creation":{"ephemeral_5m_input_tokens":5199,"ephemeral_1h_input_tokens":0},"output_tokens":5834,"service_tier":"standard"}},"requestId":"req_011CVhb6hvHpkhpe73DC9omP","type":"assistant","uuid":"f84d9289-dad8-44e7-b6d5-94516cb560a5","timestamp":"2025-12-02T09:03:11.858Z"}
{"parentUuid":"f84d9289-dad8-44e7-b6d5-94516cb560a5","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_011JzmPMweoDhrEhCg1g2eUE","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WtWEbJT9y49iySqp1ARuuB","name":"AskUserQuestion","input":{"questions":[{"question":"Do you have sample Z-score QEEG reports we can test with? Or should we create synthetic test data first?","header":"Test Data","multiSelect":false,"options":[{"label":"Yes, I have Z-score PDFs ready","description":"We can start with real reports for testing detection and extraction"},{"label":"No, let's use synthetic data","description":"Create mock Z-score tables to test the logic before getting real reports"},{"label":"Mixed - some real, some synthetic","description":"Use both approaches for comprehensive testing"}]},{"question":"Should Z-score detection be automatic only, or include a manual override in the UI?","header":"Detection UX","multiSelect":false,"options":[{"label":"Automatic only (simpler)","description":"System auto-detects report type, no user input needed. Faster workflow."},{"label":"Automatic with manual override","description":"Auto-detect by default, but allow user to override if detection fails. More flexible."},{"label":"Manual selection required","description":"User must explicitly choose report type before upload. Most control, slower workflow."}]},{"question":"What should happen if a user uploads mismatched report types (EO is raw, EC is Z-score)?","header":"Error Handling","multiSelect":false,"options":[{"label":"Reject with error message","description":"Stop processing and ask user to provide matching report types. Safest option."},{"label":"Try to convert one to match","description":"Attempt automatic conversion (requires normative database). Complex but convenient."},{"label":"Process separately with warning","description":"Allow processing but prominently warn that results may be invalid."}]},{"question":"Do you want to implement full Z-score mode in Phase 1, or start with detection/extraction only?","header":"Scope","multiSelect":false,"options":[{"label":"Full implementation (all phases)","description":"Detection, extraction, dual calculations, UI updates. Complete feature. ~2-3 days work."},{"label":"Phase 1-2 only (detection + extraction)","description":"Just detect report type and extract Z-scores. Calculate later. ~1 day work."},{"label":"Start with detection only","description":"Minimal implementation - just identify report types and log warnings. ~2 hours work."}]}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":5199,"cache_read_input_tokens":61372,"cache_creation":{"ephemeral_5m_input_tokens":5199,"ephemeral_1h_input_tokens":0},"output_tokens":5834,"service_tier":"standard"}},"requestId":"req_011CVhb6hvHpkhpe73DC9omP","type":"assistant","uuid":"25011ba7-eca1-4ead-8681-5ff1d5285f30","timestamp":"2025-12-02T09:03:24.822Z"}
{"parentUuid":"25011ba7-eca1-4ead-8681-5ff1d5285f30","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"User has answered your questions: \"Do you have sample Z-score QEEG reports we can test with? Or should we create synthetic test data first?\"=\"Yes, I have Z-score PDFs ready\", \"Should Z-score detection be automatic only, or include a manual override in the UI?\"=\"Automatic only (simpler)\", \"What should happen if a user uploads mismatched report types (EO is raw, EC is Z-score)?\"=\"Reject with error message\", \"Do you want to implement full Z-score mode in Phase 1, or start with detection/extraction only?\"=\"Full implementation (all phases)\". You can now continue with the user's answers in mind.","tool_use_id":"toolu_01WtWEbJT9y49iySqp1ARuuB"}]},"uuid":"79fd52bb-6727-408f-97fe-d35bcbf6b452","timestamp":"2025-12-02T09:05:23.823Z","toolUseResult":{"questions":[{"question":"Do you have sample Z-score QEEG reports we can test with? Or should we create synthetic test data first?","header":"Test Data","options":[{"label":"Yes, I have Z-score PDFs ready","description":"We can start with real reports for testing detection and extraction"},{"label":"No, let's use synthetic data","description":"Create mock Z-score tables to test the logic before getting real reports"},{"label":"Mixed - some real, some synthetic","description":"Use both approaches for comprehensive testing"}],"multiSelect":false},{"question":"Should Z-score detection be automatic only, or include a manual override in the UI?","header":"Detection UX","options":[{"label":"Automatic only (simpler)","description":"System auto-detects report type, no user input needed. Faster workflow."},{"label":"Automatic with manual override","description":"Auto-detect by default, but allow user to override if detection fails. More flexible."},{"label":"Manual selection required","description":"User must explicitly choose report type before upload. Most control, slower workflow."}],"multiSelect":false},{"question":"What should happen if a user uploads mismatched report types (EO is raw, EC is Z-score)?","header":"Error Handling","options":[{"label":"Reject with error message","description":"Stop processing and ask user to provide matching report types. Safest option."},{"label":"Try to convert one to match","description":"Attempt automatic conversion (requires normative database). Complex but convenient."},{"label":"Process separately with warning","description":"Allow processing but prominently warn that results may be invalid."}],"multiSelect":false},{"question":"Do you want to implement full Z-score mode in Phase 1, or start with detection/extraction only?","header":"Scope","options":[{"label":"Full implementation (all phases)","description":"Detection, extraction, dual calculations, UI updates. Complete feature. ~2-3 days work."},{"label":"Phase 1-2 only (detection + extraction)","description":"Just detect report type and extract Z-scores. Calculate later. ~1 day work."},{"label":"Start with detection only","description":"Minimal implementation - just identify report types and log warnings. ~2 hours work."}],"multiSelect":false}],"answers":{"Do you have sample Z-score QEEG reports we can test with? Or should we create synthetic test data first?":"Yes, I have Z-score PDFs ready","Should Z-score detection be automatic only, or include a manual override in the UI?":"Automatic only (simpler)","What should happen if a user uploads mismatched report types (EO is raw, EC is Z-score)?":"Reject with error message","Do you want to implement full Z-score mode in Phase 1, or start with detection/extraction only?":"Full implementation (all phases)"}}}
{"parentUuid":"79fd52bb-6727-408f-97fe-d35bcbf6b452","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"cc710945-1636-4867-a582-8cd5b56d80d5","version":"2.0.33","gitBranch":"main","agentId":"678d280d","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_012MwRZhMNKtz1drLPes9akJ","type":"message","role":"assistant","content":[{"type":"text","text":"Perfect! Based on your answers, here's the complete implementation plan:\n\n---\n\n## FINAL IMPLEMENTATION PLAN\n\n**Scope**: Full dual-mode QEEG system (all phases)  \n**Detection**: Automatic only (no manual override)  \n**Error Handling**: Reject mismatched report types with clear error  \n**Testing**: Use your real Z-score PDFs\n\n---\n\n## FILES TO MODIFY/CREATE\n\n### 1. **server/services/qeegParser.js** (MODIFY)\n- Add `detectReportType()` method\n- Add `getExtractionPrompt()` method for dual prompts\n- Modify `parse()` to detect and validate report types\n- Modify `parsePDF()` to use appropriate prompt based on type\n- Add value range validation post-extraction\n\n### 2. **server/services/algorithmCalculator.js** (MODIFY)\n- Update constructor to accept `dataType`\n- Create Z-score calculation methods for all 9 metrics\n- Add conditional routing in existing methods (if zscore ‚Üí use new method)\n- Update `getValue()` to handle both `absolute/relative` and `zscores` paths\n\n### 3. **server/services/zscoreThresholds.js** (CREATE NEW)\n- Define clinical Z-score thresholds\n- Document scientific rationale for each threshold\n- Export as module for use in calculator\n\n### 4. **server/routes/qeegRoutes.js** (MODIFY - MINIMAL)\n- Add logging for detected report type\n- Pass `dataType` to frontend in response\n- Update error messages for mismatched types\n\n### 5. **src/components/admin/AlgorithmDataProcessor.jsx** (MODIFY - MINIMAL)\n- Display detected report type in console log\n- Show Z-score mode indicator badge when active\n- Update results display to show Z-scores when applicable\n\n### 6. **server/tests/dualModeTests.js** (CREATE NEW)\n- Test raw value mode (existing)\n- Test Z-score mode (new)\n- Test detection logic\n- Test mismatch rejection\n- Test edge cases\n\n### 7. **.env.example** (UPDATE - OPTIONAL)\n- Add comment about Z-score detection feature\n- No new environment variables needed\n\n---\n\n## IMPLEMENTATION SEQUENCE\n\n### STEP 1: Core Detection (30 min)\n**File**: `server/services/qeegParser.js`\n\n```javascript\n// Add after line 43\nstatic async detectReportType(file) {\n  try {\n    const dataBuffer = fs.readFileSync(file.path);\n    const pdfData = await pdfParse(dataBuffer);\n    const text = pdfData.text.toLowerCase();\n    \n    // Keyword detection\n    const zscoreKeywords = ['z-score', 'z score', 'standard deviation', 'z ='];\n    const rawKeywords = ['absolute power (Œºv¬≤)', 'relative power (%)', 'absolute (Œºv¬≤)'];\n    \n    const hasZscore = zscoreKeywords.some(kw => text.includes(kw));\n    const hasRaw = rawKeywords.some(kw => text.includes(kw));\n    \n    if (hasZscore && !hasRaw) return 'zscore';\n    if (hasRaw && !hasZscore) return 'raw';\n    if (hasZscore && hasRaw) {\n      console.warn('‚ö†Ô∏è Mixed report type detected - defaulting to raw');\n      return 'raw';\n    }\n    \n    // Fallback: assume raw if unclear\n    console.warn('‚ö†Ô∏è Could not detect report type clearly - defaulting to raw');\n    return 'raw';\n  } catch (error) {\n    console.error('Error detecting report type:', error);\n    return 'raw'; // Safe default\n  }\n}\n```\n\n### STEP 2: Modify Parse Flow (15 min)\n**File**: `server/services/qeegParser.js`\n\n```javascript\n// Replace lines 86-113 with:\nstatic async parse(eyesOpenFile, eyesClosedFile) {\n  try {\n    console.log('üìÑ Parsing QEEG files...');\n    console.log('  - Eyes Open:', eyesOpenFile?.originalname);\n    console.log('  - Eyes Closed:', eyesClosedFile?.originalname);\n\n    // STEP 1: Detect report types\n    console.log('\\nüîç Detecting report types...');\n    const eoType = await this.detectReportType(eyesOpenFile);\n    const ecType = await this.detectReportType(eyesClosedFile);\n    \n    console.log(`  - Eyes Open: ${eoType.toUpperCase()}`);\n    console.log(`  - Eyes Closed: ${ecType.toUpperCase()}`);\n    \n    // STEP 2: Validate matching types\n    if (eoType !== ecType) {\n      throw new Error(\n        `Mismatched report types detected!\\n` +\n        `Eyes Open is ${eoType.toUpperCase()}, but Eyes Closed is ${ecType.toUpperCase()}.\\n` +\n        `Please ensure both reports are the same type.`\n      );\n    }\n    \n    const reportType = eoType;\n    console.log(`‚úÖ Report type validated: ${reportType.toUpperCase()}`);\n\n    // STEP 3: Parse with appropriate method\n    const eyesOpenData = await this.parseFile(eyesOpenFile, 'pdf', 'EO', reportType);\n    const eyesClosedData = await this.parseFile(eyesClosedFile, 'pdf', 'EC', reportType);\n\n    // STEP 4: Combine with metadata\n    const combinedData = {\n      EO: eyesOpenData,\n      EC: eyesClosedData,\n      dataType: reportType // Add type metadata\n    };\n\n    console.log('‚úÖ QEEG files parsed successfully');\n    return combinedData;\n\n  } catch (error) {\n    console.error('‚ùå Error parsing QEEG files:', error);\n    throw error;\n  }\n}\n```\n\n### STEP 3: Dual Prompts (45 min)\n**File**: `server/services/qeegParser.js`\n\n```javascript\n// Add new method after line 138\nstatic getExtractionPrompt(condition, reportType, pdfText) {\n  const conditionName = condition === 'EO' ? 'Eyes Open' : 'Eyes Closed';\n  \n  if (reportType === 'zscore') {\n    return `You are a QEEG Z-score data extraction expert. Extract Z-score values from this ${conditionName} QEEG report.\n\n**IMPORTANT**: Z-scores represent standard deviations from the mean. They typically range from -3 to +3.\n- Negative values = below average\n- Zero = average\n- Positive values = above average\n\nExtract Z-score tables for these channels: FP1, FP2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2\n\nFor each channel, extract Z-scores for:\n- Delta (1-4 Hz)\n- Theta (4-8 Hz)\n- Alpha (8-13 Hz)\n- Beta (13-30 Hz)\n- HiBeta / High Beta (20-30 Hz)\n\nAlso extract:\n- Alpha Peak Frequency (Hz) and its Z-score if available\n\nReturn ONLY valid JSON in this EXACT format:\n{\n  \"zscores\": {\n    \"absolute\": {\n      \"Fz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n      \"Cz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n      \"Pz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n      \"F3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n      \"F4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n      \"C3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n      \"C4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n      \"P3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n      \"P4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 }\n    },\n    \"relative\": {\n      \"Fz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n      \"Cz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n      \"Pz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n      \"F3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n      \"F4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n      \"C3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n      \"C4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n      \"P3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n      \"P4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 }\n    }\n  },\n  \"special\": {\n    \"alphaPeak\": 10.0,\n    \"alphaPeakZscore\": 0.0\n  }\n}\n\nPDF Content:\n${pdfText.substring(0, 15000)}`;\n    \n  } else {\n    // Original raw power prompt (keep existing lines 159-207)\n    return `You are a QEEG data extraction expert. Extract the following data from this ${conditionName} QEEG report:\n... (keep existing raw prompt)`;\n  }\n}\n```\n\n### STEP 4: Update parsePDF Method (20 min)\n**File**: `server/services/qeegParser.js`\n\n```javascript\n// Modify parseFile signature (line 129)\nstatic async parseFile(file, fileType, condition, reportType = 'raw') {\n  if (fileType === 'pdf') {\n    return await this.parsePDF(file, condition, reportType);\n  }\n  // ... rest unchanged\n}\n\n// Modify parsePDF signature (line 143)\nstatic async parsePDF(file, condition, reportType = 'raw') {\n  console.log(`  üîç Parsing PDF with OpenAI (${condition}, ${reportType.toUpperCase()} mode)...`);\n  \n  try {\n    this.validateAPIKey();\n    const dataBuffer = fs.readFileSync(file.path);\n    const pdfData = await pdfParse(dataBuffer);\n    const pdfText = pdfData.text;\n    \n    // Use appropriate prompt based on report type\n    const prompt = this.getExtractionPrompt(condition, reportType, pdfText);\n    \n    const response = await openai.chat.completions.create({\n      model: 'gpt-4-turbo-preview',\n      messages: [\n        {\n          role: 'system',\n          content: `You are an expert at extracting structured QEEG data from medical reports. Always return valid JSON. Report type: ${reportType.toUpperCase()}`\n        },\n        { role: 'user', content: prompt }\n      ],\n      temperature: 0.1,\n      response_format: { type: 'json_object' }\n    });\n    \n    const extractedData = JSON.parse(response.choices[0].message.content);\n    \n    // Validate extracted data based on type\n    if (reportType === 'zscore') {\n      this.validateZScoreData(extractedData, condition);\n    } else {\n      this.validateRawData(extractedData, condition);\n    }\n    \n    console.log(`  ‚úÖ PDF data extracted (${reportType.toUpperCase()} mode)`);\n    return extractedData;\n    \n  } catch (error) {\n    console.error(`  ‚ùå Extraction error (${condition}):`, error.message);\n    throw error;\n  }\n}\n```\n\n### STEP 5: Add Validation Methods (30 min)\n**File**: `server/services/qeegParser.js`\n\n```javascript\n// Add after parsePDF method\nstatic validateZScoreData(data, condition) {\n  if (!data.zscores) {\n    throw new Error(`Missing zscores object in ${condition} data`);\n  }\n  \n  // Check for required channels\n  const requiredChannels = ['Fz', 'Cz', 'Pz', 'F3', 'F4'];\n  const absoluteChannels = Object.keys(data.zscores.absolute || {});\n  const missingChannels = requiredChannels.filter(ch => !absoluteChannels.includes(ch));\n  \n  if (missingChannels.length > 0) {\n    console.warn(`‚ö†Ô∏è Missing channels in ${condition}:`, missingChannels.join(', '));\n  }\n  \n  // Validate Z-score ranges (should be -5 to +5, typically -3 to +3)\n  Object.entries(data.zscores.absolute || {}).forEach(([channel, bands]) => {\n    Object.entries(bands).forEach(([band, value]) => {\n      if (Math.abs(value) > 5) {\n        console.warn(`‚ö†Ô∏è Unusual Z-score in ${condition} ${channel}.${band}: ${value} (expected -5 to +5)`);\n      }\n    });\n  });\n  \n  console.log(`‚úÖ Z-score data validated for ${condition}`);\n}\n\nstatic validateRawData(data, condition) {\n  // Keep existing validation (lines 234-247)\n  const requiredChannels = ['Fz', 'Cz', 'Pz', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4'];\n  const absoluteChannels = Object.keys(data.absolute || {});\n  const relativeChannels = Object.keys(data.relative || {});\n  // ... rest of existing validation\n}\n```\n\n### STEP 6: Create Z-Score Thresholds (20 min)\n**File**: `server/services/zscoreThresholds.js` (NEW)\n\n```javascript\n/**\n * Z-Score Thresholds for QEEG Algorithm\n * \n * Clinical Interpretation:\n * - Z-scores represent standard deviations from age-matched norms\n * - Range: -3 to +3 (typical), -5 to +5 (extreme)\n * - Interpretation:\n *   * ¬±1 SD = 68% of population (NORMAL)\n *   * ¬±2 SD = 95% of population (MILD ABNORMALITY)\n *   * >¬±2 SD = Outliers (SIGNIFICANT ABNORMALITY)\n * \n * References:\n * - Neuroguide normative database\n * - Clinical neurophysiology standards (ACNS)\n */\n\nmodule.exports = {\n  // General thresholds\n  NORMAL_RANGE: { min: -1.0, max: 1.0 },\n  MILD_RANGE: { min: -2.0, max: 2.0 },\n  SIGNIFICANT_THRESHOLD: 2.0,\n  \n  // Focus & Attention (EO, Frontal)\n  FOCUS: {\n    // Elevated theta = decreased alertness\n    THETA_ELEVATED: 1.0,      // Z > +1 SD\n    // Reduced beta = decreased active attention\n    BETA_REDUCED: -1.0,       // Z < -1 SD\n    // Normal if both within ¬±1 SD\n    NORMAL_RANGE: 1.0\n  },\n  \n  // Arousal / Stress (EO, Frontal)\n  AROUSAL: {\n    // Elevated HiBeta = hyperarousal/anxiety\n    HIBETA_ELEVATED: 1.0,     // Z > +1 SD\n    // Normal beta range\n    BETA_NORMAL: 1.0\n  },\n  \n  // Alpha (EC, Posterior)\n  ALPHA: {\n    // Peak frequency (Hz, not Z-score)\n    PEAK_MINIMUM: 9.0,        // Hz\n    // Peak frequency Z-score\n    PEAK_ZSCORE_NORMAL: 1.0,  // Z within ¬±1 SD\n    // Asymmetry (F4/F3)\n    ASYMMETRY_THRESHOLD: 1.0\n  },\n  \n  // Delta (EO, Widespread)\n  DELTA: {\n    // Excessive slow wave activity\n    EXCESSIVE_THRESHOLD: 2.0  // Z > +2 SD\n  },\n  \n  // Alpha:Theta Ratio\n  ALPHA_THETA: {\n    // Normal if ratio decreases from posterior to frontal\n    GRADIENT_NORMAL: true     // Pz > Cz > Fz\n  }\n};\n```\n\n### STEP 7: Update Algorithm Calculator (60 min)\n**File**: `server/services/algorithmCalculator.js`\n\n```javascript\n// Update constructor (lines 8-15)\nconstructor(qeegData) {\n  this.data = qeegData;\n  this.dataType = qeegData.dataType || 'raw';\n  this.results = {\n    parameters: [],\n    rawCalculations: {},\n    overallScore: 0,\n    dataType: this.dataType\n  };\n  \n  console.log(`üßÆ Calculator Mode: ${this.dataType.toUpperCase()}`);\n}\n\n// Update getValue to handle Z-scores (lines 46-53)\ngetValue(condition, powerType, channel, band) {\n  try {\n    if (this.dataType === 'zscore' && powerType === 'zscores') {\n      // Z-score path: data[condition].zscores.absolute/relative[channel][band]\n      return this.data[condition]?.zscores?.[powerType.split('.')[1] || 'absolute']?.[channel]?.[band];\n    } else {\n      // Raw path: data[condition].absolute/relative[channel][band]\n      return this.data[condition]?.[powerType]?.[channel]?.[band];\n    }\n  } catch (error) {\n    console.error(`Error getting value: ${condition}.${powerType}.${channel}.${band}`);\n    return null;\n  }\n}\n\n// Add Z-score specific methods (add after line 105)\n/**\n * Calculate Focus Score from Z-scores\n * Logic: Normal if Theta < +1 SD AND Beta > -1 SD (within normal range)\n */\ncalculateFocusScoreFromZScores() {\n  const fzThetaZ = this.getValue('EO', 'zscores.absolute', 'Fz', 'Theta');\n  const fzBetaZ = this.getValue('EO', 'zscores.absolute', 'Fz', 'Beta');\n  const czThetaZ = this.getValue('EO', 'zscores.absolute', 'Cz', 'Theta');\n  const czBetaZ = this.getValue('EO', 'zscores.absolute', 'Cz', 'Beta');\n  \n  if (fzThetaZ === null || fzBetaZ === null || czThetaZ === null || czBetaZ === null) {\n    return { value: null, score: 0 };\n  }\n  \n  // Score 1 if BOTH locations are normal\n  const fzNormal = (fzThetaZ < 1.0) && (fzBetaZ > -1.0);\n  const czNormal = (czThetaZ < 1.0) && (czBetaZ > -1.0);\n  const score = (fzNormal && czNormal) ? 1 : 0;\n  \n  return {\n    value: { fzThetaZ, fzBetaZ, czThetaZ, czBetaZ },\n    score,\n    description: `Focus Z-scores: Fz(Œ∏=${fzThetaZ.toFixed(1)}, Œ≤=${fzBetaZ.toFixed(1)}), Cz(Œ∏=${czThetaZ.toFixed(1)}, Œ≤=${czBetaZ.toFixed(1)}) - ${score === 1 ? 'Normal' : 'Elevated Theta or Reduced Beta'}`,\n    details: { fzNormal, czNormal }\n  };\n}\n\n/**\n * Calculate Alpha Peak from Z-scores\n */\ncalculateAlphaPeakFromZScores() {\n  const alphaPeak = this.data.EC?.special?.alphaPeak || 10.0;\n  const alphaPeakZ = this.data.EC?.special?.alphaPeakZscore || 0;\n  \n  // Score 1 if peak > 9 Hz AND Z-score within ¬±1 SD\n  const score = (alphaPeak > 9 && Math.abs(alphaPeakZ) < 1.0) ? 1 : 0;\n  \n  return {\n    value: alphaPeak,\n    zscore: alphaPeakZ,\n    score,\n    description: `Alpha Peak = ${alphaPeak.toFixed(1)} Hz (Z=${alphaPeakZ.toFixed(1)}) - ${score === 1 ? 'Normal' : 'Below Normal'}`\n  };\n}\n\n/**\n * Calculate Alpha:Theta Balance from Z-scores\n * Logic: Normal gradient if Pz > Cz > Fz (posterior dominance)\n */\ncalculateAlphaThetaBalanceFromZScores() {\n  const fzAlphaZ = this.getValue('EC', 'zscores.absolute', 'Fz', 'Alpha');\n  const czAlphaZ = this.getValue('EC', 'zscores.absolute', 'Cz', 'Alpha');\n  const pzAlphaZ = this.getValue('EC', 'zscores.absolute', 'Pz', 'Alpha');\n  \n  if (fzAlphaZ === null || czAlphaZ === null || pzAlphaZ === null) {\n    return { value: null, score: 0 };\n  }\n  \n  // Normal if posterior > central > frontal\n  const isNormalGradient = (pzAlphaZ > czAlphaZ) && (czAlphaZ > fzAlphaZ);\n  \n  return {\n    value: { fzAlphaZ, czAlphaZ, pzAlphaZ },\n    score: isNormalGradient ? 1 : 0,\n    description: `Alpha Z-score Gradient: ${isNormalGradient ? 'Pz > Cz > Fz (Normal)' : 'Abnormal pattern'}`,\n    details: { fzAlphaZ, czAlphaZ, pzAlphaZ, gradient: isNormalGradient }\n  };\n}\n\n// ... (Add similar methods for all other metrics: Arousal, Relaxation, etc.)\n// See full implementation in attached file\n\n// Modify existing metric methods to route based on dataType (lines 87-286)\ncalculateFocusScore() {\n  if (this.dataType === 'zscore') {\n    return this.calculateFocusScoreFromZScores();\n  } else {\n    return this.calculateFocusScoreFromRawValues(); // Rename existing method\n  }\n}\n\ncalculateAlphaPeak() {\n  if (this.dataType === 'zscore') {\n    return this.calculateAlphaPeakFromZScores();\n  } else {\n    return this.calculateAlphaPeakFromRawValues();\n  }\n}\n\n// ... (Apply same pattern to all metric methods)\n```\n\n### STEP 8: Frontend Updates (30 min)\n**File**: `src/components/admin/AlgorithmDataProcessor.jsx`\n\n```javascript\n// After line 386 (in processQEEGFiles after response):\nconst data = await response.json();\n\n// Add console logging for report type\nconst reportType = data.data.dataType || 'raw';\nsetConsoleLog(prev => [...prev, `üìã Report Type: ${reportType.toUpperCase()}`]);\n\nif (reportType === 'zscore') {\n  setConsoleLog(prev => [...prev, '‚ö° Using Z-score analysis mode']);\n  setConsoleLog(prev => [...prev, '  (Values represent standard deviations from norm)']);\n} else {\n  setConsoleLog(prev => [...prev, 'üìä Using raw power analysis mode']);\n  setConsoleLog(prev => [...prev, '  (Values represent ŒºV¬≤ and percentages)']);\n}\n\n// Store report type in state for display\nsetReportType(reportType);\n```\n\n```jsx\n{/* Add badge in results panel (after line 1244) */}\n<div className=\"flex items-center justify-between mb-4\">\n  <h2 className=\"text-lg font-semibold\">Final 7 Parameter Scores</h2>\n  {reportType === 'zscore' && (\n    <span className=\"px-3 py-1 bg-purple-100 dark:bg-purple-900/30 text-purple-700 dark:text-purple-400 text-xs font-medium rounded-full\">\n      Z-Score Mode\n    </span>\n  )}\n</div>\n```\n\n### STEP 9: Testing (60 min)\n**File**: `server/tests/dualModeTests.js` (NEW)\n\n```javascript\nconst QEEGParser = require('../services/qeegParser');\nconst AlgorithmCalculator = require('../services/algorithmCalculator');\nconst fs = require('fs');\nconst path = require('path');\n\n// Test 1: Detection accuracy\nasync function testDetection() {\n  console.log('\\nüìã Testing Report Type Detection...\\n');\n  \n  // You'll provide real Z-score PDFs\n  const zscorePDF = { path: './test-data/zscore-report-EO.pdf', originalname: 'zscore-EO.pdf' };\n  const rawPDF = { path: './test-data/raw-report-EO.pdf', originalname: 'raw-EO.pdf' };\n  \n  const zType = await QEEGParser.detectReportType(zscorePDF);\n  const rType = await QEEGParser.detectReportType(rawPDF);\n  \n  console.assert(zType === 'zscore', `Expected 'zscore', got '${zType}'`);\n  console.assert(rType === 'raw', `Expected 'raw', got '${rType}'`);\n  \n  console.log('‚úÖ Detection test passed\\n');\n}\n\n// Test 2: Z-score extraction\nasync function testZScoreExtraction() {\n  console.log('üîç Testing Z-Score Extraction...\\n');\n  \n  const eoFile = { path: './test-data/zscore-report-EO.pdf', originalname: 'zscore-EO.pdf' };\n  const ecFile = { path: './test-data/zscore-report-EC.pdf', originalname: 'zscore-EC.pdf' };\n  \n  const data = await QEEGParser.parse(eoFile, ecFile);\n  \n  console.assert(data.dataType === 'zscore', 'Should be zscore type');\n  console.assert(data.EO.zscores, 'Should have zscores object');\n  console.assert(data.EO.zscores.absolute.Fz, 'Should have Fz channel');\n  console.assert(typeof data.EO.zscores.absolute.Fz.Theta === 'number', 'Theta should be number');\n  \n  console.log('‚úÖ Z-score extraction test passed\\n');\n  console.log('Sample values:', data.EO.zscores.absolute.Fz);\n}\n\n// Test 3: Z-score calculations\nasync function testZScoreCalculations() {\n  console.log('üßÆ Testing Z-Score Calculations...\\n');\n  \n  const mockData = {\n    EO: {\n      zscores: {\n        absolute: {\n          Fz: { Theta: 0.5, Beta: 0.2, HiBeta: 0.8 },\n          Cz: { Theta: 0.3, Beta: 0.1, HiBeta: 0.6 }\n        },\n        relative: {\n          Fz: { Theta: 0.4, Delta: 0.5 },\n          Pz: { Alpha: -0.3 }\n        }\n      }\n    },\n    EC: {\n      zscores: {\n        absolute: {\n          Fz: { Alpha: -0.2, Theta: 0.5 },\n          Cz: { Alpha: 0.1, Theta: 0.4 },\n          Pz: { Alpha: 0.3, Theta: 0.2, Beta: -0.5 },\n          F3: { Alpha: 0.4 },\n          F4: { Alpha: 0.3 }\n        },\n        relative: {\n          Pz: { Alpha: 0.5 }\n        }\n      },\n      special: {\n        alphaPeak: 10.2,\n        alphaPeakZscore: 0.3\n      }\n    },\n    dataType: 'zscore'\n  };\n  \n  const calculator = new AlgorithmCalculator(mockData);\n  const results = calculator.calculate();\n  \n  console.assert(results.dataType === 'zscore', 'Results should be zscore type');\n  console.assert(results.parameters.length === 7, 'Should have 7 parameters');\n  console.assert(results.overallScore >= 0 && results.overallScore <= 21, 'Score in valid range');\n  \n  console.log('‚úÖ Z-score calculation test passed\\n');\n  console.log('Results:', results.parameters.map(p => `${p.name}: ${p.score}/3`));\n}\n\n// Test 4: Mismatch rejection\nasync function testMismatchRejection() {\n  console.log('üö´ Testing Mismatch Rejection...\\n');\n  \n  const zscoreFile = { path: './test-data/zscore-report-EO.pdf', originalname: 'zscore.pdf' };\n  const rawFile = { path: './test-data/raw-report-EC.pdf', originalname: 'raw.pdf' };\n  \n  try {\n    await QEEGParser.parse(zscoreFile, rawFile);\n    console.assert(false, 'Should have thrown error');\n  } catch (error) {\n    console.assert(error.message.includes('Mismatched report types'), 'Should be mismatch error');\n    console.log('‚úÖ Mismatch rejection test passed\\n');\n  }\n}\n\n// Run all tests\n(async () => {\n  try {\n    await testDetection();\n    await testZScoreExtraction();\n    await testZScoreCalculations();\n    await testMismatchRejection();\n    console.log('\\nüéâ All tests passed!\\n');\n  } catch (error) {\n    console.error('\\n‚ùå Test failed:', error.message);\n    console.error(error.stack);\n  }\n})();\n```\n\n### STEP 10: Documentation (20 min)\n**File**: `docs/ZSCORE_MODE.md` (NEW)\n\n```markdown\n# Z-Score QEEG Report Mode\n\n## Overview\nNeuroSense now supports TWO types of QEEG reports:\n1. **Raw Power Mode** (Original) - Absolute Power (ŒºV¬≤) and Relative Power (%)\n2. **Z-Score Mode** (New) - Standardized deviations from age-matched norms\n\n## How It Works\n\n### Automatic Detection\nThe system automatically detects report type by:\n1. Scanning PDF for keywords (\"Z-score\", \"ŒºV¬≤\", etc.)\n2. Validating data ranges (Z: -3 to +3, Raw: 0-500)\n3. Rejecting mismatched report types\n\n### Z-Score Interpretation\n- **Z = 0**: Average (50th percentile)\n- **Z = ¬±1**: Within normal range (68% of population)\n- **Z = ¬±2**: Mild abnormality (95% of population)\n- **Z > ¬±2**: Significant deviation (outliers)\n\n### Clinical Thresholds\n\n| Metric | Raw Threshold | Z-Score Threshold |\n|--------|---------------|-------------------|\n| Focus (Theta:Beta) | < 1.5 | Theta < +1 SD, Beta > -1 SD |\n| Alpha Peak | > 9 Hz | > 9 Hz AND Z within ¬±1 |\n| Arousal (HiBeta:Beta) | < 1.0 | HiBeta < +1 SD |\n| Excessive Delta | < 70% | Delta < +2 SD |\n| Alpha Asymmetry | F4/F3 < 1 | F4-F3 within ¬±1 SD |\n\n## Usage\n\n### Upload Z-Score Reports\n1. Navigate to Algorithm Data Processor\n2. Select patient\n3. Upload EO and EC Z-score reports\n4. System detects type automatically\n5. Calculation uses Z-score formulas\n\n### Error Handling\n- **Mismatched types**: Error message prompts for matching reports\n- **Unclear detection**: Defaults to raw mode with warning\n- **Missing channels**: Calculates available parameters\n\n## Testing\nRun tests:\n```bash\nnode server/tests/dualModeTests.js\n```\n\n## References\n- Neuroguide normative database\n- Clinical neurophysiology standards (ACNS)\n- Z-score standardization methodology\n```\n\n---\n\n## TESTING CHECKLIST\n\nBefore going live:\n- [ ] Test detection with your Z-score PDFs\n- [ ] Test extraction quality (OpenAI correctly parses Z-scores)\n- [ ] Test all 7 parameters calculate correctly in Z-score mode\n- [ ] Test mismatch rejection (EO=raw, EC=zscore)\n- [ ] Test edge case: Z-scores = 0 (perfect average brain)\n- [ ] Test edge case: Z-scores > ¬±3 (extreme outliers)\n- [ ] Test frontend displays Z-score badge correctly\n- [ ] Test PDF generation works with Z-score results\n- [ ] Test database saves dataType correctly\n- [ ] Compare results with known clinical interpretations\n\n---\n\n## TIME ESTIMATE\n\n| Task | Time | Cumulative |\n|------|------|------------|\n| Detection logic | 30 min | 30 min |\n| Parse flow update | 15 min | 45 min |\n| Dual prompts | 45 min | 1.5 hr |\n| Update parsePDF | 20 min | 1.8 hr |\n| Validation methods | 30 min | 2.3 hr |\n| Z-score thresholds | 20 min | 2.5 hr |\n| Calculator updates | 60 min | 3.5 hr |\n| Frontend updates | 30 min | 4 hr |\n| Testing setup | 60 min | 5 hr |\n| Documentation | 20 min | 5.3 hr |\n| Real-world testing | 60 min | 6.3 hr |\n| Bug fixes & polish | 90 min | 7.8 hr |\n\n**Total**: ~8 hours (1 full day of focused work)\n\n---\n\n## NEXT STEPS\n\n1. **Provide Z-Score PDFs**: Upload sample reports to `server/test-data/` for testing\n2. **Review Plan**: Confirm this approach meets your needs\n3. **Begin Implementation**: I'll start with detection logic and work through sequentially\n4. **Iterative Testing**: Test each phase before moving to next\n\nReady to proceed?"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":6136,"cache_read_input_tokens":66571,"cache_creation":{"ephemeral_5m_input_tokens":6136,"ephemeral_1h_input_tokens":0},"output_tokens":9481,"service_tier":"standard"}},"requestId":"req_011CVhbPjJMgMpHn5bqqDCHf","type":"assistant","uuid":"2eebc027-8ef6-4033-ba95-ea9294fb098a","timestamp":"2025-12-02T09:07:50.780Z"}
