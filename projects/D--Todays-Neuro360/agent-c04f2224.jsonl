{"parentUuid":null,"isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"972863b1-626a-4b9e-b24c-b6506ce5f6af","version":"2.0.33","gitBranch":"main","agentId":"c04f2224","type":"user","message":{"role":"user","content":"I need to improve error handling in the QEEG processing system to ensure patients always get dynamic calculations (never hardcoded sample data).\n\nPlease analyze and plan:\n\n1. **Read `server/services/qeegParser.js` completely** and identify:\n   - Where is the sample data fallback? (around lines 259-285)\n   - Where is the OpenAI API key check? (around lines 81-84)\n   - What should proper error handling look like instead of silent fallback?\n\n2. **Read `server/routes/qeegRoutes.js`** and identify:\n   - How does the /process endpoint handle errors from qeegParser?\n   - What error messages are sent to the frontend?\n   - Where should we add logging?\n\n3. **Read `server/.env`** to check:\n   - Is OPENAI_API_KEY configured?\n   - Is it a valid key format?\n\n4. **Create a plan** for:\n   - Remove hardcoded sample data fallback\n   - Add proper error handling that fails fast instead of using fake data\n   - Add detailed logging to track which patient data is being used\n   - Ensure frontend gets clear error messages when extraction fails\n   - Verify OpenAI API key is valid before processing\n\nShow me the specific code sections that need to be modified with line numbers."},"uuid":"f954a3f2-cfa2-4830-addb-50e7c148e19d","timestamp":"2025-11-29T07:08:15.241Z"}
{"parentUuid":"f954a3f2-cfa2-4830-addb-50e7c148e19d","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"972863b1-626a-4b9e-b24c-b6506ce5f6af","version":"2.0.33","gitBranch":"main","agentId":"c04f2224","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01AZPJPBL9iydvTs17RETiKt","type":"message","role":"assistant","content":[{"type":"text","text":"I'll analyze the QEEG processing system to identify error handling issues and create a comprehensive plan for improvements."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":9052,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":9052,"ephemeral_1h_input_tokens":0},"output_tokens":203,"service_tier":"standard"}},"requestId":"req_011CVbm28i43dxnpZE7ZA5e9","type":"assistant","uuid":"e601bd3e-fe6d-4a96-bd11-9224d295cb73","timestamp":"2025-11-29T07:08:18.177Z"}
{"parentUuid":"e601bd3e-fe6d-4a96-bd11-9224d295cb73","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"972863b1-626a-4b9e-b24c-b6506ce5f6af","version":"2.0.33","gitBranch":"main","agentId":"c04f2224","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01AZPJPBL9iydvTs17RETiKt","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01NHG8xoAstpadf7YWdCVg9J","name":"Read","input":{"file_path":"D:\\Todays\\Neuro360\\server\\services\\qeegParser.js"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":9052,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":9052,"ephemeral_1h_input_tokens":0},"output_tokens":203,"service_tier":"standard"}},"requestId":"req_011CVbm28i43dxnpZE7ZA5e9","type":"assistant","uuid":"22ea794b-a024-433a-b4be-14ed71fc4ceb","timestamp":"2025-11-29T07:08:18.790Z"}
{"parentUuid":"22ea794b-a024-433a-b4be-14ed71fc4ceb","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"972863b1-626a-4b9e-b24c-b6506ce5f6af","version":"2.0.33","gitBranch":"main","agentId":"c04f2224","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01AZPJPBL9iydvTs17RETiKt","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011ADMkuSCaUmhNmdNNivu5W","name":"Read","input":{"file_path":"D:\\Todays\\Neuro360\\server\\routes\\qeegRoutes.js"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":9052,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":9052,"ephemeral_1h_input_tokens":0},"output_tokens":203,"service_tier":"standard"}},"requestId":"req_011CVbm28i43dxnpZE7ZA5e9","type":"assistant","uuid":"d33717e6-150f-4760-a465-a7a10fc0c0e2","timestamp":"2025-11-29T07:08:19.129Z"}
{"parentUuid":"d33717e6-150f-4760-a465-a7a10fc0c0e2","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"972863b1-626a-4b9e-b24c-b6506ce5f6af","version":"2.0.33","gitBranch":"main","agentId":"c04f2224","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01AZPJPBL9iydvTs17RETiKt","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0164sa5GYRyWAqM5TMSN22rS","name":"Read","input":{"file_path":"D:\\Todays\\Neuro360\\server\\.env"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":9052,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":9052,"ephemeral_1h_input_tokens":0},"output_tokens":203,"service_tier":"standard"}},"requestId":"req_011CVbm28i43dxnpZE7ZA5e9","type":"assistant","uuid":"78961e0f-0f72-4bdc-9327-91b01e92e137","timestamp":"2025-11-29T07:08:19.409Z"}
{"parentUuid":"78961e0f-0f72-4bdc-9327-91b01e92e137","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"972863b1-626a-4b9e-b24c-b6506ce5f6af","version":"2.0.33","gitBranch":"main","agentId":"c04f2224","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01NHG8xoAstpadf7YWdCVg9J","type":"tool_result","content":"     1â†’const fs = require('fs');\n     2â†’const path = require('path');\n     3â†’const OpenAI = require('openai');\n     4â†’const pdfParse = require('pdf-parse');\n     5â†’const XLSX = require('xlsx');\n     6â†’\n     7â†’// Initialize OpenAI client\n     8â†’const openai = new OpenAI({\n     9â†’  apiKey: process.env.OPENAI_API_KEY\n    10â†’});\n    11â†’\n    12â†’class QEEGParser {\n    13â†’  /**\n    14â†’   * Main method to parse uploaded files\n    15â†’   * @param {Object} eyesOpenFile - Multer file object for Eyes Open data\n    16â†’   * @param {Object} eyesClosedFile - Multer file object for Eyes Closed data\n    17â†’   * @returns {Object} Parsed QEEG data\n    18â†’   */\n    19â†’  static async parse(eyesOpenFile, eyesClosedFile) {\n    20â†’    try {\n    21â†’      console.log('ğŸ“„ Parsing QEEG files...');\n    22â†’      console.log('  - Eyes Open:', eyesOpenFile?.originalname);\n    23â†’      console.log('  - Eyes Closed:', eyesClosedFile?.originalname);\n    24â†’\n    25â†’      // Determine file types\n    26â†’      const eoFileType = this.getFileType(eyesOpenFile.originalname);\n    27â†’      const ecFileType = this.getFileType(eyesClosedFile.originalname);\n    28â†’\n    29â†’      // Parse each file\n    30â†’      const eyesOpenData = await this.parseFile(eyesOpenFile, eoFileType, 'EO');\n    31â†’      const eyesClosedData = await this.parseFile(eyesClosedFile, ecFileType, 'EC');\n    32â†’\n    33â†’      // Combine data\n    34â†’      const combinedData = {\n    35â†’        EO: eyesOpenData,\n    36â†’        EC: eyesClosedData\n    37â†’      };\n    38â†’\n    39â†’      console.log('âœ… QEEG files parsed successfully');\n    40â†’      return combinedData;\n    41â†’\n    42â†’    } catch (error) {\n    43â†’      console.error('âŒ Error parsing QEEG files:', error);\n    44â†’      throw new Error(`Failed to parse QEEG files: ${error.message}`);\n    45â†’    }\n    46â†’  }\n    47â†’\n    48â†’  /**\n    49â†’   * Determine file type from filename\n    50â†’   */\n    51â†’  static getFileType(filename) {\n    52â†’    const ext = path.extname(filename).toLowerCase();\n    53â†’    if (ext === '.pdf') return 'pdf';\n    54â†’    if (ext === '.csv') return 'csv';\n    55â†’    if (ext === '.xlsx' || ext === '.xls') return 'excel';\n    56â†’    throw new Error(`Unsupported file type: ${ext}`);\n    57â†’  }\n    58â†’\n    59â†’  /**\n    60â†’   * Parse a single file based on its type\n    61â†’   */\n    62â†’  static async parseFile(file, fileType, condition) {\n    63â†’    if (fileType === 'pdf') {\n    64â†’      return await this.parsePDF(file, condition);\n    65â†’    } else if (fileType === 'csv') {\n    66â†’      return this.parseCSV(file);\n    67â†’    } else if (fileType === 'excel') {\n    68â†’      return this.parseExcel(file);\n    69â†’    }\n    70â†’    throw new Error(`Unknown file type: ${fileType}`);\n    71â†’  }\n    72â†’\n    73â†’  /**\n    74â†’   * Parse PDF file using OpenAI Vision API\n    75â†’   */\n    76â†’  static async parsePDF(file, condition) {\n    77â†’    console.log(`  ğŸ” Parsing PDF with OpenAI Vision API (${condition})...`);\n    78â†’\n    79â†’    try {\n    80â†’      // Check if OpenAI API key exists\n    81â†’      if (!process.env.OPENAI_API_KEY || process.env.OPENAI_API_KEY === 'your-openai-api-key-here') {\n    82â†’        console.error('  âš ï¸ OpenAI API key not configured. Using sample data.');\n    83â†’        return this.getSampleDataStructure();\n    84â†’      }\n    85â†’\n    86â†’      // Read PDF file\n    87â†’      const dataBuffer = fs.readFileSync(file.path);\n    88â†’      const pdfData = await pdfParse(dataBuffer);\n    89â†’\n    90â†’      // Extract text from PDF\n    91â†’      const pdfText = pdfData.text;\n    92â†’\n    93â†’    // Use OpenAI to extract QEEG tables\n    94â†’    const prompt = `You are a QEEG data extraction expert. Extract the following data from this ${condition === 'EO' ? 'Eyes Open' : 'Eyes Closed'} QEEG report:\n    95â†’\n    96â†’Extract two tables:\n    97â†’1. **Absolute Power (Î¼VÂ²)** table\n    98â†’2. **Relative Power (%)** table\n    99â†’\n   100â†’For each table, extract values for these EEG channels: FP1, FP2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2\n   101â†’\n   102â†’For each channel, extract values for these frequency bands:\n   103â†’- Delta\n   104â†’- Theta\n   105â†’- Alpha\n   106â†’- Beta\n   107â†’- HiBeta (High Beta)\n   108â†’\n   109â†’Also extract Alpha Peak Frequency (APF) if available.\n   110â†’\n   111â†’Return the data in this EXACT JSON format:\n   112â†’{\n   113â†’  \"absolute\": {\n   114â†’    \"Fz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   115â†’    \"Cz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   116â†’    \"Pz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   117â†’    \"F3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   118â†’    \"F4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   119â†’    \"C3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   120â†’    \"C4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   121â†’    \"P3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   122â†’    \"P4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 }\n   123â†’  },\n   124â†’  \"relative\": {\n   125â†’    \"Fz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   126â†’    \"Cz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   127â†’    \"Pz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   128â†’    \"F3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   129â†’    \"F4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   130â†’    \"C3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   131â†’    \"C4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   132â†’    \"P3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n   133â†’    \"P4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 }\n   134â†’  },\n   135â†’  \"special\": {\n   136â†’    \"alphaPeak\": 10.0,\n   137â†’    \"O1\": 10.0\n   138â†’  }\n   139â†’}\n   140â†’\n   141â†’PDF Content:\n   142â†’${pdfText.substring(0, 15000)}`;\n   143â†’\n   144â†’      const response = await openai.chat.completions.create({\n   145â†’        model: 'gpt-4-turbo-preview',\n   146â†’        messages: [\n   147â†’          {\n   148â†’            role: 'system',\n   149â†’            content: 'You are an expert at extracting structured QEEG data from medical reports. Always return valid JSON.'\n   150â†’          },\n   151â†’          {\n   152â†’            role: 'user',\n   153â†’            content: prompt\n   154â†’          }\n   155â†’        ],\n   156â†’        temperature: 0.1,\n   157â†’        response_format: { type: 'json_object' }\n   158â†’      });\n   159â†’\n   160â†’      const extractedData = JSON.parse(response.choices[0].message.content);\n   161â†’      console.log(`  âœ… PDF data extracted successfully (${condition})`);\n   162â†’      return extractedData;\n   163â†’\n   164â†’    } catch (error) {\n   165â†’      console.error(`  âŒ OpenAI API error (${condition}):`, error.message);\n   166â†’\n   167â†’      // Log more details for debugging\n   168â†’      if (error.response) {\n   169â†’        console.error(`  âŒ OpenAI API Status:`, error.response.status);\n   170â†’        console.error(`  âŒ OpenAI API Error:`, error.response.data);\n   171â†’      }\n   172â†’\n   173â†’      // Fallback: Return sample data structure if OpenAI fails\n   174â†’      console.log('  âš ï¸ Using sample data structure as fallback');\n   175â†’      return this.getSampleDataStructure();\n   176â†’    }\n   177â†’  }\n   178â†’\n   179â†’  /**\n   180â†’   * Parse CSV file\n   181â†’   */\n   182â†’  static parseCSV(file) {\n   183â†’    console.log('  ğŸ“Š Parsing CSV file...');\n   184â†’\n   185â†’    // Read CSV file\n   186â†’    const workbook = XLSX.readFile(file.path);\n   187â†’    const sheetName = workbook.SheetNames[0];\n   188â†’    const worksheet = workbook.Sheets[sheetName];\n   189â†’    const jsonData = XLSX.utils.sheet_to_json(worksheet);\n   190â†’\n   191â†’    // Convert CSV data to our format\n   192â†’    const data = this.convertCSVToFormat(jsonData);\n   193â†’\n   194â†’    console.log('  âœ… CSV parsed successfully');\n   195â†’    return data;\n   196â†’  }\n   197â†’\n   198â†’  /**\n   199â†’   * Parse Excel file\n   200â†’   */\n   201â†’  static parseExcel(file) {\n   202â†’    console.log('  ğŸ“Š Parsing Excel file...');\n   203â†’\n   204â†’    // Read Excel file\n   205â†’    const workbook = XLSX.readFile(file.path);\n   206â†’    const sheetName = workbook.SheetNames[0];\n   207â†’    const worksheet = workbook.Sheets[sheetName];\n   208â†’    const jsonData = XLSX.utils.sheet_to_json(worksheet);\n   209â†’\n   210â†’    // Convert Excel data to our format\n   211â†’    const data = this.convertExcelToFormat(jsonData);\n   212â†’\n   213â†’    console.log('  âœ… Excel parsed successfully');\n   214â†’    return data;\n   215â†’  }\n   216â†’\n   217â†’  /**\n   218â†’   * Convert CSV data to expected format\n   219â†’   */\n   220â†’  static convertCSVToFormat(csvData) {\n   221â†’    // Assuming CSV has structure: Channel, PowerType, Delta, Theta, Alpha, Beta, HiBeta\n   222â†’    const result = {\n   223â†’      absolute: {},\n   224â†’      relative: {},\n   225â†’      special: { alphaPeak: 10.0, O1: 10.0 }\n   226â†’    };\n   227â†’\n   228â†’    const channels = ['Fz', 'Cz', 'Pz', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4'];\n   229â†’    const bands = ['Delta', 'Theta', 'Alpha', 'Beta', 'HiBeta'];\n   230â†’\n   231â†’    for (const row of csvData) {\n   232â†’      const channel = row.Channel;\n   233â†’      const powerType = row.PowerType?.toLowerCase();\n   234â†’\n   235â†’      if (channels.includes(channel) && (powerType === 'absolute' || powerType === 'relative')) {\n   236â†’        result[powerType][channel] = {\n   237â†’          Delta: parseFloat(row.Delta) || 0,\n   238â†’          Theta: parseFloat(row.Theta) || 0,\n   239â†’          Alpha: parseFloat(row.Alpha) || 0,\n   240â†’          Beta: parseFloat(row.Beta) || 0,\n   241â†’          HiBeta: parseFloat(row.HiBeta || row.HighBeta) || 0\n   242â†’        };\n   243â†’      }\n   244â†’    }\n   245â†’\n   246â†’    return result;\n   247â†’  }\n   248â†’\n   249â†’  /**\n   250â†’   * Convert Excel data to expected format (same as CSV for now)\n   251â†’   */\n   252â†’  static convertExcelToFormat(excelData) {\n   253â†’    return this.convertCSVToFormat(excelData);\n   254â†’  }\n   255â†’\n   256â†’  /**\n   257â†’   * Get sample data structure (fallback)\n   258â†’   */\n   259â†’  static getSampleDataStructure() {\n   260â†’    const channels = ['Fz', 'Cz', 'Pz', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4'];\n   261â†’    const result = {\n   262â†’      absolute: {},\n   263â†’      relative: {},\n   264â†’      special: { alphaPeak: 10.0, O1: 10.0 }\n   265â†’    };\n   266â†’\n   267â†’    for (const channel of channels) {\n   268â†’      result.absolute[channel] = {\n   269â†’        Delta: 100,\n   270â†’        Theta: 120,\n   271â†’        Alpha: 200,\n   272â†’        Beta: 150,\n   273â†’        HiBeta: 100\n   274â†’      };\n   275â†’      result.relative[channel] = {\n   276â†’        Delta: 20,\n   277â†’        Theta: 15,\n   278â†’        Alpha: 40,\n   279â†’        Beta: 20,\n   280â†’        HiBeta: 5\n   281â†’      };\n   282â†’    }\n   283â†’\n   284â†’    return result;\n   285â†’  }\n   286â†’}\n   287â†’\n   288â†’module.exports = QEEGParser;\n   289â†’\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"c30b1b84-6e95-46f5-84ad-25b7cafa100f","timestamp":"2025-11-29T07:08:25.567Z","toolUseResult":{"type":"text","file":{"filePath":"D:\\Todays\\Neuro360\\server\\services\\qeegParser.js","content":"const fs = require('fs');\nconst path = require('path');\nconst OpenAI = require('openai');\nconst pdfParse = require('pdf-parse');\nconst XLSX = require('xlsx');\n\n// Initialize OpenAI client\nconst openai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY\n});\n\nclass QEEGParser {\n  /**\n   * Main method to parse uploaded files\n   * @param {Object} eyesOpenFile - Multer file object for Eyes Open data\n   * @param {Object} eyesClosedFile - Multer file object for Eyes Closed data\n   * @returns {Object} Parsed QEEG data\n   */\n  static async parse(eyesOpenFile, eyesClosedFile) {\n    try {\n      console.log('ğŸ“„ Parsing QEEG files...');\n      console.log('  - Eyes Open:', eyesOpenFile?.originalname);\n      console.log('  - Eyes Closed:', eyesClosedFile?.originalname);\n\n      // Determine file types\n      const eoFileType = this.getFileType(eyesOpenFile.originalname);\n      const ecFileType = this.getFileType(eyesClosedFile.originalname);\n\n      // Parse each file\n      const eyesOpenData = await this.parseFile(eyesOpenFile, eoFileType, 'EO');\n      const eyesClosedData = await this.parseFile(eyesClosedFile, ecFileType, 'EC');\n\n      // Combine data\n      const combinedData = {\n        EO: eyesOpenData,\n        EC: eyesClosedData\n      };\n\n      console.log('âœ… QEEG files parsed successfully');\n      return combinedData;\n\n    } catch (error) {\n      console.error('âŒ Error parsing QEEG files:', error);\n      throw new Error(`Failed to parse QEEG files: ${error.message}`);\n    }\n  }\n\n  /**\n   * Determine file type from filename\n   */\n  static getFileType(filename) {\n    const ext = path.extname(filename).toLowerCase();\n    if (ext === '.pdf') return 'pdf';\n    if (ext === '.csv') return 'csv';\n    if (ext === '.xlsx' || ext === '.xls') return 'excel';\n    throw new Error(`Unsupported file type: ${ext}`);\n  }\n\n  /**\n   * Parse a single file based on its type\n   */\n  static async parseFile(file, fileType, condition) {\n    if (fileType === 'pdf') {\n      return await this.parsePDF(file, condition);\n    } else if (fileType === 'csv') {\n      return this.parseCSV(file);\n    } else if (fileType === 'excel') {\n      return this.parseExcel(file);\n    }\n    throw new Error(`Unknown file type: ${fileType}`);\n  }\n\n  /**\n   * Parse PDF file using OpenAI Vision API\n   */\n  static async parsePDF(file, condition) {\n    console.log(`  ğŸ” Parsing PDF with OpenAI Vision API (${condition})...`);\n\n    try {\n      // Check if OpenAI API key exists\n      if (!process.env.OPENAI_API_KEY || process.env.OPENAI_API_KEY === 'your-openai-api-key-here') {\n        console.error('  âš ï¸ OpenAI API key not configured. Using sample data.');\n        return this.getSampleDataStructure();\n      }\n\n      // Read PDF file\n      const dataBuffer = fs.readFileSync(file.path);\n      const pdfData = await pdfParse(dataBuffer);\n\n      // Extract text from PDF\n      const pdfText = pdfData.text;\n\n    // Use OpenAI to extract QEEG tables\n    const prompt = `You are a QEEG data extraction expert. Extract the following data from this ${condition === 'EO' ? 'Eyes Open' : 'Eyes Closed'} QEEG report:\n\nExtract two tables:\n1. **Absolute Power (Î¼VÂ²)** table\n2. **Relative Power (%)** table\n\nFor each table, extract values for these EEG channels: FP1, FP2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2\n\nFor each channel, extract values for these frequency bands:\n- Delta\n- Theta\n- Alpha\n- Beta\n- HiBeta (High Beta)\n\nAlso extract Alpha Peak Frequency (APF) if available.\n\nReturn the data in this EXACT JSON format:\n{\n  \"absolute\": {\n    \"Fz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"Cz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"Pz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"F3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"F4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"C3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"C4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"P3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"P4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 }\n  },\n  \"relative\": {\n    \"Fz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"Cz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"Pz\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"F3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"F4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"C3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"C4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"P3\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 },\n    \"P4\": { \"Delta\": 0.0, \"Theta\": 0.0, \"Alpha\": 0.0, \"Beta\": 0.0, \"HiBeta\": 0.0 }\n  },\n  \"special\": {\n    \"alphaPeak\": 10.0,\n    \"O1\": 10.0\n  }\n}\n\nPDF Content:\n${pdfText.substring(0, 15000)}`;\n\n      const response = await openai.chat.completions.create({\n        model: 'gpt-4-turbo-preview',\n        messages: [\n          {\n            role: 'system',\n            content: 'You are an expert at extracting structured QEEG data from medical reports. Always return valid JSON.'\n          },\n          {\n            role: 'user',\n            content: prompt\n          }\n        ],\n        temperature: 0.1,\n        response_format: { type: 'json_object' }\n      });\n\n      const extractedData = JSON.parse(response.choices[0].message.content);\n      console.log(`  âœ… PDF data extracted successfully (${condition})`);\n      return extractedData;\n\n    } catch (error) {\n      console.error(`  âŒ OpenAI API error (${condition}):`, error.message);\n\n      // Log more details for debugging\n      if (error.response) {\n        console.error(`  âŒ OpenAI API Status:`, error.response.status);\n        console.error(`  âŒ OpenAI API Error:`, error.response.data);\n      }\n\n      // Fallback: Return sample data structure if OpenAI fails\n      console.log('  âš ï¸ Using sample data structure as fallback');\n      return this.getSampleDataStructure();\n    }\n  }\n\n  /**\n   * Parse CSV file\n   */\n  static parseCSV(file) {\n    console.log('  ğŸ“Š Parsing CSV file...');\n\n    // Read CSV file\n    const workbook = XLSX.readFile(file.path);\n    const sheetName = workbook.SheetNames[0];\n    const worksheet = workbook.Sheets[sheetName];\n    const jsonData = XLSX.utils.sheet_to_json(worksheet);\n\n    // Convert CSV data to our format\n    const data = this.convertCSVToFormat(jsonData);\n\n    console.log('  âœ… CSV parsed successfully');\n    return data;\n  }\n\n  /**\n   * Parse Excel file\n   */\n  static parseExcel(file) {\n    console.log('  ğŸ“Š Parsing Excel file...');\n\n    // Read Excel file\n    const workbook = XLSX.readFile(file.path);\n    const sheetName = workbook.SheetNames[0];\n    const worksheet = workbook.Sheets[sheetName];\n    const jsonData = XLSX.utils.sheet_to_json(worksheet);\n\n    // Convert Excel data to our format\n    const data = this.convertExcelToFormat(jsonData);\n\n    console.log('  âœ… Excel parsed successfully');\n    return data;\n  }\n\n  /**\n   * Convert CSV data to expected format\n   */\n  static convertCSVToFormat(csvData) {\n    // Assuming CSV has structure: Channel, PowerType, Delta, Theta, Alpha, Beta, HiBeta\n    const result = {\n      absolute: {},\n      relative: {},\n      special: { alphaPeak: 10.0, O1: 10.0 }\n    };\n\n    const channels = ['Fz', 'Cz', 'Pz', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4'];\n    const bands = ['Delta', 'Theta', 'Alpha', 'Beta', 'HiBeta'];\n\n    for (const row of csvData) {\n      const channel = row.Channel;\n      const powerType = row.PowerType?.toLowerCase();\n\n      if (channels.includes(channel) && (powerType === 'absolute' || powerType === 'relative')) {\n        result[powerType][channel] = {\n          Delta: parseFloat(row.Delta) || 0,\n          Theta: parseFloat(row.Theta) || 0,\n          Alpha: parseFloat(row.Alpha) || 0,\n          Beta: parseFloat(row.Beta) || 0,\n          HiBeta: parseFloat(row.HiBeta || row.HighBeta) || 0\n        };\n      }\n    }\n\n    return result;\n  }\n\n  /**\n   * Convert Excel data to expected format (same as CSV for now)\n   */\n  static convertExcelToFormat(excelData) {\n    return this.convertCSVToFormat(excelData);\n  }\n\n  /**\n   * Get sample data structure (fallback)\n   */\n  static getSampleDataStructure() {\n    const channels = ['Fz', 'Cz', 'Pz', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4'];\n    const result = {\n      absolute: {},\n      relative: {},\n      special: { alphaPeak: 10.0, O1: 10.0 }\n    };\n\n    for (const channel of channels) {\n      result.absolute[channel] = {\n        Delta: 100,\n        Theta: 120,\n        Alpha: 200,\n        Beta: 150,\n        HiBeta: 100\n      };\n      result.relative[channel] = {\n        Delta: 20,\n        Theta: 15,\n        Alpha: 40,\n        Beta: 20,\n        HiBeta: 5\n      };\n    }\n\n    return result;\n  }\n}\n\nmodule.exports = QEEGParser;\n","numLines":289,"startLine":1,"totalLines":289}}}
{"parentUuid":"c30b1b84-6e95-46f5-84ad-25b7cafa100f","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"972863b1-626a-4b9e-b24c-b6506ce5f6af","version":"2.0.33","gitBranch":"main","agentId":"c04f2224","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011ADMkuSCaUmhNmdNNivu5W","type":"tool_result","content":"     1â†’const express = require('express');\n     2â†’const multer = require('multer');\n     3â†’const path = require('path');\n     4â†’const fs = require('fs');\n     5â†’const QEEGParser = require('../services/qeegParser');\n     6â†’const AlgorithmCalculator = require('../services/algorithmCalculator');\n     7â†’const PDFReportGenerator = require('../services/pdfGenerator');\n     8â†’const AIPdfGenerator = require('../services/aiPdfGenerator');\n     9â†’const SupabaseStorage = require('../services/supabaseStorage');\n    10â†’\n    11â†’const router = express.Router();\n    12â†’\n    13â†’// Configure multer for file uploads\n    14â†’const storage = multer.diskStorage({\n    15â†’  destination: function (req, file, cb) {\n    16â†’    const uploadDir = path.join(__dirname, '../uploads');\n    17â†’    // Ensure upload directory exists\n    18â†’    if (!fs.existsSync(uploadDir)) {\n    19â†’      fs.mkdirSync(uploadDir, { recursive: true });\n    20â†’    }\n    21â†’    cb(null, uploadDir);\n    22â†’  },\n    23â†’  filename: function (req, file, cb) {\n    24â†’    const uniqueSuffix = Date.now() + '-' + Math.round(Math.random() * 1E9);\n    25â†’    cb(null, file.fieldname + '-' + uniqueSuffix + path.extname(file.originalname));\n    26â†’  }\n    27â†’});\n    28â†’\n    29â†’const upload = multer({\n    30â†’  storage: storage,\n    31â†’  limits: {\n    32â†’    fileSize: 10 * 1024 * 1024 // 10MB limit\n    33â†’  },\n    34â†’  fileFilter: function (req, file, cb) {\n    35â†’    const allowedExtensions = ['.pdf', '.csv', '.xlsx', '.xls'];\n    36â†’    const ext = path.extname(file.originalname).toLowerCase();\n    37â†’    if (allowedExtensions.includes(ext)) {\n    38â†’      cb(null, true);\n    39â†’    } else {\n    40â†’      cb(new Error(`Only ${allowedExtensions.join(', ')} files are allowed`));\n    41â†’    }\n    42â†’  }\n    43â†’});\n    44â†’\n    45â†’/**\n    46â†’ * POST /api/qeeg/process\n    47â†’ * Process QEEG files and calculate 7 brain health parameters\n    48â†’ */\n    49â†’router.post('/process', upload.fields([\n    50â†’  { name: 'eyesOpen', maxCount: 1 },\n    51â†’  { name: 'eyesClosed', maxCount: 1 }\n    52â†’]), async (req, res) => {\n    53â†’  let eyesOpenFile = null;\n    54â†’  let eyesClosedFile = null;\n    55â†’\n    56â†’  try {\n    57â†’    console.log('\\nğŸ”¬ === QEEG Processing Started ===\\n');\n    58â†’\n    59â†’    // Get uploaded files\n    60â†’    const files = req.files;\n    61â†’    if (!files || !files.eyesOpen || !files.eyesClosed) {\n    62â†’      return res.status(400).json({\n    63â†’        error: true,\n    64â†’        message: 'Both Eyes Open and Eyes Closed files are required'\n    65â†’      });\n    66â†’    }\n    67â†’\n    68â†’    eyesOpenFile = files.eyesOpen[0];\n    69â†’    eyesClosedFile = files.eyesClosed[0];\n    70â†’\n    71â†’    console.log('ğŸ“ Files received:');\n    72â†’    console.log('  - Eyes Open:', eyesOpenFile.originalname, `(${(eyesOpenFile.size / 1024).toFixed(2)} KB)`);\n    73â†’    console.log('  - Eyes Closed:', eyesClosedFile.originalname, `(${(eyesClosedFile.size / 1024).toFixed(2)} KB)`);\n    74â†’\n    75â†’    // Get patient info from request body\n    76â†’    const { patientId, patientName, clinicName } = req.body;\n    77â†’\n    78â†’    console.log('\\nğŸ‘¤ Patient Information:');\n    79â†’    console.log('  - Patient ID:', patientId);\n    80â†’    console.log('  - Patient Name:', patientName);\n    81â†’    console.log('  - Clinic:', clinicName);\n    82â†’\n    83â†’    // Step 1: Parse QEEG files\n    84â†’    console.log('\\nğŸ“Š Step 1: Parsing QEEG files...');\n    85â†’    const qeegData = await QEEGParser.parse(eyesOpenFile, eyesClosedFile);\n    86â†’\n    87â†’    // Step 2: Calculate parameters\n    88â†’    console.log('\\nğŸ§® Step 2: Calculating 7 brain health parameters...');\n    89â†’    const calculator = new AlgorithmCalculator(qeegData);\n    90â†’    const results = calculator.calculate();\n    91â†’\n    92â†’    console.log('\\nâœ… Calculation completed successfully!');\n    93â†’    console.log('ğŸ“ˆ Results Summary:');\n    94â†’    results.parameters.forEach(param => {\n    95â†’      console.log(`  - ${param.name}: ${param.score}/${param.maxScore} (${param.classification})`);\n    96â†’    });\n    97â†’    console.log(`  - Overall Score: ${results.overallScore}/21`);\n    98â†’\n    99â†’    // Clean up uploaded files\n   100â†’    try {\n   101â†’      fs.unlinkSync(eyesOpenFile.path);\n   102â†’      fs.unlinkSync(eyesClosedFile.path);\n   103â†’      console.log('\\nğŸ—‘ï¸  Temporary files cleaned up');\n   104â†’    } catch (cleanupError) {\n   105â†’      console.error('âš ï¸  Error cleaning up files:', cleanupError.message);\n   106â†’    }\n   107â†’\n   108â†’    console.log('\\nğŸ === QEEG Processing Completed ===\\n');\n   109â†’\n   110â†’    // Send response\n   111â†’    res.json({\n   112â†’      success: true,\n   113â†’      data: {\n   114â†’        patientId,\n   115â†’        patientName,\n   116â†’        clinicName,\n   117â†’        processedAt: new Date().toISOString(),\n   118â†’        results: results.parameters,\n   119â†’        overallScore: results.overallScore,\n   120â†’        maxScore: 21\n   121â†’      }\n   122â†’    });\n   123â†’\n   124â†’  } catch (error) {\n   125â†’    console.error('\\nâŒ === QEEG Processing Failed ===');\n   126â†’    console.error('Error:', error.message);\n   127â†’    console.error('Stack:', error.stack);\n   128â†’\n   129â†’    // Clean up files on error\n   130â†’    if (eyesOpenFile && fs.existsSync(eyesOpenFile.path)) {\n   131â†’      try {\n   132â†’        fs.unlinkSync(eyesOpenFile.path);\n   133â†’      } catch (e) {\n   134â†’        console.error('Error deleting Eyes Open file:', e.message);\n   135â†’      }\n   136â†’    }\n   137â†’    if (eyesClosedFile && fs.existsSync(eyesClosedFile.path)) {\n   138â†’      try {\n   139â†’        fs.unlinkSync(eyesClosedFile.path);\n   140â†’      } catch (e) {\n   141â†’        console.error('Error deleting Eyes Closed file:', e.message);\n   142â†’      }\n   143â†’    }\n   144â†’\n   145â†’    res.status(500).json({\n   146â†’      error: true,\n   147â†’      message: error.message || 'Failed to process QEEG files',\n   148â†’      details: process.env.NODE_ENV === 'development' ? error.stack : undefined\n   149â†’    });\n   150â†’  }\n   151â†’});\n   152â†’\n   153â†’/**\n   154â†’ * POST /api/qeeg/generate-pdf\n   155â†’ * Generate PDF report from algorithm results\n   156â†’ */\n   157â†’router.post('/generate-pdf', async (req, res) => {\n   158â†’  try {\n   159â†’    console.log('\\nğŸ“„ === PDF Report Generation Started ===\\n');\n   160â†’\n   161â†’    const { patientData, algorithmResults, qeegData } = req.body;\n   162â†’\n   163â†’    // Validate input\n   164â†’    if (!patientData || !algorithmResults || !qeegData) {\n   165â†’      return res.status(400).json({\n   166â†’        error: true,\n   167â†’        message: 'Missing required data: patientData, algorithmResults, and qeegData are required'\n   168â†’      });\n   169â†’    }\n   170â†’\n   171â†’    console.log('ğŸ‘¤ Patient:', patientData.name);\n   172â†’    console.log('ğŸ“Š Parameters:', algorithmResults.parameters?.length);\n   173â†’\n   174â†’    // Generate PDF\n   175â†’    const generator = new PDFReportGenerator(patientData, algorithmResults, qeegData);\n   176â†’\n   177â†’    // Create output filename\n   178â†’    const timestamp = Date.now();\n   179â†’    const sanitizedName = (patientData.name || 'patient').replace(/[^a-z0-9]/gi, '_').toLowerCase();\n   180â†’    const filename = `neurosense-report-${sanitizedName}-${timestamp}.pdf`;\n   181â†’    const outputPath = path.join(__dirname, '../uploads', filename);\n   182â†’\n   183â†’    console.log('ğŸ“ Generating PDF to:', filename);\n   184â†’\n   185â†’    // Generate the PDF\n   186â†’    const pdfPath = await generator.generateReport(outputPath);\n   187â†’\n   188â†’    console.log('\\nâœ… PDF Report Generated Successfully!');\n   189â†’    console.log('ğŸ“„ File:', filename);\n   190â†’    console.log('ğŸ“Š Size:', (fs.statSync(pdfPath).size / 1024).toFixed(2), 'KB');\n   191â†’\n   192â†’    // Upload to Supabase Storage - TEMPORARILY DISABLED\n   193â†’    let supabaseUrl = null;\n   194â†’    let supabasePath = null;\n   195â†’    let uploadError = null;\n   196â†’\n   197â†’    // DISABLE SUPABASE UPLOAD FOR NOW - USE LOCAL STORAGE ONLY\n   198â†’    console.log('\\nğŸ“ Using local storage (Supabase upload disabled)');\n   199â†’    uploadError = 'Supabase upload disabled - using local storage';\n   200â†’\n   201â†’    /* COMMENTED OUT - Enable when Supabase is configured properly\n   202â†’    try {\n   203â†’      console.log('\\nâ˜ï¸  Uploading PDF to Supabase storage...');\n   204â†’      const uploadResult = await SupabaseStorage.uploadFile(\n   205â†’        pdfPath,\n   206â†’        'patient-reports', // bucket name\n   207â†’        `reports/${filename}` // path in bucket\n   208â†’      );\n   209â†’\n   210â†’      // Verify upload was successful and URL is valid\n   211â†’      if (uploadResult && uploadResult.url) {\n   212â†’        supabaseUrl = uploadResult.url;\n   213â†’        supabasePath = uploadResult.path;\n   214â†’\n   215â†’        console.log('âœ… PDF uploaded to Supabase successfully');\n   216â†’        console.log('ğŸ”— Supabase URL:', supabaseUrl);\n   217â†’\n   218â†’        // Only delete local file after SUCCESSFUL Supabase upload\n   219â†’        try {\n   220â†’          fs.unlinkSync(pdfPath);\n   221â†’          console.log('ğŸ—‘ï¸  Local PDF file deleted after successful upload');\n   222â†’        } catch (deleteError) {\n   223â†’          console.warn('âš ï¸  Could not delete local PDF file:', deleteError.message);\n   224â†’        }\n   225â†’      } else {\n   226â†’        throw new Error('Supabase upload returned invalid result');\n   227â†’      }\n   228â†’\n   229â†’    } catch (error) {\n   230â†’      console.error('âš ï¸  Supabase upload failed, using local storage:', error.message);\n   231â†’      uploadError = error.message;\n   232â†’      // Keep local file as fallback - DO NOT DELETE\n   233â†’      console.log('ğŸ“ Using local file as fallback');\n   234â†’    }\n   235â†’    */\n   236â†’\n   237â†’    console.log('\\nğŸ === PDF Generation Completed ===\\n');\n   238â†’\n   239â†’    // Return PDF info - prioritize Supabase URL\n   240â†’    res.json({\n   241â†’      success: true,\n   242â†’      data: {\n   243â†’        filename: filename,\n   244â†’        path: supabasePath || `/uploads/${filename}`,\n   245â†’        url: supabaseUrl || `${req.protocol}://${req.get('host')}/uploads/${filename}`,\n   246â†’        size: fs.existsSync(pdfPath) ? fs.statSync(pdfPath).size : 0,\n   247â†’        generatedAt: new Date().toISOString(),\n   248â†’        storage: supabaseUrl ? 'supabase' : 'local',\n   249â†’        uploadError: uploadError\n   250â†’      }\n   251â†’    });\n   252â†’\n   253â†’  } catch (error) {\n   254â†’    console.error('\\nâŒ === PDF Generation Failed ===');\n   255â†’    console.error('Error:', error.message);\n   256â†’    console.error('Stack:', error.stack);\n   257â†’\n   258â†’    res.status(500).json({\n   259â†’      error: true,\n   260â†’      message: error.message || 'Failed to generate PDF report',\n   261â†’      details: process.env.NODE_ENV === 'development' ? error.stack : undefined\n   262â†’    });\n   263â†’  }\n   264â†’});\n   265â†’\n   266â†’/**\n   267â†’ * POST /api/qeeg/generate-sample-pdf\n   268â†’ * Generate a sample PDF report for testing\n   269â†’ */\n   270â†’router.post('/generate-sample-pdf', async (req, res) => {\n   271â†’  try {\n   272â†’    console.log('\\nğŸ“„ === Sample PDF Generation Started ===\\n');\n   273â†’\n   274â†’    const pdfPath = await PDFReportGenerator.generateSampleReport();\n   275â†’\n   276â†’    console.log('âœ… Sample PDF Generated!');\n   277â†’    console.log('ğŸ“„ Path:', pdfPath);\n   278â†’\n   279â†’    const filename = path.basename(pdfPath);\n   280â†’\n   281â†’    res.json({\n   282â†’      success: true,\n   283â†’      data: {\n   284â†’        filename: filename,\n   285â†’        path: `/uploads/${filename}`,\n   286â†’        url: `${req.protocol}://${req.get('host')}/uploads/${filename}`,\n   287â†’        size: fs.statSync(pdfPath).size\n   288â†’      }\n   289â†’    });\n   290â†’\n   291â†’  } catch (error) {\n   292â†’    console.error('âŒ Sample PDF generation failed:', error);\n   293â†’\n   294â†’    res.status(500).json({\n   295â†’      error: true,\n   296â†’      message: error.message\n   297â†’    });\n   298â†’  }\n   299â†’});\n   300â†’\n   301â†’/**\n   302â†’ * POST /api/qeeg/generate-ai-pdf\n   303â†’ * Generate AI-powered PDF report with enhanced design and content\n   304â†’ */\n   305â†’router.post('/generate-ai-pdf', async (req, res) => {\n   306â†’  try {\n   307â†’    console.log('\\nğŸ¤– === AI PDF Report Generation Started ===\\n');\n   308â†’\n   309â†’    const { patientData, algorithmResults, qeegData } = req.body;\n   310â†’\n   311â†’    // Validate input\n   312â†’    if (!patientData || !algorithmResults || !qeegData) {\n   313â†’      return res.status(400).json({\n   314â†’        error: true,\n   315â†’        message: 'Missing required data: patientData, algorithmResults, and qeegData are required'\n   316â†’      });\n   317â†’    }\n   318â†’\n   319â†’    console.log('ğŸ‘¤ Patient:', patientData.name);\n   320â†’    console.log('ğŸ“Š Parameters:', algorithmResults.parameters?.length);\n   321â†’    console.log('ğŸ¯ Using AI-powered generation with enhanced prompt');\n   322â†’\n   323â†’    // Generate AI PDF\n   324â†’    const generator = new AIPdfGenerator(patientData, algorithmResults, qeegData);\n   325â†’\n   326â†’    // Create output filename\n   327â†’    const timestamp = Date.now();\n   328â†’    const sanitizedName = (patientData.name || 'patient').replace(/[^a-z0-9]/gi, '_').toLowerCase();\n   329â†’    const filename = `ai-neurosense-report-${sanitizedName}-${timestamp}.pdf`;\n   330â†’    const outputPath = path.join(__dirname, '../uploads', filename);\n   331â†’\n   332â†’    console.log('ğŸ“ Generating AI PDF to:', filename);\n   333â†’\n   334â†’    // Generate the PDF\n   335â†’    const result = await generator.generateReport(outputPath);\n   336â†’\n   337â†’    console.log('\\nâœ… AI NeuroSense Report Generated Successfully!');\n   338â†’    console.log('ğŸ“„ Text File:', path.basename(result.textOutputPath));\n   339â†’    console.log('ğŸ“„ JSON File:', path.basename(result.outputPath));\n   340â†’    console.log('ğŸ“Š Tokens Used:', result.tokensUsed);\n   341â†’    console.log('ğŸ“ Content Length:', result.contentLength, 'characters');\n   342â†’    console.log('\\nğŸ === AI PDF Generation Completed ===\\n');\n   343â†’\n   344â†’    // Return report info\n   345â†’    res.json({\n   346â†’      success: true,\n   347â†’      data: {\n   348â†’        textFile: {\n   349â†’          filename: path.basename(result.textOutputPath),\n   350â†’          path: `/uploads/${path.basename(result.textOutputPath)}`,\n   351â†’          url: `${req.protocol}://${req.get('host')}/uploads/${path.basename(result.textOutputPath)}`,\n   352â†’          type: 'Plain Text Report'\n   353â†’        },\n   354â†’        jsonFile: {\n   355â†’          filename: path.basename(result.outputPath),\n   356â†’          path: `/uploads/${path.basename(result.outputPath)}`,\n   357â†’          url: `${req.protocol}://${req.get('host')}/uploads/${path.basename(result.outputPath)}`,\n   358â†’          type: 'Structured Data (JSON)'\n   359â†’        },\n   360â†’        contentLength: result.contentLength,\n   361â†’        tokensUsed: result.tokensUsed,\n   362â†’        generatedAt: new Date().toISOString()\n   363â†’      },\n   364â†’      message: 'AI-powered NeuroSense report generated successfully. Text file contains formatted report ready for PDF conversion.'\n   365â†’    });\n   366â†’\n   367â†’  } catch (error) {\n   368â†’    console.error('\\nâŒ === AI PDF Generation Failed ===');\n   369â†’    console.error('Error:', error.message);\n   370â†’    console.error('Stack:', error.stack);\n   371â†’\n   372â†’    res.status(500).json({\n   373â†’      error: true,\n   374â†’      message: error.message || 'Failed to generate AI PDF report',\n   375â†’      details: process.env.NODE_ENV === 'development' ? error.stack : undefined\n   376â†’    });\n   377â†’  }\n   378â†’});\n   379â†’\n   380â†’/**\n   381â†’ * POST /api/qeeg/generate-ai-sample-pdf\n   382â†’ * Generate a sample AI-powered PDF report for testing\n   383â†’ */\n   384â†’router.post('/generate-ai-sample-pdf', async (req, res) => {\n   385â†’  try {\n   386â†’    console.log('\\nğŸ¤– === Sample AI PDF Generation Started ===\\n');\n   387â†’\n   388â†’    const result = await AIPdfGenerator.generateSampleReport();\n   389â†’\n   390â†’    console.log('âœ… Sample AI PDF Generated!');\n   391â†’    console.log('ğŸ“„ Path:', result.outputPath);\n   392â†’\n   393â†’    const filename = path.basename(result.outputPath);\n   394â†’\n   395â†’    res.json({\n   396â†’      success: true,\n   397â†’      data: {\n   398â†’        filename: filename,\n   399â†’        path: `/uploads/${filename}`,\n   400â†’        url: `${req.protocol}://${req.get('host')}/uploads/${filename}`,\n   401â†’        contentLength: result.contentLength,\n   402â†’        tokensUsed: result.tokensUsed,\n   403â†’        type: 'AI-Generated Sample (JSON format)'\n   404â†’      }\n   405â†’    });\n   406â†’\n   407â†’  } catch (error) {\n   408â†’    console.error('âŒ Sample AI PDF generation failed:', error);\n   409â†’\n   410â†’    res.status(500).json({\n   411â†’      error: true,\n   412â†’      message: error.message\n   413â†’    });\n   414â†’  }\n   415â†’});\n   416â†’\n   417â†’/**\n   418â†’ * GET /api/qeeg/test\n   419â†’ * Test endpoint to verify API is working\n   420â†’ */\n   421â†’router.get('/test', (req, res) => {\n   422â†’  res.json({\n   423â†’    success: true,\n   424â†’    message: 'QEEG Processing API is working',\n   425â†’    endpoints: {\n   426â†’      process: 'POST /api/qeeg/process - Upload and process QEEG files',\n   427â†’      generatePdf: 'POST /api/qeeg/generate-pdf - Generate PDF report from results (PDFKit)',\n   428â†’      generateSamplePdf: 'POST /api/qeeg/generate-sample-pdf - Generate sample PDF report (PDFKit)',\n   429â†’      generateAiPdf: 'POST /api/qeeg/generate-ai-pdf - Generate AI-powered PDF report (OpenAI)',\n   430â†’      generateAiSamplePdf: 'POST /api/qeeg/generate-ai-sample-pdf - Generate AI sample PDF report (OpenAI)'\n   431â†’    }\n   432â†’  });\n   433â†’});\n   434â†’\n   435â†’module.exports = router;\n   436â†’\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"556f14af-73cc-4622-82bf-e1b0ccfd3dac","timestamp":"2025-11-29T07:08:25.570Z","toolUseResult":{"type":"text","file":{"filePath":"D:\\Todays\\Neuro360\\server\\routes\\qeegRoutes.js","content":"const express = require('express');\nconst multer = require('multer');\nconst path = require('path');\nconst fs = require('fs');\nconst QEEGParser = require('../services/qeegParser');\nconst AlgorithmCalculator = require('../services/algorithmCalculator');\nconst PDFReportGenerator = require('../services/pdfGenerator');\nconst AIPdfGenerator = require('../services/aiPdfGenerator');\nconst SupabaseStorage = require('../services/supabaseStorage');\n\nconst router = express.Router();\n\n// Configure multer for file uploads\nconst storage = multer.diskStorage({\n  destination: function (req, file, cb) {\n    const uploadDir = path.join(__dirname, '../uploads');\n    // Ensure upload directory exists\n    if (!fs.existsSync(uploadDir)) {\n      fs.mkdirSync(uploadDir, { recursive: true });\n    }\n    cb(null, uploadDir);\n  },\n  filename: function (req, file, cb) {\n    const uniqueSuffix = Date.now() + '-' + Math.round(Math.random() * 1E9);\n    cb(null, file.fieldname + '-' + uniqueSuffix + path.extname(file.originalname));\n  }\n});\n\nconst upload = multer({\n  storage: storage,\n  limits: {\n    fileSize: 10 * 1024 * 1024 // 10MB limit\n  },\n  fileFilter: function (req, file, cb) {\n    const allowedExtensions = ['.pdf', '.csv', '.xlsx', '.xls'];\n    const ext = path.extname(file.originalname).toLowerCase();\n    if (allowedExtensions.includes(ext)) {\n      cb(null, true);\n    } else {\n      cb(new Error(`Only ${allowedExtensions.join(', ')} files are allowed`));\n    }\n  }\n});\n\n/**\n * POST /api/qeeg/process\n * Process QEEG files and calculate 7 brain health parameters\n */\nrouter.post('/process', upload.fields([\n  { name: 'eyesOpen', maxCount: 1 },\n  { name: 'eyesClosed', maxCount: 1 }\n]), async (req, res) => {\n  let eyesOpenFile = null;\n  let eyesClosedFile = null;\n\n  try {\n    console.log('\\nğŸ”¬ === QEEG Processing Started ===\\n');\n\n    // Get uploaded files\n    const files = req.files;\n    if (!files || !files.eyesOpen || !files.eyesClosed) {\n      return res.status(400).json({\n        error: true,\n        message: 'Both Eyes Open and Eyes Closed files are required'\n      });\n    }\n\n    eyesOpenFile = files.eyesOpen[0];\n    eyesClosedFile = files.eyesClosed[0];\n\n    console.log('ğŸ“ Files received:');\n    console.log('  - Eyes Open:', eyesOpenFile.originalname, `(${(eyesOpenFile.size / 1024).toFixed(2)} KB)`);\n    console.log('  - Eyes Closed:', eyesClosedFile.originalname, `(${(eyesClosedFile.size / 1024).toFixed(2)} KB)`);\n\n    // Get patient info from request body\n    const { patientId, patientName, clinicName } = req.body;\n\n    console.log('\\nğŸ‘¤ Patient Information:');\n    console.log('  - Patient ID:', patientId);\n    console.log('  - Patient Name:', patientName);\n    console.log('  - Clinic:', clinicName);\n\n    // Step 1: Parse QEEG files\n    console.log('\\nğŸ“Š Step 1: Parsing QEEG files...');\n    const qeegData = await QEEGParser.parse(eyesOpenFile, eyesClosedFile);\n\n    // Step 2: Calculate parameters\n    console.log('\\nğŸ§® Step 2: Calculating 7 brain health parameters...');\n    const calculator = new AlgorithmCalculator(qeegData);\n    const results = calculator.calculate();\n\n    console.log('\\nâœ… Calculation completed successfully!');\n    console.log('ğŸ“ˆ Results Summary:');\n    results.parameters.forEach(param => {\n      console.log(`  - ${param.name}: ${param.score}/${param.maxScore} (${param.classification})`);\n    });\n    console.log(`  - Overall Score: ${results.overallScore}/21`);\n\n    // Clean up uploaded files\n    try {\n      fs.unlinkSync(eyesOpenFile.path);\n      fs.unlinkSync(eyesClosedFile.path);\n      console.log('\\nğŸ—‘ï¸  Temporary files cleaned up');\n    } catch (cleanupError) {\n      console.error('âš ï¸  Error cleaning up files:', cleanupError.message);\n    }\n\n    console.log('\\nğŸ === QEEG Processing Completed ===\\n');\n\n    // Send response\n    res.json({\n      success: true,\n      data: {\n        patientId,\n        patientName,\n        clinicName,\n        processedAt: new Date().toISOString(),\n        results: results.parameters,\n        overallScore: results.overallScore,\n        maxScore: 21\n      }\n    });\n\n  } catch (error) {\n    console.error('\\nâŒ === QEEG Processing Failed ===');\n    console.error('Error:', error.message);\n    console.error('Stack:', error.stack);\n\n    // Clean up files on error\n    if (eyesOpenFile && fs.existsSync(eyesOpenFile.path)) {\n      try {\n        fs.unlinkSync(eyesOpenFile.path);\n      } catch (e) {\n        console.error('Error deleting Eyes Open file:', e.message);\n      }\n    }\n    if (eyesClosedFile && fs.existsSync(eyesClosedFile.path)) {\n      try {\n        fs.unlinkSync(eyesClosedFile.path);\n      } catch (e) {\n        console.error('Error deleting Eyes Closed file:', e.message);\n      }\n    }\n\n    res.status(500).json({\n      error: true,\n      message: error.message || 'Failed to process QEEG files',\n      details: process.env.NODE_ENV === 'development' ? error.stack : undefined\n    });\n  }\n});\n\n/**\n * POST /api/qeeg/generate-pdf\n * Generate PDF report from algorithm results\n */\nrouter.post('/generate-pdf', async (req, res) => {\n  try {\n    console.log('\\nğŸ“„ === PDF Report Generation Started ===\\n');\n\n    const { patientData, algorithmResults, qeegData } = req.body;\n\n    // Validate input\n    if (!patientData || !algorithmResults || !qeegData) {\n      return res.status(400).json({\n        error: true,\n        message: 'Missing required data: patientData, algorithmResults, and qeegData are required'\n      });\n    }\n\n    console.log('ğŸ‘¤ Patient:', patientData.name);\n    console.log('ğŸ“Š Parameters:', algorithmResults.parameters?.length);\n\n    // Generate PDF\n    const generator = new PDFReportGenerator(patientData, algorithmResults, qeegData);\n\n    // Create output filename\n    const timestamp = Date.now();\n    const sanitizedName = (patientData.name || 'patient').replace(/[^a-z0-9]/gi, '_').toLowerCase();\n    const filename = `neurosense-report-${sanitizedName}-${timestamp}.pdf`;\n    const outputPath = path.join(__dirname, '../uploads', filename);\n\n    console.log('ğŸ“ Generating PDF to:', filename);\n\n    // Generate the PDF\n    const pdfPath = await generator.generateReport(outputPath);\n\n    console.log('\\nâœ… PDF Report Generated Successfully!');\n    console.log('ğŸ“„ File:', filename);\n    console.log('ğŸ“Š Size:', (fs.statSync(pdfPath).size / 1024).toFixed(2), 'KB');\n\n    // Upload to Supabase Storage - TEMPORARILY DISABLED\n    let supabaseUrl = null;\n    let supabasePath = null;\n    let uploadError = null;\n\n    // DISABLE SUPABASE UPLOAD FOR NOW - USE LOCAL STORAGE ONLY\n    console.log('\\nğŸ“ Using local storage (Supabase upload disabled)');\n    uploadError = 'Supabase upload disabled - using local storage';\n\n    /* COMMENTED OUT - Enable when Supabase is configured properly\n    try {\n      console.log('\\nâ˜ï¸  Uploading PDF to Supabase storage...');\n      const uploadResult = await SupabaseStorage.uploadFile(\n        pdfPath,\n        'patient-reports', // bucket name\n        `reports/${filename}` // path in bucket\n      );\n\n      // Verify upload was successful and URL is valid\n      if (uploadResult && uploadResult.url) {\n        supabaseUrl = uploadResult.url;\n        supabasePath = uploadResult.path;\n\n        console.log('âœ… PDF uploaded to Supabase successfully');\n        console.log('ğŸ”— Supabase URL:', supabaseUrl);\n\n        // Only delete local file after SUCCESSFUL Supabase upload\n        try {\n          fs.unlinkSync(pdfPath);\n          console.log('ğŸ—‘ï¸  Local PDF file deleted after successful upload');\n        } catch (deleteError) {\n          console.warn('âš ï¸  Could not delete local PDF file:', deleteError.message);\n        }\n      } else {\n        throw new Error('Supabase upload returned invalid result');\n      }\n\n    } catch (error) {\n      console.error('âš ï¸  Supabase upload failed, using local storage:', error.message);\n      uploadError = error.message;\n      // Keep local file as fallback - DO NOT DELETE\n      console.log('ğŸ“ Using local file as fallback');\n    }\n    */\n\n    console.log('\\nğŸ === PDF Generation Completed ===\\n');\n\n    // Return PDF info - prioritize Supabase URL\n    res.json({\n      success: true,\n      data: {\n        filename: filename,\n        path: supabasePath || `/uploads/${filename}`,\n        url: supabaseUrl || `${req.protocol}://${req.get('host')}/uploads/${filename}`,\n        size: fs.existsSync(pdfPath) ? fs.statSync(pdfPath).size : 0,\n        generatedAt: new Date().toISOString(),\n        storage: supabaseUrl ? 'supabase' : 'local',\n        uploadError: uploadError\n      }\n    });\n\n  } catch (error) {\n    console.error('\\nâŒ === PDF Generation Failed ===');\n    console.error('Error:', error.message);\n    console.error('Stack:', error.stack);\n\n    res.status(500).json({\n      error: true,\n      message: error.message || 'Failed to generate PDF report',\n      details: process.env.NODE_ENV === 'development' ? error.stack : undefined\n    });\n  }\n});\n\n/**\n * POST /api/qeeg/generate-sample-pdf\n * Generate a sample PDF report for testing\n */\nrouter.post('/generate-sample-pdf', async (req, res) => {\n  try {\n    console.log('\\nğŸ“„ === Sample PDF Generation Started ===\\n');\n\n    const pdfPath = await PDFReportGenerator.generateSampleReport();\n\n    console.log('âœ… Sample PDF Generated!');\n    console.log('ğŸ“„ Path:', pdfPath);\n\n    const filename = path.basename(pdfPath);\n\n    res.json({\n      success: true,\n      data: {\n        filename: filename,\n        path: `/uploads/${filename}`,\n        url: `${req.protocol}://${req.get('host')}/uploads/${filename}`,\n        size: fs.statSync(pdfPath).size\n      }\n    });\n\n  } catch (error) {\n    console.error('âŒ Sample PDF generation failed:', error);\n\n    res.status(500).json({\n      error: true,\n      message: error.message\n    });\n  }\n});\n\n/**\n * POST /api/qeeg/generate-ai-pdf\n * Generate AI-powered PDF report with enhanced design and content\n */\nrouter.post('/generate-ai-pdf', async (req, res) => {\n  try {\n    console.log('\\nğŸ¤– === AI PDF Report Generation Started ===\\n');\n\n    const { patientData, algorithmResults, qeegData } = req.body;\n\n    // Validate input\n    if (!patientData || !algorithmResults || !qeegData) {\n      return res.status(400).json({\n        error: true,\n        message: 'Missing required data: patientData, algorithmResults, and qeegData are required'\n      });\n    }\n\n    console.log('ğŸ‘¤ Patient:', patientData.name);\n    console.log('ğŸ“Š Parameters:', algorithmResults.parameters?.length);\n    console.log('ğŸ¯ Using AI-powered generation with enhanced prompt');\n\n    // Generate AI PDF\n    const generator = new AIPdfGenerator(patientData, algorithmResults, qeegData);\n\n    // Create output filename\n    const timestamp = Date.now();\n    const sanitizedName = (patientData.name || 'patient').replace(/[^a-z0-9]/gi, '_').toLowerCase();\n    const filename = `ai-neurosense-report-${sanitizedName}-${timestamp}.pdf`;\n    const outputPath = path.join(__dirname, '../uploads', filename);\n\n    console.log('ğŸ“ Generating AI PDF to:', filename);\n\n    // Generate the PDF\n    const result = await generator.generateReport(outputPath);\n\n    console.log('\\nâœ… AI NeuroSense Report Generated Successfully!');\n    console.log('ğŸ“„ Text File:', path.basename(result.textOutputPath));\n    console.log('ğŸ“„ JSON File:', path.basename(result.outputPath));\n    console.log('ğŸ“Š Tokens Used:', result.tokensUsed);\n    console.log('ğŸ“ Content Length:', result.contentLength, 'characters');\n    console.log('\\nğŸ === AI PDF Generation Completed ===\\n');\n\n    // Return report info\n    res.json({\n      success: true,\n      data: {\n        textFile: {\n          filename: path.basename(result.textOutputPath),\n          path: `/uploads/${path.basename(result.textOutputPath)}`,\n          url: `${req.protocol}://${req.get('host')}/uploads/${path.basename(result.textOutputPath)}`,\n          type: 'Plain Text Report'\n        },\n        jsonFile: {\n          filename: path.basename(result.outputPath),\n          path: `/uploads/${path.basename(result.outputPath)}`,\n          url: `${req.protocol}://${req.get('host')}/uploads/${path.basename(result.outputPath)}`,\n          type: 'Structured Data (JSON)'\n        },\n        contentLength: result.contentLength,\n        tokensUsed: result.tokensUsed,\n        generatedAt: new Date().toISOString()\n      },\n      message: 'AI-powered NeuroSense report generated successfully. Text file contains formatted report ready for PDF conversion.'\n    });\n\n  } catch (error) {\n    console.error('\\nâŒ === AI PDF Generation Failed ===');\n    console.error('Error:', error.message);\n    console.error('Stack:', error.stack);\n\n    res.status(500).json({\n      error: true,\n      message: error.message || 'Failed to generate AI PDF report',\n      details: process.env.NODE_ENV === 'development' ? error.stack : undefined\n    });\n  }\n});\n\n/**\n * POST /api/qeeg/generate-ai-sample-pdf\n * Generate a sample AI-powered PDF report for testing\n */\nrouter.post('/generate-ai-sample-pdf', async (req, res) => {\n  try {\n    console.log('\\nğŸ¤– === Sample AI PDF Generation Started ===\\n');\n\n    const result = await AIPdfGenerator.generateSampleReport();\n\n    console.log('âœ… Sample AI PDF Generated!');\n    console.log('ğŸ“„ Path:', result.outputPath);\n\n    const filename = path.basename(result.outputPath);\n\n    res.json({\n      success: true,\n      data: {\n        filename: filename,\n        path: `/uploads/${filename}`,\n        url: `${req.protocol}://${req.get('host')}/uploads/${filename}`,\n        contentLength: result.contentLength,\n        tokensUsed: result.tokensUsed,\n        type: 'AI-Generated Sample (JSON format)'\n      }\n    });\n\n  } catch (error) {\n    console.error('âŒ Sample AI PDF generation failed:', error);\n\n    res.status(500).json({\n      error: true,\n      message: error.message\n    });\n  }\n});\n\n/**\n * GET /api/qeeg/test\n * Test endpoint to verify API is working\n */\nrouter.get('/test', (req, res) => {\n  res.json({\n    success: true,\n    message: 'QEEG Processing API is working',\n    endpoints: {\n      process: 'POST /api/qeeg/process - Upload and process QEEG files',\n      generatePdf: 'POST /api/qeeg/generate-pdf - Generate PDF report from results (PDFKit)',\n      generateSamplePdf: 'POST /api/qeeg/generate-sample-pdf - Generate sample PDF report (PDFKit)',\n      generateAiPdf: 'POST /api/qeeg/generate-ai-pdf - Generate AI-powered PDF report (OpenAI)',\n      generateAiSamplePdf: 'POST /api/qeeg/generate-ai-sample-pdf - Generate AI sample PDF report (OpenAI)'\n    }\n  });\n});\n\nmodule.exports = router;\n","numLines":436,"startLine":1,"totalLines":436}}}
{"parentUuid":"556f14af-73cc-4622-82bf-e1b0ccfd3dac","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"972863b1-626a-4b9e-b24c-b6506ce5f6af","version":"2.0.33","gitBranch":"main","agentId":"c04f2224","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0164sa5GYRyWAqM5TMSN22rS","type":"tool_result","content":"     1â†’# Backend Server Environment Configuration\n     2â†’\n     3â†’# Server Port\n     4â†’PORT=3001\n     5â†’\n     6â†’# OpenAI API Configuration\n     7â†’OPENAI_API_KEY=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\n     8â†’\n     9â†’# Supabase Configuration\n    10â†’SUPABASE_URL=https://omyltmcesgbhnqmhrrvq.supabase.co\n    11â†’SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im9teWx0bWNlc2diaG5xbWhycnZxIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1ODE3NjY1MCwiZXhwIjoyMDczNzUyNjUwfQ.UZT7MbCkfi-AuMaZ7tcV78bjyOT6PKOJHiP0x1LlFhM\n    12â†’\n    13â†’# Environment\n    14â†’\n    15â†’\n    16â†’NODE_ENV=development\n    17â†’\n    18â†’# Frontend URL (for CORS)\n    19â†’FRONTEND_URL=http://localhost:3000\n    20â†’\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"da2d907c-d287-4e12-a9f0-93754d07c8ca","timestamp":"2025-11-29T07:08:25.572Z","toolUseResult":{"type":"text","file":{"filePath":"D:\\Todays\\Neuro360\\server\\.env","content":"# Backend Server Environment Configuration\n\n# Server Port\nPORT=3001\n\n# OpenAI API Configuration\nOPENAI_API_KEY=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\n\n# Supabase Configuration\nSUPABASE_URL=https://omyltmcesgbhnqmhrrvq.supabase.co\nSUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im9teWx0bWNlc2diaG5xbWhycnZxIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1ODE3NjY1MCwiZXhwIjoyMDczNzUyNjUwfQ.UZT7MbCkfi-AuMaZ7tcV78bjyOT6PKOJHiP0x1LlFhM\n\n# Environment\n\n\nNODE_ENV=development\n\n# Frontend URL (for CORS)\nFRONTEND_URL=http://localhost:3000\n","numLines":20,"startLine":1,"totalLines":20}}}
{"parentUuid":"da2d907c-d287-4e12-a9f0-93754d07c8ca","isSidechain":true,"userType":"external","cwd":"D:\\Todays\\Neuro360","sessionId":"972863b1-626a-4b9e-b24c-b6506ce5f6af","version":"2.0.33","gitBranch":"main","agentId":"c04f2224","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_0188h6cPhJbV9o2Qcfr6uTU6","type":"message","role":"assistant","content":[{"type":"text","text":"## Analysis Complete\n\nI've analyzed the QEEG processing system and identified critical error handling issues. Here's my comprehensive report:\n\n---\n\n## 1. QEEG PARSER ANALYSIS (`server/services/qeegParser.js`)\n\n### CRITICAL ISSUES FOUND:\n\n#### A. Sample Data Fallback - Lines 81-84 (API Key Check)\n```javascript\n// Check if OpenAI API key exists\nif (!process.env.OPENAI_API_KEY || process.env.OPENAI_API_KEY === 'your-openai-api-key-here') {\n  console.error('  âš ï¸ OpenAI API key not configured. Using sample data.');\n  return this.getSampleDataStructure();  // âŒ SILENT FALLBACK\n}\n```\n\n#### B. Sample Data Fallback - Lines 164-176 (OpenAI API Error)\n```javascript\n} catch (error) {\n  console.error(`  âŒ OpenAI API error (${condition}):`, error.message);\n  \n  // Log more details for debugging\n  if (error.response) {\n    console.error(`  âŒ OpenAI API Status:`, error.response.status);\n    console.error(`  âŒ OpenAI API Error:`, error.response.data);\n  }\n  \n  // Fallback: Return sample data structure if OpenAI fails\n  console.log('  âš ï¸ Using sample data structure as fallback');\n  return this.getSampleDataStructure();  // âŒ SILENT FALLBACK\n}\n```\n\n#### C. Hardcoded Sample Data - Lines 259-285\n```javascript\nstatic getSampleDataStructure() {\n  const channels = ['Fz', 'Cz', 'Pz', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4'];\n  const result = {\n    absolute: {},\n    relative: {},\n    special: { alphaPeak: 10.0, O1: 10.0 }\n  };\n\n  for (const channel of channels) {\n    result.absolute[channel] = {\n      Delta: 100,    // âŒ FAKE DATA\n      Theta: 120,\n      Alpha: 200,\n      Beta: 150,\n      HiBeta: 100\n    };\n    result.relative[channel] = {\n      Delta: 20,     // âŒ FAKE DATA\n      Theta: 15,\n      Alpha: 40,\n      Beta: 20,\n      HiBeta: 5\n    };\n  }\n  return result;\n}\n```\n\n---\n\n## 2. ROUTES ANALYSIS (`server/routes/qeegRoutes.js`)\n\n### ERROR HANDLING ISSUES:\n\n#### A. Generic Error Handling - Lines 124-150\n```javascript\n} catch (error) {\n  console.error('\\nâŒ === QEEG Processing Failed ===');\n  console.error('Error:', error.message);\n  console.error('Stack:', error.stack);\n  \n  // Clean up files on error\n  if (eyesOpenFile && fs.existsSync(eyesOpenFile.path)) {\n    try {\n      fs.unlinkSync(eyesOpenFile.path);\n    } catch (e) {\n      console.error('Error deleting Eyes Open file:', e.message);\n    }\n  }\n  if (eyesClosedFile && fs.existsSync(eyesClosedFile.path)) {\n    try {\n      fs.unlinkSync(eyesClosedFile.path);\n    } catch (e) {\n      console.error('Error deleting Eyes Closed file:', e.message);\n    }\n  }\n\n  res.status(500).json({\n    error: true,\n    message: error.message || 'Failed to process QEEG files',  // âŒ Too generic\n    details: process.env.NODE_ENV === 'development' ? error.stack : undefined\n  });\n}\n```\n\n#### B. No Logging of Data Source\n- No indication to frontend whether real patient data or sample data was used\n- No warning flags in the response\n- Silent failures could lead to medical errors\n\n---\n\n## 3. ENVIRONMENT CONFIGURATION (`.env`)\n\n### API KEY STATUS:\n```\nOPENAI_API_KEY=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\n```\n\n- Key format: `sk-proj-*` (valid OpenAI project key format)\n- Key appears to be configured (not placeholder)\n- However, key could be expired or invalid (needs runtime validation)\n\n---\n\n## 4. COMPREHENSIVE IMPROVEMENT PLAN\n\n### PHASE 1: Remove Sample Data Fallback\n\n**File: `server/services/qeegParser.js`**\n\n#### Change 1: Lines 81-84 - Fail Fast on Missing API Key\n```javascript\n// BEFORE:\nif (!process.env.OPENAI_API_KEY || process.env.OPENAI_API_KEY === 'your-openai-api-key-here') {\n  console.error('  âš ï¸ OpenAI API key not configured. Using sample data.');\n  return this.getSampleDataStructure();\n}\n\n// AFTER:\nif (!process.env.OPENAI_API_KEY || process.env.OPENAI_API_KEY === 'your-openai-api-key-here') {\n  const error = new Error('OpenAI API key not configured. Cannot extract patient data from PDF.');\n  error.code = 'MISSING_API_KEY';\n  throw error;\n}\n```\n\n#### Change 2: Lines 164-176 - Fail Fast on OpenAI Errors\n```javascript\n// BEFORE:\n} catch (error) {\n  console.error(`  âŒ OpenAI API error (${condition}):`, error.message);\n  \n  if (error.response) {\n    console.error(`  âŒ OpenAI API Status:`, error.response.status);\n    console.error(`  âŒ OpenAI API Error:`, error.response.data);\n  }\n  \n  console.log('  âš ï¸ Using sample data structure as fallback');\n  return this.getSampleDataStructure();\n}\n\n// AFTER:\n} catch (error) {\n  console.error(`  âŒ OpenAI API error (${condition}):`, error.message);\n  \n  if (error.response) {\n    console.error(`  âŒ OpenAI API Status:`, error.response.status);\n    console.error(`  âŒ OpenAI API Error:`, error.response.data);\n  }\n  \n  // Re-throw with more context\n  const enhancedError = new Error(`Failed to extract QEEG data from PDF (${condition}): ${error.message}`);\n  enhancedError.code = 'PDF_EXTRACTION_FAILED';\n  enhancedError.originalError = error;\n  enhancedError.condition = condition;\n  throw enhancedError;\n}\n```\n\n#### Change 3: Lines 259-285 - Delete Sample Data Method Entirely\n```javascript\n// DELETE THIS ENTIRE METHOD:\n/**\n * Get sample data structure (fallback)\n */\nstatic getSampleDataStructure() {\n  // ... DELETE ALL 27 LINES ...\n}\n```\n\n---\n\n### PHASE 2: Add API Key Validation\n\n**File: `server/services/qeegParser.js`**\n\n#### Add New Method After Line 11:\n```javascript\n/**\n * Validate OpenAI API key is configured and appears valid\n * @throws {Error} if API key is missing or invalid format\n */\nstatic validateAPIKey() {\n  const apiKey = process.env.OPENAI_API_KEY;\n  \n  // Check if key exists\n  if (!apiKey || apiKey.trim() === '') {\n    const error = new Error('OPENAI_API_KEY environment variable is not set');\n    error.code = 'MISSING_API_KEY';\n    throw error;\n  }\n  \n  // Check if key is placeholder\n  if (apiKey === 'your-openai-api-key-here' || apiKey.includes('placeholder')) {\n    const error = new Error('OPENAI_API_KEY is set to placeholder value. Please configure a valid OpenAI API key.');\n    error.code = 'INVALID_API_KEY';\n    throw error;\n  }\n  \n  // Check key format (OpenAI keys start with sk-)\n  if (!apiKey.startsWith('sk-')) {\n    const error = new Error('OPENAI_API_KEY has invalid format. OpenAI keys should start with \"sk-\"');\n    error.code = 'INVALID_API_KEY_FORMAT';\n    throw error;\n  }\n  \n  console.log('âœ… OpenAI API key validation passed');\n  return true;\n}\n```\n\n#### Modify parsePDF Method - Add validation at Line 77:\n```javascript\nstatic async parsePDF(file, condition) {\n  console.log(`  ğŸ” Parsing PDF with OpenAI Vision API (${condition})...`);\n\n  try {\n    // Validate API key before attempting to use it\n    this.validateAPIKey();  // â† ADD THIS LINE\n    \n    // Read PDF file\n    const dataBuffer = fs.readFileSync(file.path);\n    // ... rest of the code\n```\n\n---\n\n### PHASE 3: Enhanced Error Messages in Routes\n\n**File: `server/routes/qeegRoutes.js`**\n\n#### Change: Lines 124-150 - Better Error Categorization\n```javascript\n// BEFORE:\n} catch (error) {\n  console.error('\\nâŒ === QEEG Processing Failed ===');\n  console.error('Error:', error.message);\n  console.error('Stack:', error.stack);\n  \n  // ... cleanup code ...\n  \n  res.status(500).json({\n    error: true,\n    message: error.message || 'Failed to process QEEG files',\n    details: process.env.NODE_ENV === 'development' ? error.stack : undefined\n  });\n}\n\n// AFTER:\n} catch (error) {\n  console.error('\\nâŒ === QEEG Processing Failed ===');\n  console.error('Error:', error.message);\n  console.error('Error Code:', error.code || 'UNKNOWN');\n  console.error('Stack:', error.stack);\n  \n  // ... cleanup code (same) ...\n  \n  // Categorize errors for better user feedback\n  let statusCode = 500;\n  let userMessage = error.message;\n  \n  switch (error.code) {\n    case 'MISSING_API_KEY':\n    case 'INVALID_API_KEY':\n    case 'INVALID_API_KEY_FORMAT':\n      statusCode = 503; // Service Unavailable\n      userMessage = 'System configuration error: OpenAI API key not properly configured. Please contact support.';\n      break;\n      \n    case 'PDF_EXTRACTION_FAILED':\n      statusCode = 422; // Unprocessable Entity\n      userMessage = 'Failed to extract QEEG data from PDF. Please ensure the PDF contains valid QEEG tables.';\n      break;\n      \n    default:\n      userMessage = error.message || 'Failed to process QEEG files';\n  }\n  \n  res.status(statusCode).json({\n    error: true,\n    message: userMessage,\n    code: error.code || 'UNKNOWN_ERROR',\n    technicalDetails: process.env.NODE_ENV === 'development' ? {\n      originalMessage: error.message,\n      stack: error.stack,\n      condition: error.condition\n    } : undefined\n  });\n}\n```\n\n---\n\n### PHASE 4: Add Comprehensive Logging\n\n**File: `server/services/qeegParser.js`**\n\n#### Add Logging to parsePDF - After Line 160:\n```javascript\nconst extractedData = JSON.parse(response.choices[0].message.content);\nconsole.log(`  âœ… PDF data extracted successfully (${condition})`);\n\n// ADD DETAILED LOGGING:\nconsole.log(`  ğŸ“Š Data extraction summary (${condition}):`);\nconsole.log(`     - Absolute power channels: ${Object.keys(extractedData.absolute || {}).length}`);\nconsole.log(`     - Relative power channels: ${Object.keys(extractedData.relative || {}).length}`);\nconsole.log(`     - Special values: ${JSON.stringify(extractedData.special || {})}`);\n\n// Validate extracted data has minimum required fields\nconst requiredChannels = ['Fz', 'Cz', 'Pz', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4'];\nconst absoluteChannels = Object.keys(extractedData.absolute || {});\nconst relativeChannels = Object.keys(extractedData.relative || {});\n\nconst missingAbsolute = requiredChannels.filter(ch => !absoluteChannels.includes(ch));\nconst missingRelative = requiredChannels.filter(ch => !relativeChannels.includes(ch));\n\nif (missingAbsolute.length > 0) {\n  console.warn(`  âš ï¸  Missing absolute power channels: ${missingAbsolute.join(', ')}`);\n}\nif (missingRelative.length > 0) {\n  console.warn(`  âš ï¸  Missing relative power channels: ${missingRelative.join(', ')}`);\n}\n\nreturn extractedData;\n```\n\n**File: `server/routes/qeegRoutes.js`**\n\n#### Add Patient Data Logging - After Line 85:\n```javascript\nconst qeegData = await QEEGParser.parse(eyesOpenFile, eyesClosedFile);\n\n// ADD THIS LOGGING:\nconsole.log('\\nğŸ“Š QEEG Data Validation:');\nconsole.log('  - Eyes Open (EO) channels:', Object.keys(qeegData.EO?.absolute || {}).length);\nconsole.log('  - Eyes Closed (EC) channels:', Object.keys(qeegData.EC?.absolute || {}).length);\nconsole.log('  - Using REAL PATIENT DATA (not sample data)');\nconsole.log('  - Patient:', patientName, `(ID: ${patientId})`);\n```\n\n---\n\n### PHASE 5: Runtime API Key Validation\n\n**File: `server/services/qeegParser.js`**\n\n#### Add Test Method:\n```javascript\n/**\n * Test OpenAI API connection with a simple request\n * @returns {Promise<boolean>} true if connection successful\n * @throws {Error} if connection fails\n */\nstatic async testAPIConnection() {\n  try {\n    this.validateAPIKey();\n    \n    console.log('ğŸ”Œ Testing OpenAI API connection...');\n    \n    const response = await openai.chat.completions.create({\n      model: 'gpt-4-turbo-preview',\n      messages: [\n        { role: 'user', content: 'Reply with OK' }\n      ],\n      max_tokens: 5\n    });\n    \n    if (response.choices && response.choices.length > 0) {\n      console.log('âœ… OpenAI API connection successful');\n      return true;\n    } else {\n      throw new Error('OpenAI API returned unexpected response');\n    }\n    \n  } catch (error) {\n    console.error('âŒ OpenAI API connection test failed:', error.message);\n    const enhancedError = new Error(`OpenAI API connection test failed: ${error.message}`);\n    enhancedError.code = 'API_CONNECTION_FAILED';\n    enhancedError.originalError = error;\n    throw enhancedError;\n  }\n}\n```\n\n**File: `server/routes/qeegRoutes.js`**\n\n#### Add Validation Before Processing - After Line 82:\n```javascript\nconsole.log('  - Clinic:', clinicName);\n\n// ADD API KEY TEST:\nconsole.log('\\nğŸ” Validating OpenAI API configuration...');\ntry {\n  await QEEGParser.testAPIConnection();\n} catch (apiError) {\n  throw new Error(`Cannot process QEEG data: ${apiError.message}`);\n}\n\n// Step 1: Parse QEEG files\nconsole.log('\\nğŸ“Š Step 1: Parsing QEEG files...');\n```\n\n---\n\n## SUMMARY OF CHANGES\n\n### Files to Modify:\n1. **`server/services/qeegParser.js`** - 6 changes\n2. **`server/routes/qeegRoutes.js`** - 3 changes\n\n### Code Sections:\n\n#### qeegParser.js:\n- Lines 11-50: Add `validateAPIKey()` method\n- Lines 51-90: Add `testAPIConnection()` method  \n- Line 77: Add API key validation call\n- Lines 81-84: Replace sample data fallback with error throw\n- Lines 160-180: Add data validation logging\n- Lines 164-176: Replace sample data fallback with error throw\n- Lines 259-285: DELETE `getSampleDataStructure()` method\n\n#### qeegRoutes.js:\n- Lines 82-90: Add API connection test before processing\n- Lines 85-91: Add patient data logging\n- Lines 124-150: Enhanced error categorization and messages\n\n### Expected Behavior After Changes:\n1. System fails immediately if OpenAI API key is missing/invalid\n2. No silent fallback to sample data\n3. Clear error messages to frontend indicating configuration issues\n4. Detailed logging of which patient's data is being processed\n5. Runtime validation that API key actually works before processing\n6. Medical safety: Never mix real patient IDs with fake sample data\n\nWould you like me to create these modifications in the actual files?"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":11257,"cache_read_input_tokens":9052,"cache_creation":{"ephemeral_5m_input_tokens":11257,"ephemeral_1h_input_tokens":0},"output_tokens":4499,"service_tier":"standard"}},"requestId":"req_011CVbm2wxfmEu5gszpGmtVs","type":"assistant","uuid":"dee5ab9d-2822-476a-8a59-3640261c1dbe","timestamp":"2025-11-29T07:09:29.377Z"}
